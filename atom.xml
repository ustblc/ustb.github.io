<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">
  <title>lemon</title>
  
  <subtitle>一直在路上</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://cblog.club/"/>
  <updated>2019-11-22T13:26:47.170Z</updated>
  <id>https://cblog.club/</id>
  
  <author>
    <name>lemon</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PyTorch-Day4</title>
    <link href="https://cblog.club/ck3a6ilg6002bjsg48c7w6s3d.html"/>
    <id>https://cblog.club/ck3a6ilg6002bjsg48c7w6s3d.html</id>
    <published>2019-11-22T13:02:15.000Z</published>
    <updated>2019-11-22T13:26:47.170Z</updated>
    
    <content type="html"><![CDATA[<h3 id="棒子写的教程"><a href="#棒子写的教程" class="headerlink" title="棒子写的教程"></a>棒子写的教程</h3><h3 id="韩国人写的PyTorch教程-真的不错"><a href="#韩国人写的PyTorch教程-真的不错" class="headerlink" title="韩国人写的PyTorch教程,真的不错"></a>韩国人写的PyTorch教程,真的不错</h3><ul><li>这个资源为深度学习研究人员提供了学习PyTorch的教程</li><li>代码大多数模型都使用少于30行代码实现</li></ul><a id="more"></a><h3 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h3><ul><li>基本的自动求导 例子1</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建张量tensors(这里举得的例子是张量)</span></span><br><span class="line">x = torch.tensor(<span class="number">1.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor(<span class="number">2.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor(<span class="number">3.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个可以计算的公式 y=2x+3</span></span><br><span class="line">y = w * x + b</span><br><span class="line">y.backward()</span><br><span class="line">print(x.grad)</span><br><span class="line">print(w.grad)</span><br><span class="line">print(b.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor(2.)tensor(1.)tensor(1.)</code></pre><h4 id="来解释一样2，1，1这三个数是怎么来的，首先y-2x-3，那么对于x求梯度（也就是求导）结果为2，以此类推。"><a href="#来解释一样2，1，1这三个数是怎么来的，首先y-2x-3，那么对于x求梯度（也就是求导）结果为2，以此类推。" class="headerlink" title="来解释一样2，1，1这三个数是怎么来的，首先y=2x+3，那么对于x求梯度（也就是求导）结果为2，以此类推。"></a>来解释一样2，1，1这三个数是怎么来的，首先y=2x+3，那么对于x求梯度（也就是求导）结果为2，以此类推。</h4><ul><li>基本的自动求导 例子2</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个 shape(10,3)和(10,2)的张量tensors</span></span><br><span class="line">x=torch.randn(<span class="number">10</span>,<span class="number">3</span>)</span><br><span class="line">y=torch.randn(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个全连接层</span></span><br><span class="line">linear=nn.Linear(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'w:'</span>,linear.weight)</span><br><span class="line">print(<span class="string">'b:'</span>,linear.bias)</span><br></pre></td></tr></table></figure><pre><code>w: Parameter containing:tensor([[-0.1955,  0.2712,  0.5710],        [-0.3143, -0.5540,  0.3058]], requires_grad=True)b: Parameter containing:tensor([-0.2155, -0.1076], requires_grad=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#建立一个损失函数和优化器</span></span><br><span class="line">criterion=nn.MSELoss()</span><br><span class="line">optimizer=torch.optim.SGD(linear.parameters(),lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#前向传播</span></span><br><span class="line">pred=linear(x)</span><br><span class="line"><span class="comment">#计算损失</span></span><br><span class="line">loss=criterion(pre,y)</span><br><span class="line"><span class="comment">#加上item()，就可以转换python中的float型数值</span></span><br><span class="line">print(<span class="string">'loss:'</span>,loss.item())</span><br></pre></td></tr></table></figure><pre><code>loss: 0.9739418625831604</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="comment">#打印输出梯度</span></span><br><span class="line">print(<span class="string">'dl/dw:'</span>,linear.weight.grad)</span><br><span class="line">print(<span class="string">'dl/db:'</span>,linear.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>dl/dw: tensor([[ 0.0576,  0.1626,  0.4199],        [-0.1823, -0.3512,  0.5736]])dl/db: tensor([0.1189, 0.1488])</code></pre><ul><li>optimizer.step()这个方法会更新所有的参数。一旦梯度被如backward()之类的函数计算好后，我们就可以调用这个函数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接着进行梯度下降</span></span><br><span class="line">optimizer.step()</span><br><span class="line"><span class="comment">#打印输出在一次梯度下降优化后的损失</span></span><br><span class="line">pred=linear(x)</span><br><span class="line">loss=criterion(pred,y)</span><br><span class="line">print(<span class="string">'loss after 1 step optimization:'</span>,loss.item())</span><br></pre></td></tr></table></figure><pre><code>loss after 1 step optimization: 0.9595106840133667</code></pre><h4 id="从numpy中加载数据"><a href="#从numpy中加载数据" class="headerlink" title="从numpy中加载数据"></a>从numpy中加载数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先创建一个numpy数组</span></span><br><span class="line">x=np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#将numpy数组转换成torch tensor（torch中的张量）</span></span><br><span class="line">y=torch.from_numpy(x)</span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#再将torch tensor转换成numpy数组</span></span><br><span class="line">z=y.numpy()</span><br><span class="line">print(z)</span><br></pre></td></tr></table></figure><pre><code>tensor([[1, 2],        [3, 4]], dtype=torch.int32)[[1 2] [3 4]]</code></pre><h4 id="定义数据输入流水线（类似于keras中加载数据集的意味）"><a href="#定义数据输入流水线（类似于keras中加载数据集的意味）" class="headerlink" title="定义数据输入流水线（类似于keras中加载数据集的意味）"></a>定义数据输入流水线（类似于keras中加载数据集的意味）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载和创建CIFAR10数据集</span></span><br><span class="line">train_dataset=torchvision.datasets.CIFAR10(root=<span class="string">'./data/'</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取一个数据对(图像和标签)（从磁盘中读取数据）</span></span><br><span class="line">image,label=train_dataset[<span class="number">0</span>]</span><br><span class="line">print(image.size())</span><br><span class="line">print(label)</span><br></pre></td></tr></table></figure><pre><code>Files already downloaded and verifiedtorch.Size([3, 32, 32])6</code></pre><img src="/ck3a6ilg6002bjsg48c7w6s3d/1.jpg" class=""><p> 我们可以看出，图片是彩色图像（3通道），尺寸大小是32x32，标签的索引为6，我们知道cifar10：它有如下10个类别:(’airplane’,’automobile’,’bird’,’cat’,’deer’,’dog’,’frog’,’horse’,’ship’,’truck’)，猜测这个6就应该是frog青蛙。嘿，果然他就是！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个显示图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(img)</span>:</span></span><br><span class="line">    img=img/<span class="number">2</span>+<span class="number">0.5</span></span><br><span class="line">    npimg=img.numpy()</span><br><span class="line">    <span class="comment">#transpose对换数组的维度</span></span><br><span class="line">    plt.imshow(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">    print(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)).shape)</span><br><span class="line">    plt.show();</span><br><span class="line"></span><br><span class="line">imshow(image)</span><br></pre></td></tr></table></figure><pre><code>(32, 32, 3)</code></pre><p>这个<code>img=img/2+0.5</code>就是对图像灰度做了点修正，然后transpose对换数组的维度，我们看啊，从数据集中读取的image，它的格式是(3,32,32)，而plt中要显示的图片，它的格式是(32,32,3)所以，要使用这个函数，将图片转换成我们能识别的格式，终于找到原因了= =！~</p><h4 id="数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）"><a href="#数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）" class="headerlink" title="数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）"></a>数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#当迭代器开始的时候，队列和线程就会从文件中加载数据</span></span><br><span class="line">data_iter=iter(train_loader)</span><br><span class="line"></span><br><span class="line"><span class="comment">#mini-batch的images和labels</span></span><br><span class="line">images,labels=data_iter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据加载器的实际使用方法如下</span></span><br><span class="line"><span class="keyword">for</span> images,labels <span class="keyword">in</span> train_loader:</span><br><span class="line">    <span class="comment">#训练代码写在这里</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="为自定义的数据集设计数据输入流水线"><a href="#为自定义的数据集设计数据输入流水线" class="headerlink" title="为自定义的数据集设计数据输入流水线"></a>为自定义的数据集设计数据输入流水线</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先创建自定义的数据集</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span><span class="params">(torch.utils.data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#To do</span></span><br><span class="line">        <span class="comment">#初始化你的文件路径和文件名列表</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        <span class="comment">#To do</span></span><br><span class="line">        <span class="comment">#首先从文件中取一个数据（举个例子：using numpy.fromfile, PIL.Image.open（打开一个图像文件））</span></span><br><span class="line">        <span class="comment">#接着对数据进行预处理（举个例子：torchvision.Transform）</span></span><br><span class="line">        <span class="comment">#PIL：Python Imaging Library，已经是Python平台事实上的图像处理标准库了。</span></span><br><span class="line">        <span class="comment">#torchvision.Transform对PIL.Image进行变换</span></span><br><span class="line">        <span class="comment">#最后返回一个数据对（image和label）</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#应该将数据集的总大小更改为0，意思就是全部训练完成</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#然后你就可以使用提前创建好的数据加载器</span></span><br><span class="line">custom_dataset=CustomDataset()</span><br><span class="line">train_loader=torch.utils.data.DataLoader(dataset=custom_dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载和加载提前训练好的ResNet-18</span></span><br><span class="line">resnet=torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果你只想微调模型的顶层，可以按照下面设置</span></span><br><span class="line"><span class="keyword">for</span> parm <span class="keyword">in</span> resnet.parameters():</span><br><span class="line">    parm.requires_grad=<span class="literal">False</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#更换顶层进行微调(将原先resnet的全连接层的输入样本大小改为100)</span></span><br><span class="line">resnet.fc=nn.Linear(resnet.fc.in_features,<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#forward省略</span></span><br><span class="line"></span><br><span class="line">images=torch.randn(<span class="number">64</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">outputs=resnet(images)</span><br><span class="line">print(outputs.size())</span><br></pre></td></tr></table></figure><pre><code>Downloading: &quot;https://download.pytorch.org/models/resnet18-5c106cde.pth&quot; to C:\Users\user/.cache\torch\checkpoints\resnet18-5c106cde.pth100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:29&lt;00:00, 1.59MB/s]torch.Size([64, 100])</code></pre><h4 id="保存和加载模型"><a href="#保存和加载模型" class="headerlink" title="保存和加载模型"></a>保存和加载模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存和加载完整的模型</span></span><br><span class="line">torch.save(resnet,<span class="string">'model.ckpt'</span>)</span><br><span class="line">model=torch.load(<span class="string">'model.ckpt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#只保存和加载模型的权重参数（推荐！）</span></span><br><span class="line">torch.save(resnet.state_dict(),<span class="string">'params.ckpt'</span>)</span><br><span class="line">resnet.load_state_dict(torch.load(<span class="string">'params.ckpt'</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;All keys matched successfully&gt;</code></pre><ul><li>state_dict() 以dict返回optimizer的状态。它包含两项。<ul><li>state 一个保存了当前优化状态的dict。optimizer的类别不同，state的内容也会不同。</li><li>param_groups  一个包含了全部参数组的dict。</li></ul></li></ul><h3 id="线性回归练习"><a href="#线性回归练习" class="headerlink" title="线性回归练习"></a>线性回归练习</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的"><a href="#设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的" class="headerlink" title="设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)"></a>设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input_size=<span class="number">1</span></span><br><span class="line">output_size=<span class="number">1</span></span><br><span class="line">num_epochs=<span class="number">60</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#准备数据集Toy dataset（玩具数据集，小数据集，缺乏实验研究，先这样理解，自己玩的数据集（自定义）= =）</span></span><br><span class="line"><span class="comment"># Toy dataset</span></span><br><span class="line">x_train = np.array([[<span class="number">3.3</span>], [<span class="number">4.4</span>], [<span class="number">5.5</span>], [<span class="number">6.71</span>], [<span class="number">6.93</span>], [<span class="number">4.168</span>], </span><br><span class="line">                    [<span class="number">9.779</span>], [<span class="number">6.182</span>], [<span class="number">7.59</span>], [<span class="number">2.167</span>], [<span class="number">7.042</span>], </span><br><span class="line">                    [<span class="number">10.791</span>], [<span class="number">5.313</span>], [<span class="number">7.997</span>], [<span class="number">3.1</span>]], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">y_train = np.array([[<span class="number">1.7</span>], [<span class="number">2.76</span>], [<span class="number">2.09</span>], [<span class="number">3.19</span>], [<span class="number">1.694</span>], [<span class="number">1.573</span>], </span><br><span class="line">                    [<span class="number">3.366</span>], [<span class="number">2.596</span>], [<span class="number">2.53</span>], [<span class="number">1.221</span>], [<span class="number">2.827</span>], </span><br><span class="line">                    [<span class="number">3.465</span>], [<span class="number">1.65</span>], [<span class="number">2.904</span>], [<span class="number">1.3</span>]], dtype=np.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#线性回归的模型,这里输入输出都是一维的，标量，也就是全连接层</span></span><br><span class="line">model=nn.Linear(input_size,output_size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和优化器</span></span><br><span class="line">criterion=nn.MSELoss()</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="comment">#将numpy数组转换成torch tensors</span></span><br><span class="line">    inputs=torch.from_numpy(x_train)</span><br><span class="line">    targets=torch.from_numpy(y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#前向传播</span></span><br><span class="line">    outputs=model(inputs)</span><br><span class="line">    loss=criterion(outputs,targets)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#反向传播和优化</span></span><br><span class="line">    <span class="comment">#zero_grad()将module中的所有模型参数的梯度设置为0.</span></span><br><span class="line">    <span class="comment">#将所有参数的梯度缓存清零,然后进行反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">5</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;],Loss:&#123;:.4f&#125;'</span>.format(epoch+<span class="number">1</span>,num_epochs,loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制图表</span></span><br><span class="line"><span class="comment">#这里如果不加detach()的话，会报错：</span></span><br><span class="line"><span class="comment">#Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.</span></span><br><span class="line"><span class="comment">#无法在需要grad的Variable上调用numpy()。 请改用var.detach().numpy()</span></span><br><span class="line"><span class="comment">#detach()的作用就是不带梯度，返回一个从当前图中分离下来的新的Variable，返回的Variable的requires_grad=False。</span></span><br><span class="line">predicted=model(torch.from_numpy(x_train)).detach().numpy()</span><br><span class="line">plt.plot(x_train,y_train,<span class="string">'ro'</span>,label=<span class="string">'Original data'</span>)</span><br><span class="line">plt.plot(x_train,predicted,label=<span class="string">'Fitted line'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型的权重（推荐，不推荐直接保存网络）</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'linear.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>Epoch [5/60],Loss:10.8415Epoch [10/60],Loss:4.5517Epoch [15/60],Loss:2.0035Epoch [20/60],Loss:0.9710Epoch [25/60],Loss:0.5526Epoch [30/60],Loss:0.3829Epoch [35/60],Loss:0.3140Epoch [40/60],Loss:0.2860Epoch [45/60],Loss:0.2745Epoch [50/60],Loss:0.2696Epoch [55/60],Loss:0.2675Epoch [60/60],Loss:0.2665</code></pre><img src="/ck3a6ilg6002bjsg48c7w6s3d/2.jpg" class=""><h3 id="逻辑回归练习"><a href="#逻辑回归练习" class="headerlink" title="逻辑回归练习"></a>逻辑回归练习</h3><h4 id="设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的-1"><a href="#设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的-1" class="headerlink" title="设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)"></a>设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input_size=<span class="number">784</span></span><br><span class="line">num_classes=<span class="number">10</span></span><br><span class="line">num_epochs=<span class="number">5</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br></pre></td></tr></table></figure><h4 id="经典的手写数字识别，MNIST数据集（images，labels）"><a href="#经典的手写数字识别，MNIST数据集（images，labels）" class="headerlink" title="经典的手写数字识别，MNIST数据集（images，labels）"></a>经典的手写数字识别，MNIST数据集（images，labels）</h4><ul><li>这里测试集就不需要<code>download=True</code>了，因为经查看文件夹，发现MNIST训练集和测试集在一个包里= =~</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dateset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br></pre></td></tr></table></figure><h4 id="数据加载-设计数据输入流水线"><a href="#数据加载-设计数据输入流水线" class="headerlink" title="数据加载(设计数据输入流水线)"></a>数据加载(设计数据输入流水线)</h4><ul><li>shuffle设置为True时会在每个epoch重新打乱数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_loader=torch.utils.data.DataLoader(dataset=train_dateset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="逻辑回归的模型"><a href="#逻辑回归的模型" class="headerlink" title="逻辑回归的模型"></a>逻辑回归的模型</h4><ul><li><p>这里有必要再介绍一下MNIST数据集，因为你要搞懂输入大小和输出大小的设定是怎么来的</p><ul><li><p>MNIST共有7万张图片。其中6万张用于训练神经网络，1万张用于测试神经网络。</p></li><li><p>每张图片是一个28*28像素点的0~9的手写数字图片。</p></li><li><p>黑底白字。黑底用0表示，白字用0~1之间的浮点数表示，越接近1，颜色越白。</p></li><li><p>我们把784个像素点组成一个长度为784的一维数组，这个一维数据就是我们要喂入神经网络的输入特征。MNIST数据集还提供了每张图片对应的标签，以一个长度为10的一维数组给出。</p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model=nn.Linear(input_size,num_classes)</span><br></pre></td></tr></table></figure><h4 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h4><ul><li>这里我们使用交叉熵来作为损失函数比较好，因为这是一个分类问题，具体原因需要机器学习基础，可能看过，暂时忘了= =！</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#因为我们是按照批量进行训练的，之前设置的batch_size=100,总共有60000张，那么就应该需要600个批次</span></span><br><span class="line">total_step=len(train_loader)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        <span class="comment">#将图片重新设定形状大小，（batch_size,input_size）,多了一维是批量数大小</span></span><br><span class="line">        <span class="comment">#当前的images的大小是28*28*batch_size的，所以再将它们重新变一下形状即可</span></span><br><span class="line">        images=images.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        outputs=model(images)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度置0+反向传播+更新参数</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;'</span>.format(epoch+<span class="number">1</span>, num_epochs, i+<span class="number">1</span>, total_step, loss.item()))</span><br></pre></td></tr></table></figure><pre><code>Epoch [1/5], Step [100/600], Loss: 2.2148Epoch [1/5], Step [200/600], Loss: 2.1090Epoch [1/5], Step [300/600], Loss: 2.0445Epoch [1/5], Step [400/600], Loss: 1.9044Epoch [1/5], Step [500/600], Loss: 1.8223Epoch [1/5], Step [600/600], Loss: 1.7955Epoch [2/5], Step [100/600], Loss: 1.7728Epoch [2/5], Step [200/600], Loss: 1.7020Epoch [2/5], Step [300/600], Loss: 1.6512Epoch [2/5], Step [400/600], Loss: 1.4894Epoch [2/5], Step [500/600], Loss: 1.5539Epoch [2/5], Step [600/600], Loss: 1.4890Epoch [3/5], Step [100/600], Loss: 1.4254Epoch [3/5], Step [200/600], Loss: 1.4015Epoch [3/5], Step [300/600], Loss: 1.4230Epoch [3/5], Step [400/600], Loss: 1.3121Epoch [3/5], Step [500/600], Loss: 1.3245Epoch [3/5], Step [600/600], Loss: 1.3191Epoch [4/5], Step [100/600], Loss: 1.2653Epoch [4/5], Step [200/600], Loss: 1.1637Epoch [4/5], Step [300/600], Loss: 1.2509Epoch [4/5], Step [400/600], Loss: 1.1195Epoch [4/5], Step [500/600], Loss: 1.1106Epoch [4/5], Step [600/600], Loss: 1.1059Epoch [5/5], Step [100/600], Loss: 1.1150Epoch [5/5], Step [200/600], Loss: 1.0129Epoch [5/5], Step [300/600], Loss: 1.0519Epoch [5/5], Step [400/600], Loss: 1.0661Epoch [5/5], Step [500/600], Loss: 0.9755Epoch [5/5], Step [600/600], Loss: 1.0962</code></pre><h4 id="测试模型并保存模型"><a href="#测试模型并保存模型" class="headerlink" title="测试模型并保存模型"></a>测试模型并保存模型</h4><ul><li>这里需要注意的是，在测试阶段，我们不需要再次计算梯度了（为了提高内存的效率= =！）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试模型</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    correct=<span class="number">0</span></span><br><span class="line">    total=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        <span class="comment">#print(labels.size(0)),其值就是100，也就是我们设置的批量大小</span></span><br><span class="line">        images=images.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        outputs=model(images)</span><br><span class="line">        _,predicted=torch.max(outputs.data,<span class="number">1</span>)</span><br><span class="line">        total+=labels.size(<span class="number">0</span>)</span><br><span class="line">        correct+=(predicted==labels).sum()</span><br><span class="line">        </span><br><span class="line">    print(<span class="string">'Accuracy of the model on the 10000 test images: &#123;&#125; %'</span>.format(<span class="number">100</span> * correct / total))</span><br><span class="line">    </span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'logistic.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the model on the 10000 test images: 82 %</code></pre><ul><li>没有用CNN，得到的这个效果其实还可以</li></ul><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>PyTorch使用的流程：</p><ul><li>第一步：通常是设置一些超参数（例如输入大小、如果是分类问题：可能有类别数目、训练轮次，批量大小，学习率）</li><li>第二步：加载数据集（有的是PyTorch中封装好的，也有是自定义的，具体问题具体分析）<ul><li>训练数据集</li><li>测试训练集</li></ul></li><li>第三步：定义数据加载器（设计数据输入流水线）</li><li>第四步：建立模型，复杂一点的就是创建自定义网络模型</li><li>第五步：定义损失函数和优化器<ul><li>回归一般用MSE（均方误差）</li><li>分类问题一般用CrossEntropyLoss（交叉熵）</li></ul></li><li>第六步：训练模型<ul><li>外部循环是训练轮次</li><li>内部循环如果有，一般是数据集很大，我们分成了很多批次，每次按照批次大小训练</li><li>训练的步骤一般是：如果是批量输入，考虑是否要给数据改变形状-&gt;前向传播-&gt;计算损失-&gt;优化器梯度置0-&gt;反向传播-&gt;更新所有参数</li></ul></li><li>第七步：测试模型（在测试阶段不需要计算梯度，使用<code>with torch.no_grad()</code>）</li><li>第八步：保存模型，推荐只保存模型的权重</li></ul><h3 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h3><p>在这个教程里,我们将学习如何使用数据并行(DataParallel)来使用多GPU。</p><p>PyTorch非常容易的就可以使用GPU,你可以用如下方式把一个模型放到GPU上:</p><p><code>device = torch.device(&quot;cuda:0&quot;)</code></p><p><code>model.to(device)</code></p><p>然后你可以复制所有的张量到GPU上:</p><p><code>mytensor = my_tensor.to(device)</code></p><p>请注意,只调用<code>mytensor.gpu()</code>并没有复制张量到GPU上。你需要把它赋值给一个新的张量并在GPU上使用这个张量。</p><p>在多GPU上执行前向和反向传播是自然而然的事。然而，<strong>PyTorch默认将只是用一个GPU</strong>。你可以使用DataParallel让模型并行运行来轻易的让你的操作在多个GPU上运行。</p><p><code>model = nn.DataParallel(model)</code></p><p>这是这篇教程背后的核心，我们接下来将更详细的介绍它</p><h4 id="导入PyTorch模块和定义参数"><a href="#导入PyTorch模块和定义参数" class="headerlink" title="导入PyTorch模块和定义参数"></a>导入PyTorch模块和定义参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义参数</span></span><br><span class="line">input_size=<span class="number">5</span></span><br><span class="line">output_size=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">30</span></span><br><span class="line">data_size=<span class="number">100</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设备</span></span><br><span class="line">device=torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">print(device)</span><br><span class="line">print(torch.cuda.device_count())</span><br><span class="line">print(torch.cuda.current_device())</span><br><span class="line">print(torch.cuda.get_device_name(<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>cuda:010GeForce GTX 950M</code></pre><h4 id="虚拟数据集"><a href="#虚拟数据集" class="headerlink" title="虚拟数据集"></a>虚拟数据集</h4><p>制作一个虚拟（随机）数据集，你只需实现<strong>getitem</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,size,length)</span>:</span></span><br><span class="line">        self.len=length</span><br><span class="line">        <span class="comment">#randn返回一个张量，从标准正态分布（均值为0，方差为1）中抽取的一组随机数。</span></span><br><span class="line">        <span class="comment">#length--整数序列，定义了输出张量的形状</span></span><br><span class="line">        <span class="comment">#size--输出张量的形状</span></span><br><span class="line">        self.data=torch.randn(length,size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data[index]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.len</span><br><span class="line">    </span><br><span class="line">rand_loader=DataLoader(dataset=RandomDataset(input_size,data_size),batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="简单的模型"><a href="#简单的模型" class="headerlink" title="简单的模型"></a>简单的模型</h4><p>作为演示，我们的模型只接受一个输入，执行一个线性操作，然后得到结果。然而，你能在任何模型（CNN，RNN，Capsule Net等）上使用DataParallel。</p><p>我们在模型内部放置了一条打印语句来检测输入和输出向量的大小。请注意批等级为0时打印的内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_size,output_size)</span>:</span></span><br><span class="line">        <span class="comment">#这句话官方就是这么写，规定好了,继承Module的初始化函数</span></span><br><span class="line">        super(Model,self).__init__()</span><br><span class="line">        self.fc=nn.Linear(input_size,output_size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=self.fc(input)</span><br><span class="line">        print(<span class="string">"\tIn Model: input size"</span>, input.size(),<span class="string">"output size"</span>, output.size())</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><h4 id="创建一个模型和数据并行"><a href="#创建一个模型和数据并行" class="headerlink" title="创建一个模型和数据并行"></a>创建一个模型和数据并行</h4><p>这是本教程的核心部分。首先，我们需要创建一个模型实例和检测我们是否有多个GPU。如果我们有多个GPU，我们使用nn.DataParallel来包装我们的模型。然后通过model.to(device)把模型放到GPU上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model=Model(input_size,output_size)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count()&gt;<span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"let's use"</span>,torch.cuda.device_count(),<span class="string">"GPUs!"</span>)</span><br><span class="line">    </span><br><span class="line">    model=nn.DataParallel(model)</span><br><span class="line">    </span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><pre><code>Model(  (fc): Linear(in_features=5, out_features=2, bias=True))</code></pre><h4 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h4><p>现在我们可以看看输入和输出张量的大小</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input=data.to(device)</span><br><span class="line">    output=model(input)</span><br><span class="line">    print(<span class="string">"outside: input size"</span>,input_size,<span class="string">"output size"</span>,output_size)</span><br></pre></td></tr></table></figure><pre><code>    In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])outside: input size 5 output size 2    In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])outside: input size 5 output size 2    In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])outside: input size 5 output size 2    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])outside: input size 5 output size 2</code></pre><h4 id="但是，我只有一个GPU-！"><a href="#但是，我只有一个GPU-！" class="headerlink" title="但是，我只有一个GPU = =！"></a>但是，我只有一个GPU = =！</h4>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;棒子写的教程&quot;&gt;&lt;a href=&quot;#棒子写的教程&quot; class=&quot;headerlink&quot; title=&quot;棒子写的教程&quot;&gt;&lt;/a&gt;棒子写的教程&lt;/h3&gt;&lt;h3 id=&quot;韩国人写的PyTorch教程-真的不错&quot;&gt;&lt;a href=&quot;#韩国人写的PyTorch教程-真的不错&quot; class=&quot;headerlink&quot; title=&quot;韩国人写的PyTorch教程,真的不错&quot;&gt;&lt;/a&gt;韩国人写的PyTorch教程,真的不错&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;这个资源为深度学习研究人员提供了学习PyTorch的教程&lt;/li&gt;
&lt;li&gt;代码大多数模型都使用少于30行代码实现&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Python之进程和线程_2</title>
    <link href="https://cblog.club/ck3a6ilgf002jjsg4d1dx1rgx.html"/>
    <id>https://cblog.club/ck3a6ilgf002jjsg4d1dx1rgx.html</id>
    <published>2019-11-22T06:31:14.000Z</published>
    <updated>2019-11-22T06:49:52.342Z</updated>
    
    <content type="html"><![CDATA[<h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><p>多任务可以由多进程完成，也可以由一个进程内的多线程完成。</p><p>我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。</p><p>由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。</p><a id="more"></a><p>Python的标准库提供了两个模块：<code>_thread</code>和<code>threading</code>，<code>_thread</code>是低级模块，<code>threading</code>是高级模块，对<code>_thread</code>进行了封装。绝大多数情况下，我们只需要使用<code>threading</code>这个高级模块。</p><p>启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#新线程的执行代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">'thread %s is running ...'</span>%threading.current_thread().name)</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="number">5</span> :</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">        print(<span class="string">'thread %s &gt;&gt;&gt; %s'</span>%(threading.current_thread().name,n))</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">'thread %s is ended.'</span>%threading.current_thread().name)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'thread %s is running ...'</span>%threading.current_thread().name)</span><br><span class="line">t=threading.Thread(target=loop,name=<span class="string">'LoopThread'</span>)</span><br><span class="line">t.start()</span><br><span class="line">t.join()</span><br><span class="line">print(<span class="string">'thread %s ended.'</span>%threading.current_thread().name)</span><br><span class="line">thread MainThread <span class="keyword">is</span> running ...</span><br><span class="line">thread LoopThread <span class="keyword">is</span> running ...</span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">1</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">2</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">3</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">4</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">5</span></span><br><span class="line">thread LoopThread <span class="keyword">is</span> ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure><p>由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个<code>current_thread()</code>函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2……</p><h4 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h4><p>多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，<strong>所有变量都由所有线程共享</strong> ，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。</p><p>来看看多个线程同时操作一个变量怎么把内容给改乱了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#假定这是你的银行存款,balance有结余的意思（get了）</span></span><br><span class="line">balance=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_balance</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="comment">#先存款，后取款，结果应为0，在这里的global关键字，定义的一个全局变量，对应于函数外的balance</span></span><br><span class="line">    <span class="keyword">global</span> balance</span><br><span class="line">    balance = balance + n</span><br><span class="line">    balance = balance - n</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_thread</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000000</span>):</span><br><span class="line">        change_balance(n)</span><br><span class="line"></span><br><span class="line">t1=threading.Thread(target=run_thread,name=<span class="string">'t1'</span>,args=(<span class="number">5</span>,))</span><br><span class="line">t2=threading.Thread(target=run_thread,name=<span class="string">'t2'</span>,args=(<span class="number">8</span>,))</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br><span class="line">print(balance)</span><br><span class="line"><span class="number">90</span></span><br></pre></td></tr></table></figure><p>我们定义了一个共享变量balance，初始值为0，并且启动两个线程，先存后取，理论上结果应该为0，但是，由于<strong>线程的调度是由操作系统决定的</strong>，当t1、t2交替执行时，只要<strong>循环次数足够多</strong> ，balance的结果就不一定是0了。</p><p>原因是因为高级语言的一条语句在CPU执行时是若干条语句，即使一个简单的计算： <code>balance = balance + n</code> 也分为两步：</p><ul><li>计算balance + n，存入临时变量中</li><li>将临时变量的值赋给balance 也就是可以看成：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = balance + n</span><br><span class="line">balance = x</span><br></pre></td></tr></table></figure><p>由于x是局部变量，两个线程各自都有自己的x，当代码正常执行时：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">初始值 balance = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">t1: x1 = balance + <span class="number">5</span> <span class="comment"># x1 = 0 + 5 = 5</span></span><br><span class="line">t1: balance = x1     <span class="comment"># balance = 5</span></span><br><span class="line">t1: x1 = balance - <span class="number">5</span> <span class="comment"># x1 = 5 - 5 = 0</span></span><br><span class="line">t1: balance = x1     <span class="comment"># balance = 0</span></span><br><span class="line"></span><br><span class="line">t2: x2 = balance + <span class="number">8</span> <span class="comment"># x2 = 0 + 8 = 8</span></span><br><span class="line">t2: balance = x2     <span class="comment"># balance = 8</span></span><br><span class="line">t2: x2 = balance - <span class="number">8</span> <span class="comment"># x2 = 8 - 8 = 0</span></span><br><span class="line">t2: balance = x2     <span class="comment"># balance = 0</span></span><br><span class="line">    </span><br><span class="line">结果 balance = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>但是t1和t2是交替运行的，如果操作系统是以下面的顺序执行的话：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">初始值 balance = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">t1: x1 = balance + <span class="number">5</span>  <span class="comment"># x1 = 0 + 5 = 5</span></span><br><span class="line"></span><br><span class="line">t2: x2 = balance + <span class="number">8</span>  <span class="comment"># x2 = 0 + 8 = 8</span></span><br><span class="line">t2: balance = x2      <span class="comment"># balance = 8</span></span><br><span class="line"></span><br><span class="line">t1: balance = x1      <span class="comment"># balance = 5</span></span><br><span class="line">t1: x1 = balance - <span class="number">5</span>  <span class="comment"># x1 = 5 - 5 = 0</span></span><br><span class="line">t1: balance = x1      <span class="comment"># balance = 0</span></span><br><span class="line"></span><br><span class="line">t2: x2 = balance - <span class="number">8</span>  <span class="comment"># x2 = 0 - 8 = -8</span></span><br><span class="line">t2: balance = x2   <span class="comment"># balance = -8</span></span><br><span class="line"></span><br><span class="line">结果 balance = <span class="number">-8</span></span><br></pre></td></tr></table></figure><p>究其原因，是因为修改balance需要多条语句，而<strong>执行这几条语句时，线程可能中断</strong>，从而导致多个线程把同一个对象的内容改乱了。</p><p>两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以，我们必须确保一个线程在修改balance的时候，别的线程一定不能改。</p><p>如果我们要确保balance计算正确，就要给<code>change_balance()</code>上一把锁，当某个线程开始执行<code>change_balance()</code>时，我们说，该线程因为获得了锁，因此其他线程不能同时执行<code>change_balance()</code>，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁(就是OS相关的互斥)，所以，不会造成修改的冲突。创建一个锁就是通过<code>threading.Lock()</code>来实现：</p><h5 id="增加锁后的代码，运行时间稍微有一点点"><a href="#增加锁后的代码，运行时间稍微有一点点" class="headerlink" title="增加锁后的代码，运行时间稍微有一点点"></a>增加锁后的代码，运行时间稍微有一点点</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#假定这是你的银行存款,balance有结余的意思（get了）</span></span><br><span class="line">balance=<span class="number">0</span></span><br><span class="line"><span class="comment">#创建一个锁</span></span><br><span class="line">lock=threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_balance</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="comment">#先存款，后取款，结果应为0，在这里的global关键字，定义的一个全局变量，对应于函数外的balance</span></span><br><span class="line">    <span class="keyword">global</span> balance</span><br><span class="line">    balance = balance + n</span><br><span class="line">    balance = balance - n</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_thread</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000000</span>):</span><br><span class="line">        <span class="comment">#先要获取锁</span></span><br><span class="line">        lock.acquire()</span><br><span class="line">        <span class="comment">#try/finally语句不管有没有异常，都会执行finally语句</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment">#放心的修改</span></span><br><span class="line">            change_balance(n)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="comment">#改完了一次就释放锁</span></span><br><span class="line">            lock.release()</span><br><span class="line"></span><br><span class="line">t1=threading.Thread(target=run_thread,name=<span class="string">'t1'</span>,args=(<span class="number">5</span>,))</span><br><span class="line">t2=threading.Thread(target=run_thread,name=<span class="string">'t2'</span>,args=(<span class="number">8</span>,))</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br><span class="line">print(balance)</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure><p>当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。</p><p>获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程（饿死）。所以我们用try…finally来确保锁一定会被释放。</p><p>锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，</p><ul><li>首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。</li><li>其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。</li></ul><h4 id="多核CPU"><a href="#多核CPU" class="headerlink" title="多核CPU"></a>多核CPU</h4><p>如果你不幸拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。</p><p>如果写一个死循环的话，会出现什么情况呢？</p><p>打开Mac OS X的Activity Monitor，或者Windows的Task Manager，都可以监控某个进程的CPU使用率。</p><p>我们可以监控到一个死循环线程会100%占用一个CPU。</p><p>如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。</p><p>要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。</p><p>试试用Python写个死循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading,multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">()</span>:</span></span><br><span class="line">    x=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        x=x^<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count()):</span><br><span class="line">    t=threading.Thread(target=loop)</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。</p><p>但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？</p><p>因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个<strong>GIL锁</strong>：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行<strong>100条字节码</strong>，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。</p><p>GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。</p><p>所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。</p><p>不过，也不用过于担心，Python虽然<strong>不能利用多线程实现多核任务，但可以通过多进程实现多核任务</strong>。多个Python进程有各自独立的GIL锁，互不影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">()</span>:</span></span><br><span class="line">    x=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        x=x^<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count()):</span><br><span class="line">    p=multiprocessing.Process(target=loop)</span><br><span class="line">    p.start()</span><br></pre></td></tr></table></figure><p>但是查看Task manager 并没有发现CPU利用率很高= =</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。</p><p>Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。</p><h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><p>在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。</p><p>但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_student</span><span class="params">(name)</span>:</span></span><br><span class="line">    std = Student(name)</span><br><span class="line">    <span class="comment"># std是局部变量，但是每个函数都要用它，因此必须传进去：</span></span><br><span class="line">    do_task_1(std)</span><br><span class="line">    do_task_2(std)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_1</span><span class="params">(std)</span>:</span></span><br><span class="line">    do_subtask_1(std)</span><br><span class="line">    do_subtask_2(std)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_2</span><span class="params">(std)</span>:</span></span><br><span class="line">    do_subtask_2(std)</span><br><span class="line">    do_subtask_2(std)</span><br></pre></td></tr></table></figure><p>每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的Student对象，不能共享。</p><p>如果用一个全局<code>dict</code>存放所有的Student对象，然后以<code>thread</code>自身作为<code>key</code>获得线程对应的Student对象如何？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">global_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">std_thread</span><span class="params">(name)</span>:</span></span><br><span class="line">    std = Student(name)</span><br><span class="line">    <span class="comment"># 把std放到全局变量global_dict中：</span></span><br><span class="line">    global_dict[threading.current_thread()] = std</span><br><span class="line">    do_task_1()</span><br><span class="line">    do_task_2()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 不传入std，而是根据当前线程查找：</span></span><br><span class="line">    std = global_dict[threading.current_thread()]</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 任何函数都可以查找出当前线程的std变量：</span></span><br><span class="line">    std = global_dict[threading.current_thread()]</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>这种方式理论上是可行的，它最大的优点是消除了std对象在每层函数中的传递问题，但是，每个函数获取std的代码有点丑。</p><p>有没有更简单的方式？</p><p>ThreadLocal应运而生，不用查找dict，ThreadLocal帮你自动做这件事：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建全局ThreadLocal对象</span></span><br><span class="line">local_school=threading.local()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_thread</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="comment">#绑定ThreadLocal的student</span></span><br><span class="line">    local_school.student=name</span><br><span class="line">    process_student()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_student</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#获取当前线程关联的student</span></span><br><span class="line">    std=local_school.student</span><br><span class="line">    print(<span class="string">'Hello , %s (in %s)\n'</span>%(std,threading.current_thread().name))</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target=process_thread,args=(<span class="string">'lemon'</span>,),name=<span class="string">'thread-lemon'</span>)</span><br><span class="line">t2 = threading.Thread(target=process_thread,args=(<span class="string">'leocode'</span>,),name=<span class="string">'thread-leocode'</span>)</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br><span class="line">print(<span class="string">'end!'</span>)</span><br><span class="line">Hello , lemon (<span class="keyword">in</span> thread-lemon)</span><br><span class="line"></span><br><span class="line">Hello , leocode (<span class="keyword">in</span> thread-leocode)</span><br><span class="line"></span><br><span class="line">end!</span><br></pre></td></tr></table></figure><p>全局变量<code>local_school</code>就是一个<code>ThreadLocal</code>对象，每个Thread对它都可以读写student属性，但互不影响。你可以把<code>local_school</code>看成全局变量，但每个属性如<code>local_school.student</code>都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。</p><p>可以理解为全局变量<code>local_school</code>是一个dict，不但可以用<code>local_school.student</code>，还可以绑定其他变量，如<code>local_school.teacher</code>等等。</p><p>ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。</p><h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p>一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。</p><h3 id="进程VS线程"><a href="#进程VS线程" class="headerlink" title="进程VS线程"></a>进程VS线程</h3><p>我们介绍了多进程和多线程，这是实现多任务最常用的两种方式。现在，我们来讨论一下这两种方式的优缺点。</p><p>首先，要实现多任务，通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责执行任务，因此，多任务环境下，通常是一个Master，多个Worker。</p><h4 id="简单介绍一下Master-Worker模式："><a href="#简单介绍一下Master-Worker模式：" class="headerlink" title="简单介绍一下Master-Worker模式："></a>简单介绍一下Master-Worker模式：</h4><ul><li>Master-Worker模式是常用的并行设计模式。它的核心思想是，系统有两个进程协议工作：Master进程和Worker进程。Master进程负责接收和分配任务，Worker进程负责处理子任务。当各个Worker进程将子任务处理完后，将结果返回给Master进程，由Master进行归纳和汇总，从而得到系统结果。</li><li><img src="/ck3a6ilgf002jjsg4d1dx1rgx/1.jpg" class=""></li><li>Master-Worker模式的好处是，它能将大任务分解成若干个小任务，并发执行，从而提高系统性能。而对于系统请求者Client来说，任务一旦提交，Master进程就会立刻分配任务并立即返回，并不会等系统处理完全部任务再返回，其处理过程是异步的。</li></ul><h4 id="Master-Worker模式结构"><a href="#Master-Worker模式结构" class="headerlink" title="Master-Worker模式结构"></a>Master-Worker模式结构</h4><ul><li><img src="/ck3a6ilgf002jjsg4d1dx1rgx/2.jpg" class=""></li><li>如上图所示，Master进程是主要进程，它维护着一个Worker进程队列、子任务队列和子结果集，Worker进程中的Worker进程不断的从任务队列中提取要处理的子任务，并将子任务的处理结果放入到子结果集中。</li><li>在上图中，Master：用于任务的分配和最终结果的合并；Worker：用于实际处理一个任务；客户端进程：用于启动系统，调度开启Master。</li></ul><p>如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。</p><p>如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。</p><p>多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。</p><p>多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。</p><p>多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。</p><p>在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式，真是把问题越搞越复杂(= =)。</p><h4 id="线程切换"><a href="#线程切换" class="headerlink" title="线程切换"></a>线程切换</h4><p>无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？</p><p>我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。</p><p>如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为单任务模型，或者批处理任务模型。</p><p>假设你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以幼儿园小朋友的眼光来看，你就正在同时写5科作业。</p><p>但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫<strong>保存现场</strong>），然后，打开数学课本、找出圆规直尺（这叫<strong>准备新环境</strong>），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于<strong>假死状态</strong>。</p><p>所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好。</p><h4 id="计算密集型-vs-IO密集型"><a href="#计算密集型-vs-IO密集型" class="headerlink" title="计算密集型 vs. IO密集型"></a>计算密集型 vs. IO密集型</h4><p>是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和IO密集型。</p><p>计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。</p><p>计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。<strong>对于计算密集型任务，最好用C语言编写</strong>。</p><p>第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。</p><p>IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。<strong>对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差</strong>。</p><h4 id="异步IO"><a href="#异步IO" class="headerlink" title="异步IO"></a>异步IO</h4><p>考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。</p><p>现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用<strong>异步IO编程模型来实现多任务是一个主要的趋势</strong>。</p><p>对应到Python语言，<strong>单线程的异步编程模型称为协程</strong>，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。我们会在后面讨论如何编写协程。</p><h4 id="分布式进程"><a href="#分布式进程" class="headerlink" title="分布式进程"></a>分布式进程</h4><p>在Thread和Process中，应当优选Process，因为Process更稳定，而且，<strong>Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上</strong>。</p><p>Python的<code>multiprocessing</code>模块不但支持多进程，其中<code>managers</code>子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于<code>managers</code>模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。</p><p>举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？</p><p>原有的Queue可以继续使用，但是，通过<code>managers</code>模块<strong>把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了</strong>。</p><p>我们先看服务进程，服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务：</p><ul><li>task_master.py，相当于分布式的主进程</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random,time,queue</span><br><span class="line"><span class="keyword">from</span> multiprocessing.managers <span class="keyword">import</span> BaseManager</span><br><span class="line"></span><br><span class="line"><span class="comment">#发送任务的队列：</span></span><br><span class="line">task_queue=queue.Queue()</span><br><span class="line"><span class="comment">#接收结果的队列</span></span><br><span class="line">result_queue=queue.Queue()</span><br><span class="line"></span><br><span class="line"><span class="comment">#从BaseManager继承的QueueManager</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueueManager</span><span class="params">(BaseManager)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#把两个Queue都注册到网络上，callale参数关联了Queue对象：</span></span><br><span class="line"><span class="comment">#lambda是匿名函数，可以理解为一次函数的执行过程</span></span><br><span class="line">QueueManager.register(<span class="string">'get_task_queue'</span>,callable=<span class="keyword">lambda</span> : task_queue)</span><br><span class="line">QueueManager.register(<span class="string">'get_result_queue'</span>,callable=<span class="keyword">lambda</span> : result_queue)</span><br><span class="line"><span class="comment">#绑定端口5000，设置验证码为'abc'</span></span><br><span class="line">manager=QueueManager(address=(<span class="string">''</span>,<span class="number">5000</span>),authkey=<span class="string">b'abc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动Queue</span></span><br><span class="line">manager.start()</span><br><span class="line"><span class="comment">#获得通过网络访问的Queue对象</span></span><br><span class="line">task=manager.get_task_queue()</span><br><span class="line">result=manager.get_result_queue()</span><br><span class="line"></span><br><span class="line"><span class="comment">#放几个任务进去</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    n=random.randint(<span class="number">0</span>,<span class="number">10000</span>)</span><br><span class="line">    print(<span class="string">'put task %s'</span>%n)</span><br><span class="line">    task.put(n)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从result队列读取结果</span></span><br><span class="line">print(<span class="string">'Try get results'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    r=result.get(timeout=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">'result : %s'</span>%r)</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭</span></span><br><span class="line">manager.shutdown()</span><br><span class="line">print(<span class="string">'master.exit.'</span>)</span><br></pre></td></tr></table></figure><p>请注意，当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。</p><p>然后，在另一台机器上启动任务进程（本机上启动也可以）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,sys,queue</span><br><span class="line"><span class="keyword">from</span> multiprocessing.managers <span class="keyword">import</span> BaseManager</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建类似的QueueManager</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueueManager</span><span class="params">(BaseManager)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#由于这个QueueManager只能从网络上获取Queue，所以注册时只提供名字</span></span><br><span class="line">QueueManager.register(<span class="string">'get_task_queue'</span>)</span><br><span class="line">QueueManager.register(<span class="string">'get_result_queue'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#连接到服务器，也就是运行task_master.py的机器</span></span><br><span class="line">server_addr=<span class="string">'127.0.0.1'</span></span><br><span class="line">print(<span class="string">'Connect to server %s...'</span>%server_addr)</span><br><span class="line"></span><br><span class="line"><span class="comment">#端口和验证码注意保持和task_master.py这只的完全一致</span></span><br><span class="line">m=QueueManager(address=(server_addr,<span class="number">5000</span>),authkey=<span class="string">b'abc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从网络连接</span></span><br><span class="line">m.connect()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取Queue的对象</span></span><br><span class="line">task=m.get_task_queue()</span><br><span class="line">result=m.get_result_queue()</span><br><span class="line"></span><br><span class="line"><span class="comment">#从task任务队列取任务，并把结果写入到result队列</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        n=task.get(timeout=<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'run task %d * %d...'</span>%(n,n))</span><br><span class="line">        r=<span class="string">'%d * %d = %d'</span>%(n,n,n*n)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        result.put(r)</span><br><span class="line">    <span class="keyword">except</span> Queue.Empty:</span><br><span class="line">        print(<span class="string">'task queue is empty.'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#处理结束</span></span><br><span class="line">print(<span class="string">'worker exit.'</span>)</span><br></pre></td></tr></table></figure><p>任务进程要通过网络连接到服务进程，所以要指定服务进程的IP。</p><p>现在，可以试试分布式进程的工作效果了。先启动<code>task_master.py</code>服务进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">liuchuang@ubuntu<span class="number">-4</span>:~/python$ python3 task_master.py</span><br><span class="line">put task <span class="number">4270</span></span><br><span class="line">put task <span class="number">7611</span></span><br><span class="line">put task <span class="number">6983</span></span><br><span class="line">put task <span class="number">2863</span></span><br><span class="line">put task <span class="number">9611</span></span><br><span class="line">put task <span class="number">2283</span></span><br><span class="line">put task <span class="number">3883</span></span><br><span class="line">put task <span class="number">9928</span></span><br><span class="line">put task <span class="number">5946</span></span><br><span class="line">put task <span class="number">7511</span></span><br><span class="line">Try get results</span><br></pre></td></tr></table></figure><p><code>task_master.py</code>进程发送完任务后，开始等待result队列的结果。现在启动<code>task_worker.py</code>进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">liuchuang@ubuntu<span class="number">-4</span>:~/python$ python3 task_worker.py</span><br><span class="line">Connect to server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>...</span><br><span class="line">run task <span class="number">4270</span> * <span class="number">4270.</span>..</span><br><span class="line">run task <span class="number">7611</span> * <span class="number">7611.</span>..</span><br><span class="line">run task <span class="number">6983</span> * <span class="number">6983.</span>..</span><br><span class="line">run task <span class="number">2863</span> * <span class="number">2863.</span>..</span><br><span class="line">run task <span class="number">9611</span> * <span class="number">9611.</span>..</span><br><span class="line">run task <span class="number">2283</span> * <span class="number">2283.</span>..</span><br><span class="line">run task <span class="number">3883</span> * <span class="number">3883.</span>..</span><br><span class="line">run task <span class="number">9928</span> * <span class="number">9928.</span>..</span><br><span class="line">run task <span class="number">5946</span> * <span class="number">5946.</span>..</span><br><span class="line">run task <span class="number">7511</span> * <span class="number">7511.</span>..</span><br><span class="line">worker exit.</span><br></pre></td></tr></table></figure><p><code>task_worker.py</code>进程结束，在<code>task_master.py</code>进程中会继续打印出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">liuchuang@ubuntu<span class="number">-4</span>:~/python$ python3 task_master.py</span><br><span class="line">put task <span class="number">4270</span></span><br><span class="line">put task <span class="number">7611</span></span><br><span class="line">put task <span class="number">6983</span></span><br><span class="line">put task <span class="number">2863</span></span><br><span class="line">put task <span class="number">9611</span></span><br><span class="line">put task <span class="number">2283</span></span><br><span class="line">put task <span class="number">3883</span></span><br><span class="line">put task <span class="number">9928</span></span><br><span class="line">put task <span class="number">5946</span></span><br><span class="line">put task <span class="number">7511</span></span><br><span class="line">Try get results</span><br><span class="line">result : <span class="number">4270</span> * <span class="number">4270</span> = <span class="number">18232900</span></span><br><span class="line">result : <span class="number">7611</span> * <span class="number">7611</span> = <span class="number">57927321</span></span><br><span class="line">result : <span class="number">6983</span> * <span class="number">6983</span> = <span class="number">48762289</span></span><br><span class="line">result : <span class="number">2863</span> * <span class="number">2863</span> = <span class="number">8196769</span></span><br><span class="line">result : <span class="number">9611</span> * <span class="number">9611</span> = <span class="number">92371321</span></span><br><span class="line">result : <span class="number">2283</span> * <span class="number">2283</span> = <span class="number">5212089</span></span><br><span class="line">result : <span class="number">3883</span> * <span class="number">3883</span> = <span class="number">15077689</span></span><br><span class="line">result : <span class="number">9928</span> * <span class="number">9928</span> = <span class="number">98565184</span></span><br><span class="line">result : <span class="number">5946</span> * <span class="number">5946</span> = <span class="number">35354916</span></span><br><span class="line">result : <span class="number">7511</span> * <span class="number">7511</span> = <span class="number">56415121</span></span><br><span class="line">master.exit.</span><br></pre></td></tr></table></figure><p>这个简单的Master/Worker模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个worker，就可以把任务分布到几台甚至几十台机器上，比如把计算<code>n*n</code>的代码换成发送邮件，就实现了邮件队列的异步发送。</p><p>Queue对象存储在哪？注意到task_worker.py中根本没有创建Queue的代码，所以，Queue对象存储在task_master.py进程中： <img src="/ck3a6ilgf002jjsg4d1dx1rgx/3.jpg" class="">而Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，所以，要给每个Queue的网络调用接口起个名字，比如get_task_queue。</p><p>authkey有什么用？这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果task_worker.py的authkey和task_master.py的authkey不一致，肯定连接不上。</p><h4 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h4><p>Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。</p><p>注意Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;多线程&quot;&gt;&lt;a href=&quot;#多线程&quot; class=&quot;headerlink&quot; title=&quot;多线程&quot;&gt;&lt;/a&gt;多线程&lt;/h3&gt;&lt;p&gt;多任务可以由多进程完成，也可以由一个进程内的多线程完成。&lt;/p&gt;
&lt;p&gt;我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。&lt;/p&gt;
&lt;p&gt;由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://cblog.club/categories/Python/"/>
    
      <category term="OS" scheme="https://cblog.club/categories/Python/OS/"/>
    
    
      <category term="Python" scheme="https://cblog.club/tags/Python/"/>
    
      <category term="OS" scheme="https://cblog.club/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch_Day3</title>
    <link href="https://cblog.club/ck3a6ilg20028jsg42ev633r8.html"/>
    <id>https://cblog.club/ck3a6ilg20028jsg42ev633r8.html</id>
    <published>2019-11-21T14:24:18.000Z</published>
    <updated>2019-11-21T14:28:43.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="训练一个分类器"><a href="#训练一个分类器" class="headerlink" title="训练一个分类器"></a>训练一个分类器</h2><p>在了解了如何定义一个神经网络、计算损失值和更新网络的权重之后，那么数据从哪里来呢？</p><p>关于数据<br>通常，当你处理图像，文本，音频和视频数据时，你可以使用标准的Python包来加载数据到一个numpy数组中.然后把这个数组转换成torch.Tensor。</p><a id="more"></a><ul><li>对于图像,有诸如Pillow,OpenCV包等非常实用</li><li>对于音频,有诸如scipy和librosa包</li><li>对于文本,可以用原始Python和Cython来加载,或者使用NLTK和SpaCy </li><li>对于视觉,我们创建了一个torchvision包,包含常见数据集的数据加载,比如Imagenet,CIFAR10,MNIST等,和图像转换器,也就是torchvision.datasets和torch.utils.data.DataLoader。</li></ul><p>在之前，我用keras训练了Cifar10训练集，现在尝试使用PyTorch来训练一个分类器。</p><ul><li>cifar10：它有如下10个类别:’airplane’,’automobile’,’bird’,’cat’,’deer’,’dog’,’frog’,’horse’,’ship’,’truck’。这个数据集中的图像大小为32x32,即,3通道,32x32像素。</li></ul><h4 id="训练一个图像分类器"><a href="#训练一个图像分类器" class="headerlink" title="训练一个图像分类器"></a>训练一个图像分类器</h4><ul><li>使用totchvision加载和归一化Cifar10训练集和测试集</li><li>定义一个卷积神经网络</li><li>定义损失函数</li><li>在训练集上训练网络</li><li>在测试及上测试网络</li></ul><h4 id="加载和归一化cifar10"><a href="#加载和归一化cifar10" class="headerlink" title="加载和归一化cifar10"></a>加载和归一化cifar10</h4><p>使用torchvision加载cifar10是非常容易的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><h4 id="torchvision的输出是-0-1-的PILimage（python中的图像处理库PIL）图像，我们将其转换为-1-1-的张量"><a href="#torchvision的输出是-0-1-的PILimage（python中的图像处理库PIL）图像，我们将其转换为-1-1-的张量" class="headerlink" title="torchvision的输出是[0,1]的PILimage（python中的图像处理库PIL）图像，我们将其转换为[-1,1]的张量"></a>torchvision的输出是[0,1]的PILimage（python中的图像处理库PIL）图像，我们将其转换为[-1,1]的张量</h4><p>transforms.Compose</p><ul><li>将多个transform组合起来使用。</li><li>transforms： 由transform构成的列表</li><li>channel=（channel-mean）/std(因为transforms.ToTensor()已经把数据处理成[0,1],那么(x-0.5)/0.5就是[-1.0, 1.0])</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">transform=transforms.Compose(</span><br><span class="line">    <span class="comment">#前者是均值，后者是标准差</span></span><br><span class="line">    [transforms.ToTensor(),transforms.Normalize((<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>),(<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>))]</span><br><span class="line">)</span><br><span class="line">    </span><br><span class="line">trainset=torchvision.datasets.CIFAR10(root=<span class="string">'/data'</span>,train=<span class="literal">True</span>,download=<span class="literal">False</span>,transform=transform)</span><br><span class="line"><span class="comment">#shuffle 随机排序</span></span><br><span class="line">trainloader=torch.utils.data.DataLoader(trainset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset=torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>,train=<span class="literal">False</span>,download=<span class="literal">False</span>,transform=transform)</span><br><span class="line">testloader=torch.utils.data.DataLoader(testset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">False</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes=(<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>,<span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>)</span><br></pre></td></tr></table></figure><p>展示一些有趣的训练图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个显示图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(img)</span>:</span></span><br><span class="line">    img=img/<span class="number">2</span>+<span class="number">0.5</span></span><br><span class="line">    npimg=img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">    plt.show();</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取一些随机的训练图片</span></span><br><span class="line">dataiter=iter(trainloader)</span><br><span class="line">images,labels=dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出标签</span></span><br><span class="line">print(<span class="string">' '</span>.join(<span class="string">'%11s'</span>%classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><img src="/ck3a6ilg20028jsg42ev633r8/1.png" class=""><pre><code>plane       truck       plane         car</code></pre><h4 id="定义一个卷积神经网络"><a href="#定义一个卷积神经网络" class="headerlink" title="定义一个卷积神经网络"></a>定义一个卷积神经网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net,self).__init__()</span><br><span class="line">        <span class="comment">#输入是三通道的图，然后输出的是6通道的图，采用5x5的卷积框</span></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">6</span>,<span class="number">5</span>)</span><br><span class="line">        <span class="comment">#2x2的最大池化层</span></span><br><span class="line">        self.pool=nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#这里的输入时6通道，因为上边输出的6通道，我们用来接收，最后输出15通道的图，继续采用5x5的卷积框</span></span><br><span class="line">        self.conv2=nn.Conv2d(<span class="number">6</span>,<span class="number">16</span>,<span class="number">5</span>)</span><br><span class="line">        <span class="comment">#定义三个全连接层，对输入数据做线性变换，最后输出图像是120通道数</span></span><br><span class="line">        self.fc1=nn.Linear(<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>,<span class="number">120</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">120</span>,<span class="number">84</span>)</span><br><span class="line">        self.fc3=nn.Linear(<span class="number">84</span>,<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#上边定义的并没有激活</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x=self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x=x.view(<span class="number">-1</span>,<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>)</span><br><span class="line">        x=F.relu(self.fc1(x))</span><br><span class="line">        x=F.relu(self.fc2(x))</span><br><span class="line">        x=self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">net=Net()</span><br></pre></td></tr></table></figure><h4 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h4><ul><li>使用交叉熵作为损失函数</li><li>使用带动量的随机梯度下降</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment">#损失函数标准为交叉熵</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#动量因子momentum</span></span><br><span class="line">optimizer=optim.SGD(net.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h4 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h4><ul><li>这时开始有趣的时刻，我们只需要在数据迭代器上循环，把数据输入给网络并优化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#epoch很熟悉了，这是数据集训练的轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    </span><br><span class="line">    running_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> enumerate(trainloader,<span class="number">0</span>):</span><br><span class="line">        <span class="comment">#获得输入</span></span><br><span class="line">        inputs,labels=data</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度置0</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#forward+backward+optimize</span></span><br><span class="line">        outputs=net(inputs)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#打印统计结果</span></span><br><span class="line">        running_loss+=loss.item()</span><br><span class="line">        <span class="comment">#每2000个为一个小批量，进行打印</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">2000</span>==<span class="number">1999</span>:</span><br><span class="line">            print(<span class="string">'[%d,%5d] loss:%.3f'</span>%(epoch+<span class="number">1</span>,i+<span class="number">1</span>,running_loss/<span class="number">2000</span>))</span><br><span class="line">            running_loss=<span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>[1, 2000] loss:2.112[1, 4000] loss:1.947[1, 6000] loss:1.926[1, 8000] loss:1.899[1,10000] loss:1.930[1,12000] loss:1.905[2, 2000] loss:1.936[2, 4000] loss:1.900[2, 6000] loss:1.932[2, 8000] loss:1.962[2,10000] loss:1.984[2,12000] loss:1.940Finished Training</code></pre><h4 id="在GPU上训练"><a href="#在GPU上训练" class="headerlink" title="在GPU上训练"></a>在GPU上训练</h4><p>你是如何把一个Tensor转换GPU上,你就如何把一个神经网络移动到GPU上训练。这个操作会递归遍历有所模块,并将其参数和缓冲区转换为CUDA张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">print(device)</span><br></pre></td></tr></table></figure><pre><code>cuda:0</code></pre><p>接下来假设我们有一台CUDA的机器，然后这些方法将递归遍历所有模块并将其参数和缓冲区转换为CUDA张量：</p><ul><li>注意优化器我们之前定义过（那是基于没有移动到GPU上的net，所以这里要再定义一次）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net.to(device)</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment">#损失函数标准为交叉熵</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#动量因子momentum</span></span><br><span class="line">optimizer=optim.SGD(net.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>请记住，你也必须在每一步中把你的输入和目标值转换到GPU上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#epoch很熟悉了，这是数据集训练的轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    </span><br><span class="line">    running_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> enumerate(trainloader,<span class="number">0</span>):</span><br><span class="line">        <span class="comment">#获得输入</span></span><br><span class="line">        inputs,labels=data</span><br><span class="line">        inputs=inputs.to(device)</span><br><span class="line">        labels=labels.to(device)</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#梯度置0</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#forward+backward+optimize</span></span><br><span class="line">        outputs=net(inputs)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        loss=loss.to(device)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#打印统计结果</span></span><br><span class="line">        running_loss+=loss.item()</span><br><span class="line">        <span class="comment">#每2000个为一个小批量，进行打印</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">2000</span>==<span class="number">1999</span>:</span><br><span class="line">            print(<span class="string">'[%d,%5d] loss:%.3f'</span>%(epoch+<span class="number">1</span>,i+<span class="number">1</span>,running_loss/<span class="number">2000</span>))</span><br><span class="line">            running_loss=<span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>[1, 2000] loss:1.937[1, 4000] loss:1.940[1, 6000] loss:1.943[1, 8000] loss:1.987[1,10000] loss:2.013[1,12000] loss:1.979[2, 2000] loss:1.950[2, 4000] loss:2.005[2, 6000] loss:1.965[2, 8000] loss:1.974[2,10000] loss:1.970[2,12000] loss:1.962Finished Training</code></pre><h4 id="在测试集上测试网络"><a href="#在测试集上测试网络" class="headerlink" title="在测试集上测试网络"></a>在测试集上测试网络</h4><p>我们在整个训练集上训练了两次网络,但是我们还需要检查网络是否从数据集中学习到东西。</p><p>我们通过预测神经网络输出的类别标签并根据实际情况进行检测，如果预测正确,我们把该样本添加到正确预测列表。</p><p>第一步，显示测试集中的图片一遍熟悉图片内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataiter=iter(testloader)</span><br><span class="line">images,labels=dataiter.next()</span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line">print(<span class="string">'GroundTruth:'</span>,<span class="string">' '</span>.join(<span class="string">'%5s'</span>%classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><h4 id="注意：这里网络和数据都要加cuda-，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。"><a href="#注意：这里网络和数据都要加cuda-，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。" class="headerlink" title="注意：这里网络和数据都要加cuda()，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。"></a>注意：这里网络和数据都要加cuda()，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。</h4><p>现在我们来看看神经网络认为以上图片是什么?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net=net.cuda()</span><br><span class="line">images=images.cuda()</span><br><span class="line">outputs = net(images)</span><br></pre></td></tr></table></figure><p>输出是10个标签的概率。一个类别的概率越大,神经网络越认为他是这个类别。所以让我们得到最高概率的标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">_,predicted=torch.max(outputs.data,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Predicted: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[predicted[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><pre><code>Predicted:    cat   dog   dog horse</code></pre><p>接下来让我们看看网络在整个测试集上的结果如何。</p><ul><li>出现错误’weight’相关的，基本上都是没有将数据放在gpu上，在其后加一个.cuda()即可</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images,labels=data</span><br><span class="line">        net=net.cuda()</span><br><span class="line">        labels=labels.cuda()</span><br><span class="line">        images=images.cuda()</span><br><span class="line">        outputs=net(images)</span><br><span class="line">        _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).sum().item()        </span><br><span class="line">print(<span class="string">'Accuracy of the network on the 10000 test images: %d %%'</span> % (<span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the network on the 10000 test images: 26 %</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class_correct = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line">class_total = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        net=net.cuda()</span><br><span class="line">        labels=labels.cuda()</span><br><span class="line">        images=images.cuda()</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">        c = (predicted == labels).squeeze()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            class_correct[label] += c[i].item()</span><br><span class="line">            class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'Accuracy of %5s : %2d %%'</span> % (</span><br><span class="line">        classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;训练一个分类器&quot;&gt;&lt;a href=&quot;#训练一个分类器&quot; class=&quot;headerlink&quot; title=&quot;训练一个分类器&quot;&gt;&lt;/a&gt;训练一个分类器&lt;/h2&gt;&lt;p&gt;在了解了如何定义一个神经网络、计算损失值和更新网络的权重之后，那么数据从哪里来呢？&lt;/p&gt;
&lt;p&gt;关于数据&lt;br&gt;通常，当你处理图像，文本，音频和视频数据时，你可以使用标准的Python包来加载数据到一个numpy数组中.然后把这个数组转换成torch.Tensor。&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Python之进程和线程</title>
    <link href="https://cblog.club/ck3a6ilgi002mjsg46saoeu4d.html"/>
    <id>https://cblog.club/ck3a6ilgi002mjsg46saoeu4d.html</id>
    <published>2019-11-21T13:24:49.000Z</published>
    <updated>2019-11-21T13:34:41.991Z</updated>
    
    <content type="html"><![CDATA[<p>刚开始学习Python的时候，只是简单的学习了基础的语法和面向对象相关的资料，但是对于进程和线程并没有花时间来看，并且到这一章，和底层实现就密切相关了，和OS更是密不可分，面试非常喜欢问这类的问题，所以还是花点时间来看看，不妨多看看，多找找相关资料，很有帮助，本人是看的廖雪峰的教程，感觉还可以，就是这一章，最好还是在ubuntu环境下跑，因为linux和windows在进程和线程实现细节上有些不同！</p><a id="more"></a><p>很多同学都听说过，现代操作系统比如Mac OS X，UNIX，Linux，Windows等，都是支持“多任务”的操作系统。</p><p>什么叫“多任务”呢？简单地说，就是操作系统可以同时运行多个任务。打个比方，你一边在用浏览器上网，一边在听MP3，一边在用Word赶作业，这就是多任务，至少同时有3个任务正在运行。还有很多任务悄悄地在后台同时运行着，只是桌面上没有显示而已。</p><p>现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是顺序执行的，那么，单核CPU是怎么执行多任务的呢？</p><p>答案就是<strong>操作系统轮流让各个任务交替执行</strong>，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。</p><p>真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。</p><p>对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。</p><p>有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。</p><p>由于每个进程至少要干一件事，所以，一个进程至少有一个线程。当然，像Word这种复杂的进程可以有多个线程，多个线程可以同时执行，多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样。当然，真正地同时执行多线程需要多核CPU才可能实现。</p><p>我们前面编写的所有的Python程序，都是执行单任务的进程，也就是只有一个线程。如果我们要同时执行多个任务怎么办？</p><p>有两种解决方案：</p><ul><li><p>一种是启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。</p></li><li><p>还有一种方法是启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。</p></li><li><p>当然还有第三种方法，就是启动多个进程，每个进程再启动多个线程，这样同时执行的任务就更多了，当然这种模型更复杂，实际很少采用。</p></li></ul><p>总结一下就是，多任务的实现有3种方式：</p><ul><li>多进程模式；</li><li>多线程模式；</li><li>多进程+多线程模式</li></ul><p>同时执行多个任务通常各个任务之间并不是没有关联的，而是需要相互通信和协调，有时，任务1必须暂停等待任务2完成后才能继续执行，有时，任务3和任务4又不能同时执行，所以，多进程和多线程的程序的复杂度要远远高于我们前面写的单进程单线程的程序。</p><p>因为复杂度高，调试困难，所以，不是迫不得已，我们也不想编写多任务。但是，有很多时候，没有多任务还真不行。想想在电脑上看电影，就必须由一个线程播放视频，另一个线程播放音频，否则，单线程实现的话就只能先把视频播放完再播放音频，或者先把音频播放完再播放视频，这显然是不行的。</p><p>Python既支持多进程，又支持多线程，我们会讨论如何编写这两种多任务程序。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>线程是最小的执行单元，而进程由至少一个线程组成。如何调度进程和线程，完全由操作系统决定，程序自己不能决定什么时候执行，执行多长时间。</p><p>多进程和多线程的程序涉及到同步、数据共享的问题，编写起来更复杂。</p><h4 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h4><p>要让Python程序实现多进程（multiprocessing），我们先了解操作系统的相关知识。</p><p>Unix/Linux操作系统提供了一个<code>fork()</code> 系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，<strong>返回两次</strong> ，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。</p><p>子进程永远返回<code>0</code>，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用<code>getppid()</code>就可以拿到父进程的ID。</p><p>Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Process (%s) start...'</span>%os.getpid())</span><br><span class="line">pid=os.fork()</span><br><span class="line"><span class="keyword">if</span> pid == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">'I am child process (%s) and my parent is %s'</span>%(os.getpid(),os.getppid()))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'I (%s) just created a child process (%s)'</span>%(os.getpid(),pid))</span><br></pre></td></tr></table></figure><p>由于Windows没有fork调用，上面的代码在Windows上无法运行。<br>这是我在ubuntu下运行的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Process (96787) start...</span><br><span class="line">I (96787) just created a child process (96788)</span><br><span class="line">I am child process (96788) and my parent is 96787</span><br></pre></td></tr></table></figure><p>有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。</p><h4 id="multiprocessing"><a href="#multiprocessing" class="headerlink" title="multiprocessing"></a>multiprocessing</h4><p>如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？</p><p>由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。</p><p>multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#子进程要做的事情</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_proc</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'Run child process %s (%s)...'</span>%(name,os.getpid()))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'Parent process %s.'</span>%os.getpid())</span><br><span class="line">    p = Process(target=run_proc,args=(<span class="string">'test'</span>,))</span><br><span class="line">    print(<span class="string">'Child process will start.'</span>)</span><br><span class="line">    p.start()</span><br><span class="line">    p.join()</span><br><span class="line">    print(<span class="string">'Child process end.'</span>)</span><br></pre></td></tr></table></figure><pre><code>Parent process 2816.Child process will start.Child process end.</code></pre><p>这是我在ubuntu下运行的结果，不知道windows为什么有问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Parent process 98189.</span><br><span class="line">Child process will start.</span><br><span class="line">Run child process test (98190)...</span><br><span class="line">Child process end.</span><br></pre></td></tr></table></figure><p>创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。</p><p>join()方法可以<strong>等待子进程结束后再继续往下运行</strong> ，通常用于进程间的同步。<br>下面是将<code>p.join()</code>注释掉的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Parent process 98628.</span><br><span class="line">Child process will start.</span><br><span class="line">Child process end.</span><br><span class="line">Run child process test (98629)...</span><br></pre></td></tr></table></figure><h4 id="Pool进程池"><a href="#Pool进程池" class="headerlink" title="Pool进程池"></a>Pool进程池</h4><p>如果要启动大量的子进程，可以用进程池的方式批量创建子进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> os,time,random</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">long_time_rask</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'Run task %s (%s)...'</span> % (name, os.getpid()))</span><br><span class="line">    start=time.time()</span><br><span class="line">    time.sleep(random.random()*<span class="number">3</span>)</span><br><span class="line">    end=time.time()</span><br><span class="line">    print(<span class="string">'Task %s runs %0.2f seconds.'</span> % (name, (end - start)))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'Parent process %s.'</span> % os.getpid())</span><br><span class="line">    p=Pool(<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        p.apply_async(long_time_rask,args=(i,))</span><br><span class="line">    print(<span class="string">'Waiting for all subprocesses done...'</span>)</span><br><span class="line">    p.close()</span><br><span class="line">    p.join()</span><br><span class="line">    print(<span class="string">'All subprocesses done.'</span>)</span><br></pre></td></tr></table></figure><pre><code>Parent process 2816.Waiting for all subprocesses done...</code></pre><p>哎，这一章节真的不能在windows下运行，如上，在windows运行，会卡住，下面是我在ubuntu下运行的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Parent process 99268.</span><br><span class="line">Waiting for all subprocesses done...</span><br><span class="line">Run task 0 (99270)...</span><br><span class="line">Run task 1 (99271)...</span><br><span class="line">Run task 2 (99272)...</span><br><span class="line">Run task 3 (99273)...</span><br><span class="line">Task 0 runs 0.30 seconds.</span><br><span class="line">Run task 4 (99270)...</span><br><span class="line">Task 1 runs 0.37 seconds.</span><br><span class="line">Task 4 runs 0.74 seconds.</span><br><span class="line">Task 2 runs 1.85 seconds.</span><br><span class="line">Task 3 runs 2.58 seconds.</span><br><span class="line">All subprocesses done.</span><br></pre></td></tr></table></figure><p>对Pool对象调用join()方法会等待所有子进程执行完毕，<strong>调用join()之前必须先调用close()</strong> ，调用close()之后就不能继续添加新的Process了。</p><p>请注意输出的结果，task 0，1，2，3是立刻执行的（也就是说同一时刻，这四个进程是同时进行的），而task 4要等待前面某个task完成后才执行（因为前边有四个进程在执行，而我们设定的同时能运行的进程数4，所以只能等待），这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成：<br><code>p = Pool(5)</code>，就可以同时跑5个进程。<br>由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。</p><h4 id="子进程"><a href="#子进程" class="headerlink" title="子进程"></a>子进程</h4><p>很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。</p><p>subprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。</p><p>下面的例子演示了如何在Python代码中运行命令 <code>nslookup www.python.org</code>，这和命令行直接运行的效果是一样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="comment">#nslookup命令用于查询DNS的记录，查看域名解析是否正常，在网络故障的时候用来诊断网络问题</span></span><br><span class="line">print(<span class="string">'$ nslookup www.python.org'</span>)</span><br><span class="line">r=subprocess.call([<span class="string">'nslookup'</span>,<span class="string">'www.python.org'</span>])</span><br><span class="line">print(<span class="string">'exit code:'</span>,r)</span><br></pre></td></tr></table></figure><pre><code>$ nslookup www.python.orgexit code: 0</code></pre><p>这是我在Ubuntu下运行的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup www.python.org</span><br><span class="line">Server:         202.204.48.8</span><br><span class="line">Address:        202.204.48.8#53</span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">www.python.org  canonical name = dualstack.python.map.fastly.net.</span><br><span class="line">Name:   dualstack.python.map.fastly.net</span><br><span class="line">Address: 151.101.24.223</span><br><span class="line"></span><br><span class="line">exit code:</span><br></pre></td></tr></table></figure><p>如果子进程还需要输入，则可以通过communicate()方法输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'$ nslookup'</span>)</span><br><span class="line">p = subprocess.Popen([<span class="string">'nslookup'</span>], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class="line">output,err=p.communicate(<span class="string">b'set q=mx\npython.org\nexit\n'</span>)</span><br><span class="line">print(output.decode(<span class="string">'utf-8'</span>))</span><br><span class="line">print(<span class="string">'exit code:'</span>,p.returncode)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup</span><br><span class="line">Server:         202.204.48.8</span><br><span class="line">Address:        202.204.48.8#53</span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">python.org      mail exchanger = 50 mail.python.org.</span><br><span class="line"></span><br><span class="line">Authoritative answers can be found from:</span><br><span class="line">mail.python.org internet address = 188.166.95.178</span><br><span class="line">mail.python.org has AAAA address 2a03:b0c0:2:d0::71:1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">exit code: 0</span><br></pre></td></tr></table></figure><h3 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h3><p>Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的<code>multiprocessing</code>模块包装了底层的机制，提供了<code>Queue</code>、<code>Pipes</code>等多种方式来交换数据。</p><p>我们以<code>Queue</code>为例，在父进程中创建两个子进程，一个往<code>Queue</code>里写数据，一个从<code>Queue</code>里读数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#写数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(q)</span>:</span></span><br><span class="line">    print(<span class="string">'Process to write: %s'</span> % os.getpid())</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> [<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'D'</span>]:</span><br><span class="line">        print(<span class="string">'Put %s to queue...'</span> % value)</span><br><span class="line">        q.put(value)</span><br><span class="line">        <span class="comment">#有了这一步，有了一定的时间间隔，那么在这个过程中，也是可以读的，如果注释掉，那么ABCD一股脑全部写入</span></span><br><span class="line">        time.sleep(random.random())</span><br><span class="line"></span><br><span class="line"><span class="comment">#读数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(q)</span>:</span></span><br><span class="line">    print(<span class="string">'Process to read: %s '</span> % os.getpid())</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        value=q.get(<span class="literal">True</span>)</span><br><span class="line">        print(<span class="string">'Get %s from queue.'</span> % value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#父进程创建Queue，并传给各个子进程</span></span><br><span class="line">    q=Queue()</span><br><span class="line">    pw=Process(target=write,args=(q,))</span><br><span class="line">    pr=Process(target=read,args=(q,))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#启动子进程pw，写入数据：</span></span><br><span class="line">    pw.start()</span><br><span class="line">    <span class="comment">#启动子进程pr，读出数据：</span></span><br><span class="line">    pr.start()</span><br><span class="line">    <span class="comment">#等待pw结束</span></span><br><span class="line">    pw.join()</span><br><span class="line">    <span class="comment">#pr进程里是死循环，无法等待其结束，只能强行终止：</span></span><br><span class="line">    pr.terminate()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Process to write: 99800</span><br><span class="line">Put A to queue...</span><br><span class="line">Process to read: 99801 </span><br><span class="line">Get A from queue.</span><br><span class="line">Put B to queue...</span><br><span class="line">Get B from queue.</span><br><span class="line">Put C to queue...</span><br><span class="line">Get C from queue.</span><br><span class="line">Put D to queue...</span><br><span class="line">Get D from queue.</span><br></pre></td></tr></table></figure><p>在Unix/Linux下，<code>multiprocessing</code>模块封装了<code>fork()</code>调用，使我们不需要关注<code>fork()</code>的细节。由于Windows没有<code>fork</code>调用，因此，<code>multiprocessing</code>需要“模拟”出fork的效果，父进程所有Python对象都必须通过<code>pickle</code>序列化再传到子进程去，所以，如果<code>multiprocessing</code>在Windows下调用失败了，要先考虑是不是pickle失败了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;刚开始学习Python的时候，只是简单的学习了基础的语法和面向对象相关的资料，但是对于进程和线程并没有花时间来看，并且到这一章，和底层实现就密切相关了，和OS更是密不可分，面试非常喜欢问这类的问题，所以还是花点时间来看看，不妨多看看，多找找相关资料，很有帮助，本人是看的廖雪峰的教程，感觉还可以，就是这一章，最好还是在ubuntu环境下跑，因为linux和windows在进程和线程实现细节上有些不同！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://cblog.club/categories/Python/"/>
    
      <category term="OS" scheme="https://cblog.club/categories/Python/OS/"/>
    
    
      <category term="OS" scheme="https://cblog.club/tags/OS/"/>
    
      <category term="python" scheme="https://cblog.club/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Django项目的自动化测试</title>
    <link href="https://cblog.club/ck3a6ilft0020jsg4f7414tzd.html"/>
    <id>https://cblog.club/ck3a6ilft0020jsg4f7414tzd.html</id>
    <published>2019-11-21T06:13:00.000Z</published>
    <updated>2019-11-21T08:30:10.056Z</updated>
    
    <content type="html"><![CDATA[<p>最近，实验室有个小项目，关于企业上云，然后我们这边要做一个Django的web(已经做了很多功能，需要添加和修改一些功能)，所以要给项目添加一些测试，以备后期更改，自动化测试看的是Django 的官方文档。网址是： <a href="https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/" target="_blank" rel="noopener">https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/</a> 。</p><a id="more"></a><h3 id="自动化测试简介"><a href="#自动化测试简介" class="headerlink" title="自动化测试简介"></a>自动化测试简介</h3><h4 id="自动化测试是什么"><a href="#自动化测试是什么" class="headerlink" title="自动化测试是什么"></a>自动化测试是什么</h4><p>测试，是用来检查代码正确性的一些简单的程序。</p><p>测试在不同的层次中都存在。有些测试只关注某个很小的细节（某个模型的某个方法的返回值是否满足预期？），而另一些测试可能检查对某个软件的一系列操作（<em>某一用户输入序列是否造成了预期的结果？</em>）。其实这和我们在 <a href="https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial02/" target="_blank" rel="noopener">教程第 2 部分</a>，里做的并没有什么不同，我们使用 <a href="https://docs.djangoproject.com/zh-hans/2.2/ref/django-admin/#django-admin-shell" target="_blank" rel="noopener"><code>shell</code></a> 来测试某一方法的功能，或者运行某个应用并输入数据来检查它的行为。</p><p>真正不同的地方在于，<em>自动化</em> 测试是由某个系统帮你自动完成的。当你创建好了一系列测试，每次修改应用代码后，就可以自动检查出修改后的代码是否还像你曾经预期的那样正常工作。你不需要花费大量时间来进行手动测试。</p><h4 id="为什么你需要写测试？"><a href="#为什么你需要写测试？" class="headerlink" title="为什么你需要写测试？"></a>为什么你需要写测试？</h4><p>但是，为什么需要测试呢？又为什么是现在呢？</p><p>你可能觉得学 Python/Django 对你来说已经很满足了，再学一些新东西的话看起来有点负担过重并且没什么必要。毕竟，我们的投票应用（官方文档的一个项目举例）看起来已经完美工作了。写一些自动测试并不能让它工作的更好。如果写一个投票应用是你想用 Django 完成的唯一工作，那你确实没必要学写测试。<strong>但是如果你还想写更复杂的项目，现在就是学习测试写法的最好时机了。</strong></p><ul><li><p>测试将节约你的时间</p><p>在某种程度上，能够「判断出代码是否正常工作」的测试，就称得上是个令人满意的了。在更复杂的应用程序中，组件之间可能会有数十个复杂的交互。</p><p>在更加复杂的应用中，各种组件之间的交互可能会及其的复杂。改变其中某一组件的行为，也有可能会造成意想不到的结果。判断「代码是否正常工作」意味着你需要用大量的数据来完整的测试全部代码的功能，以确保你的小修改没有对应用整体造成破坏——这太费时间了。</p><p>尤其是当你发现自动化测试能在几秒钟之内帮你完成这件事时，就更会觉得手动测试实在是太浪费时间了。当某人写出错误的代码时，自动化测试还能帮助你定位错误代码的位置。</p><p>有时候你会觉得，和富有创造性和生产力的业务代码比起来，编写枯燥的测试代码实在是太无聊了，特别是当你知道你的代码完全没有问题的时候。</p><p><strong>然而，编写测试还是要比花费几个小时手动测试你的应用，或者为了找到某个小错误而胡乱翻看代码要有意义的多。</strong></p></li><li><p>测试不仅能发现错误，还能预防错误</p><p>「测试是开发的对立面」，这种思想是不对的。</p><p>如果没有测试，整个应用的行为意图会变得更加的不清晰。甚至当你在看自己写的代码时也是这样，有时候你需要仔细研读一段代码才能搞清楚它有什么用。</p><p>而测试的出现改变了这种情况。测试就好像是从内部仔细检查你的代码，当有些地方出错时，这些地方将会变得很显眼——<em>就算你自己没有意识到那里写错了</em>。</p></li><li><p>测试使你的代码更有吸引力</p><p>你也许遇到过这种情况：你编写了一个绝赞的软件，但是其他开发者看都不看它一眼，因为它缺少测试。<strong>没有测试的代码不值得信任。</strong> Django 最初开发者之一的 Jacob Kaplan-Moss 说过：“项目规划时没有包含测试是不科学的。”</p><p>其他的开发者希望在正式使用你的代码前看到它通过了测试，这是你需要写测试的另一个重要原因。</p></li><li><p>测试有助于团队协作</p><p>前面的几点都是从单人开发的角度来说的。复杂的应用可能由团队维护。测试的存在保证了协作者不会不小心破坏了了你的代码（也保证你不会不小心弄坏他们的）。如果你想作为一个 Django 程序员谋生的话，你必须擅长编写测试！ </p></li></ul><h4 id="基础测试策略"><a href="#基础测试策略" class="headerlink" title="基础测试策略"></a>基础测试策略</h4><p>有好几种不同的方法可以写测试。</p><p>一些开发者遵循 “<a href="https://en.wikipedia.org/wiki/Test-driven_development" target="_blank" rel="noopener">测试驱动</a>“ 的开发原则，他们在写代码之前先写测试。这种方法看起来有点反直觉，但事实上，这和大多数人日常的做法是相吻合的。我们会先描述一个问题，然后写代码来解决它。「测试驱动」的开发方法只是将问题的描述抽象为了 Python 的测试样例。</p><p>更普遍的情况是，一个刚接触自动化测试的新手更倾向于先写代码，然后再写测试。虽然提前写测试可能更好，但是晚点写起码也比没有强。</p><p>有时候很难决定从哪里开始下手写测试。如果你才写了几千行 Python 代码，选择从哪里开始写测试确实不怎么简单。如果是这种情况，那么在你下次修改代码（比如加新功能，或者修复 Bug）之前写个测试是比较合理且有效的。</p><h4 id="Django中的测试"><a href="#Django中的测试" class="headerlink" title="Django中的测试"></a>Django中的测试</h4><p>随着网站的增长，他们越来越难以手动测试。不仅要进行更多的测试，而且随着组件之间的交互变得越来越复杂，一个区域的小改变可能会影响到其他区域，所以需要做更多的改变来确保一切正常运行，并且在进行更多更改时不会引入错误。减轻这些问题的一种方法是编写自动化测试，每当您进行更改时，都可以轻松可靠地运行测试。</p><p>测试一个 Web 应用是一项复杂的工作，因为 Web 应用包含了多层业务逻辑——从 HTTP 层响应请求，到表单有效性检测和处理，再到模板渲染。利用 Django 的测试执行框架和配套的工具，你可以模拟其你去，插入测试数据，检查应用的输出，以此检验你的代码是否按照期望运行。</p><p>最大的优点是，它非常简单。</p><p>此外，自动化测试可以充当代码的第一个真实“用户”，迫使您严格定义和记录网站的行为方式。它们通常是您的代码示例，和文档的基础。由于这些原因，一些软件开发过程，从测试定义和实现开始，之后编写代码以匹配所需的行为（例如，测试驱动<a href="https://en.wikipedia.org/wiki/Test-driven_development" target="_blank" rel="noopener">test-driven</a> 和行为驱动 <a href="https://en.wikipedia.org/wiki/Behavior-driven_development" target="_blank" rel="noopener">behaviour-driven</a>的开发）。 </p><h4 id="测试的类型"><a href="#测试的类型" class="headerlink" title="测试的类型"></a>测试的类型</h4><ul><li>单元测试<ul><li>验证各个组件的功能行为，通常是类别和功能级别 </li></ul></li><li>回归测试<ul><li>测试重现历史错误。最初运行每个测试，以验证错误是否已修复，然后重新运行，以确保在以后更改代码之后，未重新引入该错误。 （有点像测试后发现错误，然后修改错误，再进行测试的意思）</li></ul></li><li>集成测试<ul><li>验证组件分组在一起使用时的工作方式。集成测试了解组件之间所需的交互，但不一定了解每个组件的内部操作。它们可能涵盖整个网站的简单组件分组。 （这就有点像全部来一次测试，验证各个组件之间是否能够正常运行）</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，实验室有个小项目，关于企业上云，然后我们这边要做一个Django的web(已经做了很多功能，需要添加和修改一些功能)，所以要给项目添加一些测试，以备后期更改，自动化测试看的是Django 的官方文档。网址是： &lt;a href=&quot;https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/&lt;/a&gt; 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Django" scheme="https://cblog.club/categories/Django/"/>
    
      <category term="自动化测试" scheme="https://cblog.club/categories/Django/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="Django" scheme="https://cblog.club/tags/Django/"/>
    
      <category term="自动化测试" scheme="https://cblog.club/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>279完全平方数</title>
    <link href="https://cblog.club/ck3a6ilde000cjsg40kmgdn2s.html"/>
    <id>https://cblog.club/ck3a6ilde000cjsg40kmgdn2s.html</id>
    <published>2019-11-21T03:36:38.000Z</published>
    <updated>2019-11-21T05:48:41.449Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定正整数 <em>n</em>，找到若干个完全平方数（比如 <code>1, 4, 9, 16, ...</code>）使得它们的和等于 <em>n</em>。你需要让组成和的完全平方数的个数最少。 </p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: n = <span class="number">12</span></span><br><span class="line">输出: <span class="number">3</span> </span><br><span class="line">解释: <span class="number">12</span> = <span class="number">4</span> + <span class="number">4</span> + <span class="number">4.</span></span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: n = <span class="number">13</span></span><br><span class="line">输出: <span class="number">2</span></span><br><span class="line">解释: <span class="number">13</span> = <span class="number">4</span> + <span class="number">9.</span></span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。"><a href="#解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。" class="headerlink" title="解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。"></a>解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numSquares</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(n+<span class="number">1</span>,n);</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j*j&lt;=n;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> cur=j*j;</span><br><span class="line">                <span class="keyword">if</span>(i&lt;cur)<span class="keyword">break</span>;</span><br><span class="line">                dp[i]=min(<span class="number">1</span>+dp[i-cur],dp[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定正整数 &lt;em&gt;n&lt;/em&gt;，找到若干个完全平方数（比如 &lt;code&gt;1, 4, 9, 16, ...&lt;/code&gt;）使得它们的和等于 &lt;em&gt;n&lt;/em&gt;。你需要让组成和的完全平方数的个数最少。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>152乘积最大子序列</title>
    <link href="https://cblog.club/ck3a6ilch0006jsg40tqxg5os.html"/>
    <id>https://cblog.club/ck3a6ilch0006jsg40tqxg5os.html</id>
    <published>2019-11-21T03:30:32.000Z</published>
    <updated>2019-11-21T03:35:40.032Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个整数数组 <code>nums</code> ，找出一个序列中乘积最大的连续子序列（该序列至少包含一个数）。 </p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">2</span>,<span class="number">3</span>,<span class="number">-2</span>,<span class="number">4</span>]</span><br><span class="line">输出: <span class="number">6</span></span><br><span class="line">解释: 子数组 [<span class="number">2</span>,<span class="number">3</span>] 有最大乘积 <span class="number">6</span>。</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">-2</span>,<span class="number">0</span>,<span class="number">-1</span>]</span><br><span class="line">输出: <span class="number">0</span></span><br><span class="line">解释: 结果不能为 <span class="number">2</span>, 因为 [<span class="number">-2</span>,<span class="number">-1</span>] 不是子数组。</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp-i-代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。"><a href="#解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp-i-代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。" class="headerlink" title="解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp[i]代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。"></a>解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp[i]代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxProduct</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">int</span> mul_pre,mul_pre2,res,max_temp,min_temp;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp2(size);</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        dp2[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        res=dp[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;size;i++)&#123;</span><br><span class="line">            mul_pre=nums[i]*dp[i<span class="number">-1</span>];</span><br><span class="line">            mul_pre2=nums[i]*dp2[i<span class="number">-1</span>];</span><br><span class="line">            max_temp=max(mul_pre,mul_pre2);</span><br><span class="line">            dp[i]=max(max_temp,nums[i]);</span><br><span class="line">            min_temp=min(mul_pre,mul_pre2);</span><br><span class="line">            dp2[i]=min(min_temp,nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(res&lt;dp[i])res=dp[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个整数数组 &lt;code&gt;nums&lt;/code&gt; ，找出一个序列中乘积最大的连续子序列（该序列至少包含一个数）。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>Python回顾之OOP</title>
    <link href="https://cblog.club/ck3a6ilgr002rjsg489883se9.html"/>
    <id>https://cblog.club/ck3a6ilgr002rjsg489883se9.html</id>
    <published>2019-11-20T14:27:36.000Z</published>
    <updated>2019-11-20T14:28:47.456Z</updated>
    
    <content type="html"><![CDATA[<h3 id="面向对象的两个基本概念"><a href="#面向对象的两个基本概念" class="headerlink" title="面向对象的两个基本概念"></a>面向对象的两个基本概念</h3><p>编程语言中，一般有两种编程思维，面向过程和面向对象。</p><p>面向过程，看重的是解决问题的过程。</p><p>这好比我们解决日常生活问题差不多，分析解决问题的步骤，然后一步一步的解决。</p><p>而面向对象是一种抽象，抽象是指用分类的眼光去看世界的一种方法。</p><a id="more"></a><p>Python 就是一门面向对象的语言,</p><p>如果你学过 Java ，就知道 Java 的编程思想就是：万事万物皆对象。Python 也不例外，在解决实际问题的过程中，可以把构成问题事务分解成各个对象。</p><p>面向对象都有两个基本的概率，分别是类和对象。</p><ul><li><p>类<br>用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。</p></li><li><p>对象<br>通过类定义的数据结构实例</p></li></ul><h3 id="面向对象的三大特性"><a href="#面向对象的三大特性" class="headerlink" title="面向对象的三大特性"></a>面向对象的三大特性</h3><p>面向对象的编程语言，也有三大特性，继承，多态和封装性。</p><ul><li><p>继承<br>即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如：一个 Dog 类型的对象派生自 Animal 类，这是模拟”是一个（is-a）”关系（例图，Dog 是一个 Animal ）。</p></li><li><p>多态<br>它是指对不同类型的变量进行相同的操作，它会根据对象（或类）类型的不同而表现出不同的行为。</p></li><li><p>封装性<br>“封装”就是将抽象得到的数据和行为（或功能）相结合，形成一个有机的整体（即类）；封装的目的是增强安全性和简化编程，使用者不必了解具体的实现细节，而只是要通过外部接口，一特定的访问权限来使用类的成员。</p></li></ul><h4 id="类方法如何调用类属性"><a href="#类方法如何调用类属性" class="headerlink" title="类方法如何调用类属性"></a>类方法如何调用类属性</h4><p>如果没有声明是类方法，方法参数中就没有 cls , 就没法通过 cls 获取到类属性。</p><p>因此类方法，想要调用类属性，需要以下步骤：</p><ul><li>在方法上面，用 @classmethon 声明该方法是类方法。只有声明了是类方法，才能使用类属性</li><li>类方法想要使用类属性，在第一个参数中，需要写上 cls , cls 是 class 的缩写，其实意思就是把这个类作为参数，传给自己，这样就可以使用类属性了。</li><li>类属性的使用方式就是 cls.变量名</li></ul><p>记住，无论是 @classmethon 还是 cls ,都是不能省去的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"name is "</span>+cls.name)</span><br><span class="line"></span><br><span class="line">Person.get_name()</span><br></pre></td></tr></table></figure><pre><code>name is lc</code></pre><h4 id="类方法传参"><a href="#类方法传参" class="headerlink" title="类方法传参"></a>类方法传参</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"name is "</span>+cls.name+str)</span><br><span class="line"></span><br><span class="line">Person.get_name(<span class="string">"1998"</span>)</span><br></pre></td></tr></table></figure><pre><code>name is lc1998</code></pre><h4 id="修改和增加类属性"><a href="#修改和增加类属性" class="headerlink" title="修改和增加类属性"></a>修改和增加类属性</h4><ul><li>从内部增加和修改类属性</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">Person.rename_customize(<span class="string">"lemon"</span>)</span><br></pre></td></tr></table></figure><pre><code>original name is lccurrent name is lemon</code></pre><ul><li>从外部增加和修改类属性</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lc=Person()</span><br><span class="line">print(lc.name)</span><br><span class="line">lc.name=<span class="string">"lc"</span></span><br><span class="line">print(lc.name)</span><br></pre></td></tr></table></figure><pre><code>12lc</code></pre><h3 id="对象的实例化"><a href="#对象的实例化" class="headerlink" title="对象的实例化"></a>对象的实例化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#属性</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"age is "</span>+str(self.age))</span><br><span class="line"></span><br><span class="line">lc=Person()</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 18</code></pre><p>只不过使用 cls 和 self 是我们的编程习惯，这也是我们的编程规范。</p><p>因为 cls 是 class 的缩写，代表这类 ， 而 self 代表这对象的意思。</p><p>所以啊，这里我们实例化对象的时候，就使用 self 。</p><p>而且 self 是所有类方法位于首位、默认的特殊参数。</p><p>除此之外，在这里，还要强调一个概念，当你把类实例化之后，里面的属性和方法，就不叫类属性和类方法了，改为叫实例</p><p>属性和实例方法，也可以叫对象属性和对象方法。</p><h4 id="实例属性和类属性"><a href="#实例属性和类属性" class="headerlink" title="实例属性和类属性"></a>实例属性和类属性</h4><ul><li>发现类属性改变了，实例属性也会改变，因为我们的实例对象就是根据类来复制出来的，类属性改变了，实例对象的属性也会跟着改变。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lemon=Person()</span><br><span class="line">Person.age=<span class="number">19</span></span><br><span class="line">lemon.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 19</code></pre><ul><li>当我们修改实例对象的属性是，类属性是不会改变的,因为每个实例都是单独的个体，不能影响到类的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lemon=Person()</span><br><span class="line">print(Person.age)</span><br><span class="line">lemon.age=<span class="number">19</span></span><br><span class="line">print(Person.age)</span><br></pre></td></tr></table></figure><pre><code>1818</code></pre><h4 id="实例方法和类方法"><a href="#实例方法和类方法" class="headerlink" title="实例方法和类方法"></a>实例方法和类方法</h4><ul><li>如果类方法改变了，实例方法会不会跟着改变呢？答案是肯定</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#属性</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"age is "</span>+str(self.age))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lc=Person()</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 18</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">    print(<span class="string">"age + 1 is "</span>+str(self.age+<span class="number">1</span>))</span><br><span class="line">Person.get_age=new_get_age</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age + 1 is 19</code></pre><p>在这个例子中，我们需要改变类方法，就用到了<strong>类的重写</strong>。</p><p>我们使用了 类.原始函数 = 新函数 就完成类的重写。</p><h4 id="要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是-类-原始函数-新函数-这个写法是不对的。"><a href="#要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是-类-原始函数-新函数-这个写法是不对的。" class="headerlink" title="要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是 类.原始函数() = 新函数() 这个写法是不对的。"></a>要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是 类.原始函数() = 新函数() 这个写法是不对的。</h4><ul><li>那么如果实例方法改变了，类方法会改变吗？答案是肯定不会的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#属性</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"age is "</span>+str(self.age))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(self,str)</span>:</span></span><br><span class="line">        print(<span class="string">"name is "</span>+str)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lc=Person()</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 18</code></pre><h4 id="我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）"><a href="#我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）" class="headerlink" title="我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）"></a>我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_get_name</span><span class="params">(str)</span>:</span></span><br><span class="line">        print(<span class="string">"your name is "</span>+str)</span><br><span class="line">lc.get_name=new_get_name</span><br><span class="line">lc.get_name(<span class="string">"leocode"</span>)</span><br></pre></td></tr></table></figure><pre><code>your name is leocode</code></pre><h4 id="修改实例方法，只对于这一个实例起作用"><a href="#修改实例方法，只对于这一个实例起作用" class="headerlink" title="修改实例方法，只对于这一个实例起作用"></a>修改实例方法，只对于这一个实例起作用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leo=Person()</span><br><span class="line">leo.get_name(<span class="string">"lc"</span>)</span><br></pre></td></tr></table></figure><pre><code>name is lc</code></pre><h3 id="初始化函数（也就是构造函数）"><a href="#初始化函数（也就是构造函数）" class="headerlink" title="初始化函数（也就是构造函数）"></a>初始化函数（也就是构造函数）</h3><ul><li>初始化函数的意思是，当你创建一个实例的时候，这个函数就会被调用。</li><li>当代码在执行 dog=Animals() 的语句时，就自动调用了 _<em>init_</em>(self) 函数。</li><li>而这个 _<em>init_</em>(self) 函数就是初始化函数，也叫构造函数</li><li>构造函数格式：<code>def __init__(self,[参数1，参数2...]):</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"初始化成功！"</span>)</span><br><span class="line">        </span><br><span class="line">dog=Animals()</span><br></pre></td></tr></table></figure><pre><code>初始化成功！</code></pre><h4 id="构造函数也可以传递参数"><a href="#构造函数也可以传递参数" class="headerlink" title="构造函数也可以传递参数"></a>构造函数也可以传递参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,str)</span>:</span></span><br><span class="line">        print(<span class="string">"初始化成功！"</span>+str)</span><br><span class="line">        </span><br><span class="line">dog=Animals(<span class="string">"leocode"</span>)</span><br></pre></td></tr></table></figure><pre><code>初始化成功！leocode</code></pre><h3 id="析构函数（用于销毁实例）"><a href="#析构函数（用于销毁实例）" class="headerlink" title="析构函数（用于销毁实例）"></a>析构函数（用于销毁实例）</h3><ul><li>一个在创建的时候，会调用构造函数，那么理所当然，这个当一个类销毁的时候，就会调用析构函数</li><li>格式：<code>def __del__(self,[参数1，参数2...]):</code></li><li>使用del调用析构函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,str)</span>:</span></span><br><span class="line">        print(<span class="string">"初始化成功！"</span>+str)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__del__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"实例已销毁"</span>)</span><br><span class="line">        </span><br><span class="line">dog=Animals(<span class="string">"leocode"</span>)</span><br><span class="line"><span class="keyword">del</span> dog</span><br></pre></td></tr></table></figure><pre><code>初始化成功！leocode实例已销毁</code></pre><h3 id="类的继承"><a href="#类的继承" class="headerlink" title="类的继承"></a>类的继承</h3><ul><li>定义类的继承</li></ul><p>说到继承，你一定会联想到继承你老爸的家产之类的。</p><p>类的继承也是一样。</p><p>比如有一个旧类，是可以算平均数的。然后这时候有一个新类，也要用到算平均数，那么这时候我们就可以使用继承的方式。新类继承旧类，这样子新类也就有这个功能了。</p><p>通常情况下，我们叫旧类为父类，新类为子类。</p><p>在定义类的时候，可以在括号里写继承的类，如果不用继承类的时候，也要写继承 object 类（也可以不写），因为在 Python 中 object 类是一切类的父类。</p><p>当然上面的是单继承，Python 也是支持多继承的，具体的语法如下：</p><p>多继承有一点需要注意的：若是父类中有相同的方法名，而在子类使用时未指定，python 在圆括号中父类的顺序，从左至右搜索 ， 即方法在子类中未找到时，从左到右查找父类中是否包含方法。</p><p>那么继承的子类可以干什么呢？</p><p>继承的子类的好处：</p><ul><li>会继承父类的属性和方法</li><li>可以自己定义，覆盖父类的属性和方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,kind,name)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self.kind=kind</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"its name is "</span>+self.name)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eat</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.kind+<span class="string">"在吃东西"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(Animals)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,kind,name,age)</span>:</span></span><br><span class="line">        super(Dog,self).__init__(kind,name)</span><br><span class="line">        self.age=age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eat</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.kind+<span class="string">"在吃东西,并且它"</span>+str(self.age)+<span class="string">"岁了"</span>)</span><br><span class="line">dog_a=Dog(<span class="string">"dog"</span>,<span class="string">"dz"</span>,<span class="number">2</span>)</span><br><span class="line">dog_a.get_name()</span><br><span class="line">dog_a.eat()</span><br></pre></td></tr></table></figure><pre><code>its name is dzdog在吃东西,并且它2岁了</code></pre><h4 id="子类的类型判断"><a href="#子类的类型判断" class="headerlink" title="子类的类型判断"></a>子类的类型判断</h4><p>对于 class 的继承关系来说，有些时候我们需要判断 class 的类型，该怎么办呢？</p><p>可以使用 isinstance() 函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span><span class="params">(User1)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User3</span><span class="params">(User2)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">user1=User1()</span><br><span class="line">user2=User2()</span><br><span class="line">user3=User3()</span><br><span class="line"></span><br><span class="line">print(isinstance(user1,User1))</span><br><span class="line">print(isinstance(user2,User1))</span><br><span class="line">print(isinstance(user3,User2))</span><br><span class="line">print(isinstance(<span class="number">1321</span>,str))</span><br><span class="line">print(isinstance(<span class="number">1321</span>,int))</span><br><span class="line">print(type(user1))</span><br></pre></td></tr></table></figure><pre><code>TrueTrueTrueFalseTrue&lt;class &apos;__main__.User1&apos;&gt;</code></pre><ul><li>可以看到 isinstance() 不仅可以告诉我们，一个对象是否是某种类型，也可以用于基本类型的判断</li></ul><h3 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h3><p>多态的概念其实不难理解，它是指对不同类型的变量进行相同的操作，它会根据对象（或类）类型的不同而表现出不同的行为。</p><p>事实上，我们经常用到多态的性质，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;1 + 2</span><br><span class="line">3</span><br><span class="line">&gt;&gt;&gt;&apos;a&apos; + &apos;b&apos;</span><br><span class="line">&apos;ab&apos;</span><br></pre></td></tr></table></figure><p>可以看到，我们对两个整数进行 + 操作，会返回它们的和，对两个字符进行相同的 + 操作，会返回拼接后的字符串。</p><p>也就是说，不同类型的对象对同一消息会作出不同的响应。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,age)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self.age=age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.name+<span class="string">"在工作！他现在"</span>+str(self.age)+<span class="string">"岁！"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,age)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self.age=age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"他现在"</span>+str(self.age)+<span class="string">"岁！"</span>+self.name+<span class="string">"在工作！"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inter_work</span><span class="params">(user)</span>:</span></span><br><span class="line">    user.work()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lc=User1(<span class="string">"lc"</span>,<span class="number">22</span>)</span><br><span class="line">lemon=User2(<span class="string">"lemon"</span>,<span class="number">21</span>)</span><br><span class="line">inter_work(lc)</span><br><span class="line">inter_work(lemon)</span><br></pre></td></tr></table></figure><pre><code>lc在工作！他现在22岁！他现在21岁！lemon在工作！</code></pre><p>可以看到，lc 和 lemon 是两个不同的对象，对它们调用 inter_work 方法，它们会自动调用实际类型的 work 方法，作出不同的响应。这就是多态的魅力。</p><p>要注意喔，有了继承，才有了多态，也会有不同类的对象对同一消息会作出不同的相应。</p><h3 id="类的访问控制"><a href="#类的访问控制" class="headerlink" title="类的访问控制"></a>类的访问控制</h3><ul><li>类属性的访问控制<br>在 Java 中，有 public （公共）属性 和 private （私有）属性，这可以对属性进行访问控制。</li></ul><p>那么在 Python 中有没有属性的访问控制呢？</p><p>一般情况下，我们会使用 __private_attrs 两个下划线开头，声明该属性为私有，不能在类地外部被使用或直接访问。在类内部的方法中使用时 self.__private_attrs。</p><p>为什么只能说一般情况下呢？</p><p>因为实际上， Python 中是没有提供私有属性等功能的。</p><p>但是 Python 对属性的访问控制是靠程序员自觉的。为什么这么说呢？</p><p>看看下面的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserInfo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,age,account)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self._age=age</span><br><span class="line">        self.__account=account</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_account</span><span class="params">(self)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> self.__account</span><br><span class="line">        </span><br><span class="line">userInfo=UserInfo(<span class="string">"leocode"</span>,<span class="number">21</span>,<span class="number">199831</span>)</span><br><span class="line"><span class="comment">#输出所有属性</span></span><br><span class="line">print(dir(userInfo))</span><br><span class="line"><span class="comment">#输出构造函数中的属性</span></span><br><span class="line">print(userInfo.__dict__)</span><br><span class="line"><span class="comment">#用于验证双下划线是否是真正的私有属性</span></span><br><span class="line">print(userInfo._UserInfo__account)</span><br><span class="line">print(userInfo._age)</span><br></pre></td></tr></table></figure><pre><code>[&apos;_UserInfo__account&apos;, &apos;__class__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__getattribute__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__module__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;, &apos;__weakref__&apos;, &apos;_age&apos;, &apos;name&apos;]{&apos;name&apos;: &apos;leocode&apos;, &apos;_age&apos;: 21, &apos;_UserInfo__account&apos;: 199831}19983121</code></pre><h3 id="类专有的方法"><a href="#类专有的方法" class="headerlink" title="类专有的方法"></a>类专有的方法</h3><ul><li>一个类创建的时候，就会包含一些方法</li></ul><h3 id="方法的访问控制"><a href="#方法的访问控制" class="headerlink" title="方法的访问控制"></a>方法的访问控制</h3><ul><li>方法也可以看成类的属性（只是看成），用法是一样的</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;面向对象的两个基本概念&quot;&gt;&lt;a href=&quot;#面向对象的两个基本概念&quot; class=&quot;headerlink&quot; title=&quot;面向对象的两个基本概念&quot;&gt;&lt;/a&gt;面向对象的两个基本概念&lt;/h3&gt;&lt;p&gt;编程语言中，一般有两种编程思维，面向过程和面向对象。&lt;/p&gt;
&lt;p&gt;面向过程，看重的是解决问题的过程。&lt;/p&gt;
&lt;p&gt;这好比我们解决日常生活问题差不多，分析解决问题的步骤，然后一步一步的解决。&lt;/p&gt;
&lt;p&gt;而面向对象是一种抽象，抽象是指用分类的眼光去看世界的一种方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://cblog.club/categories/Python/"/>
    
    
      <category term="Python" scheme="https://cblog.club/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>300最长上升子序列</title>
    <link href="https://cblog.club/ck3a6ildo000djsg48wu2dng8.html"/>
    <id>https://cblog.club/ck3a6ildo000djsg48wu2dng8.html</id>
    <published>2019-11-20T14:13:00.000Z</published>
    <updated>2019-11-21T06:02:54.860Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个无序的整数数组，找到其中最长上升子序列的长度。 </p><a id="more"></a><blockquote><p><strong>示例:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">10</span>,<span class="number">9</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">101</span>,<span class="number">18</span>]</span><br><span class="line">输出: <span class="number">4</span> </span><br><span class="line">解释: 最长的上升子序列是 [<span class="number">2</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">101</span>]，它的长度是 <span class="number">4</span>。</span><br></pre></td></tr></table></figure><p><strong>说明:</strong></p><ul><li>可能会有多种最长上升子序列的组合，你只需要输出对应的长度即可。</li><li>你算法的时间复杂度应该为 O(<em>n2</em>) 。</li></ul><p><strong>进阶:</strong> 你能将算法的时间复杂度降低到 O(<em>n</em> log <em>n</em>) 吗?</p></blockquote><h6 id="解题思路：本题思路不是很难，但是时间复杂度在O-n-2-，想要让时间复杂度降低到-O-n-log-n-，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。"><a href="#解题思路：本题思路不是很难，但是时间复杂度在O-n-2-，想要让时间复杂度降低到-O-n-log-n-，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。" class="headerlink" title="解题思路：本题思路不是很难，但是时间复杂度在O(n^2)，想要让时间复杂度降低到 O(n log n)，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。"></a>解题思路：本题思路不是很难，但是时间复杂度在O(n^2)，想要让时间复杂度降低到 O(<em>n</em> log <em>n</em>)，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> max_val=<span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size,<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;size;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i<span class="number">-1</span>;j&gt;=<span class="number">0</span>;j--)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[j]&lt;nums[i])dp[i]=max(dp[i],dp[j]+<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(max_val&lt;dp[i])max_val=dp[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max_val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h6 id="法二：其实题目规定将算法时间复杂度降到O-nlogn-这就是在提示我们使用二分法，但是这个二分真的很难想，dp-i-代表的是i-1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）"><a href="#法二：其实题目规定将算法时间复杂度降到O-nlogn-这就是在提示我们使用二分法，但是这个二分真的很难想，dp-i-代表的是i-1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）" class="headerlink" title="法二：其实题目规定将算法时间复杂度降到O(nlogn)这就是在提示我们使用二分法，但是这个二分真的很难想，dp[i]代表的是i+1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）"></a>法二：其实题目规定将算法时间复杂度降到O(nlogn)这就是在提示我们使用二分法，但是这个二分真的很难想，dp[i]代表的是i+1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> max_val,cur_max,res;</span><br><span class="line">        max_val=<span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        res=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num:nums)&#123;</span><br><span class="line">            <span class="keyword">int</span> l,r,m;</span><br><span class="line">            l=<span class="number">0</span>;r=res;</span><br><span class="line">            <span class="keyword">while</span>(l&lt;r)&#123;</span><br><span class="line">                m=(r+l)/<span class="number">2</span>;</span><br><span class="line">                <span class="keyword">if</span>(dp[m]&gt;=num)r=m;</span><br><span class="line">                <span class="keyword">else</span> l=m+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            dp[l]=num;</span><br><span class="line">            <span class="keyword">if</span>(res==r)res++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个无序的整数数组，找到其中最长上升子序列的长度。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>62不同路径</title>
    <link href="https://cblog.club/ck3a6ilff001ojsg41xz0b0ek.html"/>
    <id>https://cblog.club/ck3a6ilff001ojsg41xz0b0ek.html</id>
    <published>2019-11-20T14:08:46.000Z</published>
    <updated>2019-11-20T14:12:20.800Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>一个机器人位于一个 <em>m x n</em> 网格的左上角 （起始点在下图中标记为“Start” ）。</p><p>机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。</p><p>问总共有多少条不同的路径？</p><a id="more"></a><blockquote><p><strong>说明：</strong>m 和 <em>n</em> 的值均不超过 100。</p><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入: m = <span class="number">3</span>, n = <span class="number">2</span></span><br><span class="line">输出: <span class="number">3</span></span><br><span class="line">解释:</span><br><span class="line">从左上角开始，总共有 <span class="number">3</span> 条路径可以到达右下角。</span><br><span class="line"><span class="number">1.</span> 向右 -&gt; 向右 -&gt; 向下</span><br><span class="line"><span class="number">2.</span> 向右 -&gt; 向下 -&gt; 向右</span><br><span class="line"><span class="number">3.</span> 向下 -&gt; 向右 -&gt; 向右</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: m = <span class="number">7</span>, n = <span class="number">3</span></span><br><span class="line">输出: <span class="number">28</span></span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）"><a href="#解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）" class="headerlink" title="解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）"></a>解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">uniquePaths</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> dp[m][n];</span><br><span class="line">        <span class="keyword">int</span> i,j;</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>][i]=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(j=<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">                dp[i][j]=dp[i<span class="number">-1</span>][j]+dp[i][j<span class="number">-1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m<span class="number">-1</span>][n<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;一个机器人位于一个 &lt;em&gt;m x n&lt;/em&gt; 网格的左上角 （起始点在下图中标记为“Start” ）。&lt;/p&gt;
&lt;p&gt;机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。&lt;/p&gt;
&lt;p&gt;问总共有多少条不同的路径？&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>55跳跃游戏</title>
    <link href="https://cblog.club/ck3a6ilf6001hjsg4d09b1vyy.html"/>
    <id>https://cblog.club/ck3a6ilf6001hjsg4d09b1vyy.html</id>
    <published>2019-11-20T14:03:59.000Z</published>
    <updated>2019-11-20T14:08:02.392Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>给定一个非负整数数组，你最初位于数组的第一个位置。</p><p>数组中的每个元素代表你在该位置可以跳跃的最大长度。</p><p>判断你是否能够到达最后一个位置。</p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>]</span><br><span class="line">输出: <span class="literal">true</span></span><br><span class="line">解释: 我们可以先跳 <span class="number">1</span> 步，从位置 <span class="number">0</span> 到达 位置 <span class="number">1</span>, 然后再从位置 <span class="number">1</span> 跳 <span class="number">3</span> 步到达最后一个位置。</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">4</span>]</span><br><span class="line">输出: <span class="literal">false</span></span><br><span class="line">解释: 无论怎样，你总会到达索引为 <span class="number">3</span> 的位置。但该位置的最大跳跃长度是 <span class="number">0</span> ， 所以你永远不可能到达最后一个位置。</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题很想走楼梯那一题，思路其实是类似的，dp-i-代表这当前结点能向后走的步数，那么如果他是0，就代表不能向后走，即返回false，状态转移方程为dp-i-max-nums-i-dp-i-1-1"><a href="#解题思路：本题很想走楼梯那一题，思路其实是类似的，dp-i-代表这当前结点能向后走的步数，那么如果他是0，就代表不能向后走，即返回false，状态转移方程为dp-i-max-nums-i-dp-i-1-1" class="headerlink" title="解题思路：本题很想走楼梯那一题，思路其实是类似的，dp[i]代表这当前结点能向后走的步数，那么如果他是0，就代表不能向后走，即返回false，状态转移方程为dp[i]=max(nums[i],dp[i-1]-1)"></a>解题思路：本题很想走楼梯那一题，思路其实是类似的，dp[i]代表这当前结点能向后走的步数，那么如果他是0，就代表不能向后走，即返回false，状态转移方程为dp[i]=max(nums[i],dp[i-1]-1)</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">canJump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">1</span>)<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">if</span>(dp[<span class="number">0</span>]==<span class="number">0</span>)<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;size;i++)&#123;</span><br><span class="line">            dp[i]=max(nums[i],dp[i<span class="number">-1</span>]<span class="number">-1</span>);</span><br><span class="line">            <span class="keyword">if</span>(dp[i]==<span class="number">0</span>&amp;&amp;i!=size<span class="number">-1</span>)<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;给定一个非负整数数组，你最初位于数组的第一个位置。&lt;/p&gt;
&lt;p&gt;数组中的每个元素代表你在该位置可以跳跃的最大长度。&lt;/p&gt;
&lt;p&gt;判断你是否能够到达最后一个位置。&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>198打家劫舍</title>
    <link href="https://cblog.club/ck3a6ilco0008jsg43f6j6avd.html"/>
    <id>https://cblog.club/ck3a6ilco0008jsg43f6j6avd.html</id>
    <published>2019-11-19T12:06:04.000Z</published>
    <updated>2019-11-19T12:17:25.556Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，<strong>如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警</strong>。</p><p>给定一个代表每个房屋存放金额的非负整数数组，计算你<strong>在不触动警报装置的情况下，</strong>能够偷窃到的最高金额。</p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>]</span><br><span class="line">输出: <span class="number">4</span></span><br><span class="line">解释: 偷窃 <span class="number">1</span> 号房屋 (金额 = <span class="number">1</span>) ，然后偷窃 <span class="number">3</span> 号房屋 (金额 = <span class="number">3</span>)。</span><br><span class="line">     偷窃到的最高金额 = <span class="number">1</span> + <span class="number">3</span> = <span class="number">4</span> 。</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">2</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">3</span>,<span class="number">1</span>]</span><br><span class="line">输出: <span class="number">12</span></span><br><span class="line">解释: 偷窃 <span class="number">1</span> 号房屋 (金额 = <span class="number">2</span>), 偷窃 <span class="number">3</span> 号房屋 (金额 = <span class="number">9</span>)，接着偷窃 <span class="number">5</span> 号房屋 (金额 = <span class="number">1</span>)。</span><br><span class="line">     偷窃到的最高金额 = <span class="number">2</span> + <span class="number">9</span> + <span class="number">1</span> = <span class="number">12</span> 。</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题还算是比较简单，仔细分析一下还是能做出来的，状态转移方程dp-i-max-dp-i-2-nums-i-dp-i-3-nums-i-因为要隔着一个，那么就只能考虑这俩个，因为再往前就会影响到其他的房间了（不是相互独立的了），还有就是如果i-3没有的话，就直接选dp-i-2-nums-i-即可。"><a href="#解题思路：本题还算是比较简单，仔细分析一下还是能做出来的，状态转移方程dp-i-max-dp-i-2-nums-i-dp-i-3-nums-i-因为要隔着一个，那么就只能考虑这俩个，因为再往前就会影响到其他的房间了（不是相互独立的了），还有就是如果i-3没有的话，就直接选dp-i-2-nums-i-即可。" class="headerlink" title="解题思路：本题还算是比较简单，仔细分析一下还是能做出来的，状态转移方程dp[i]=max(dp[i-2]+nums[i],dp[i-3]+nums[i]);因为要隔着一个，那么就只能考虑这俩个，因为再往前就会影响到其他的房间了（不是相互独立的了），还有就是如果i-3没有的话，就直接选dp[i-2]+nums[i]即可。"></a>解题思路：本题还算是比较简单，仔细分析一下还是能做出来的，状态转移方程dp[i]=max(dp[i-2]+nums[i],dp[i-3]+nums[i]);因为要隔着一个，那么就只能考虑这俩个，因为再往前就会影响到其他的房间了（不是相互独立的了），还有就是如果i-3没有的话，就直接选dp[i-2]+nums[i]即可。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">rob</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">1</span>)<span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        dp[<span class="number">1</span>]=nums[<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span> result=max(dp[<span class="number">0</span>],dp[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>;i&lt;size;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i<span class="number">-3</span>&lt;<span class="number">0</span>)dp[i]=dp[i<span class="number">-2</span>]+nums[i];</span><br><span class="line">            <span class="keyword">else</span> dp[i]=max(dp[i<span class="number">-2</span>]+nums[i],dp[i<span class="number">-3</span>]+nums[i]);</span><br><span class="line">            result=max(dp[i],result);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，&lt;strong&gt;如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;给定一个代表每个房屋存放金额的非负整数数组，计算你&lt;strong&gt;在不触动警报装置的情况下，&lt;/strong&gt;能够偷窃到的最高金额。&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>53最大子序和</title>
    <link href="https://cblog.club/ck3a6ilf1001djsg4es66dma6.html"/>
    <id>https://cblog.club/ck3a6ilf1001djsg4es66dma6.html</id>
    <published>2019-11-19T11:57:50.000Z</published>
    <updated>2019-11-19T12:05:25.942Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个整数数组 <code>nums</code> ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 </p><a id="more"></a><blockquote><p><strong>示例:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [-2,1,-3,4,-1,2,1,-5,4],</span><br><span class="line">输出: 6</span><br><span class="line">解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。</span><br></pre></td></tr></table></figure><p><strong>进阶:</strong></p><p>如果你已经实现复杂度为 O(<em>n</em>) 的解法，尝试使用更为精妙的分治法求解。</p></blockquote><h6 id="解题思路：本题刚开始我就在纠结于，遍历到当前元素时dp-i-的值，但是发现自己想的有点乱，借鉴了别人的思路，发现很不错，dp-i-代表以当前元素为终止元素的子序和（dp的选值就是max-以当前元素为终止结点的序列和，当前节点值-），因为我们要找的子序列一定是以某个元素为终止元素的，所以这么找一定会找到最终的结果，但是要注意的是，虽然当前元素会只用到前一个节点的dp值，但是最终结点的dp值不一定是最大的（这个要注意，和兑换零钱那种不太一样，要区别一下），最后找出其中最大的值即可。"><a href="#解题思路：本题刚开始我就在纠结于，遍历到当前元素时dp-i-的值，但是发现自己想的有点乱，借鉴了别人的思路，发现很不错，dp-i-代表以当前元素为终止元素的子序和（dp的选值就是max-以当前元素为终止结点的序列和，当前节点值-），因为我们要找的子序列一定是以某个元素为终止元素的，所以这么找一定会找到最终的结果，但是要注意的是，虽然当前元素会只用到前一个节点的dp值，但是最终结点的dp值不一定是最大的（这个要注意，和兑换零钱那种不太一样，要区别一下），最后找出其中最大的值即可。" class="headerlink" title="解题思路：本题刚开始我就在纠结于，遍历到当前元素时dp[i]的值，但是发现自己想的有点乱，借鉴了别人的思路，发现很不错，dp[i]代表以当前元素为终止元素的子序和（dp的选值就是max(以当前元素为终止结点的序列和，当前节点值)），因为我们要找的子序列一定是以某个元素为终止元素的，所以这么找一定会找到最终的结果，但是要注意的是，虽然当前元素会只用到前一个节点的dp值，但是最终结点的dp值不一定是最大的（这个要注意，和兑换零钱那种不太一样，要区别一下），最后找出其中最大的值即可。"></a>解题思路：本题刚开始我就在纠结于，遍历到当前元素时dp[i]的值，但是发现自己想的有点乱，借鉴了别人的思路，发现很不错，dp[i]代表以当前元素为终止元素的子序和（dp的选值就是max(以当前元素为终止结点的序列和，当前节点值)），因为我们要找的子序列一定是以某个元素为终止元素的，所以这么找一定会找到最终的结果，但是要注意的是，虽然当前元素会只用到前一个节点的dp值，但是最终结点的dp值不一定是最大的（这个要注意，和兑换零钱那种不太一样，要区别一下），最后找出其中最大的值即可。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> result=dp[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;dp.size();i++)&#123;</span><br><span class="line">            dp[i]=max(dp[i<span class="number">-1</span>]+nums[i],nums[i]);</span><br><span class="line">            result=max(dp[i],result);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个整数数组 &lt;code&gt;nums&lt;/code&gt; ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>121买卖股票的最佳时机</title>
    <link href="https://cblog.club/ck3a6ilar0000jsg41iiza5x9.html"/>
    <id>https://cblog.club/ck3a6ilar0000jsg41iiza5x9.html</id>
    <published>2019-11-19T11:49:56.000Z</published>
    <updated>2019-11-19T11:57:46.887Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>给定一个数组，它的第 <em>i</em> 个元素是一支给定股票第 <em>i</em> 天的价格。</p><p>如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。</p><p>注意你不能在买入股票前卖出股票。</p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入: [7,1,5,3,6,4]</span><br><span class="line">输出: 5</span><br><span class="line">解释: 在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。</span><br><span class="line">     注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格。</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [7,6,4,3,1]</span><br><span class="line">输出: 0</span><br><span class="line">解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：可能是刚接触动态规划不久，一开始做这一题的时候，一直找不到状态转移方程（找这个真的不简单）-最终借鉴别人的思想，dp-i-max-前i-1天的最大利润，（当前价格-前i-1天最低的价格-，豁然开朗，找最低的价格，我想到的是使用multiset（因为set插入即有序的，比较方便，但是时间可能会慢一点）。（暴力破解也能过-）"><a href="#解题思路：可能是刚接触动态规划不久，一开始做这一题的时候，一直找不到状态转移方程（找这个真的不简单）-最终借鉴别人的思想，dp-i-max-前i-1天的最大利润，（当前价格-前i-1天最低的价格-，豁然开朗，找最低的价格，我想到的是使用multiset（因为set插入即有序的，比较方便，但是时间可能会慢一点）。（暴力破解也能过-）" class="headerlink" title="解题思路：可能是刚接触动态规划不久，一开始做这一题的时候，一直找不到状态转移方程（找这个真的不简单）,最终借鉴别人的思想，dp[i]=max(前i-1天的最大利润，（当前价格-前i-1天最低的价格))，豁然开朗，找最低的价格，我想到的是使用multiset（因为set插入即有序的，比较方便，但是时间可能会慢一点）。（暴力破解也能过= =）"></a>解题思路：可能是刚接触动态规划不久，一开始做这一题的时候，一直找不到状态转移方程（找这个真的不简单）,最终借鉴别人的思想，dp[i]=max(前i-1天的最大利润，（当前价格-前i-1天最低的价格))，豁然开朗，找最低的价格，我想到的是使用multiset（因为set插入即有序的，比较方便，但是时间可能会慢一点）。（暴力破解也能过= =）</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*class Solution &#123;</span></span><br><span class="line"><span class="comment">public:</span></span><br><span class="line"><span class="comment">    int maxProfit(vector&lt;int&gt;&amp; prices) &#123;</span></span><br><span class="line"><span class="comment">        int max=0;</span></span><br><span class="line"><span class="comment">        int cur_sub;</span></span><br><span class="line"><span class="comment">        for(int j=0;j&lt;prices.size();j++)&#123;</span></span><br><span class="line"><span class="comment">            for(int i=j+1;i&lt;prices.size();i++)&#123;</span></span><br><span class="line"><span class="comment">                if(prices[j]&lt;prices[i])&#123;</span></span><br><span class="line"><span class="comment">                    cur_sub=prices[i]-prices[j];</span></span><br><span class="line"><span class="comment">                    if(max&lt;cur_sub)max=cur_sub;</span></span><br><span class="line"><span class="comment">                &#125;</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        return max;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;;*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxProfit</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; prices)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=prices.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">multiset</span>&lt;<span class="keyword">int</span>&gt;mset;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> cur_sub_pre;</span><br><span class="line">        <span class="built_in">multiset</span>&lt;<span class="keyword">int</span>&gt;::iterator it;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;dp.size();i++)&#123;</span><br><span class="line">            mset.insert(prices[i<span class="number">-1</span>]);</span><br><span class="line">            it=mset.begin();</span><br><span class="line">            cur_sub_pre=prices[i]-*(it);</span><br><span class="line">            dp[i]=max(dp[i<span class="number">-1</span>],cur_sub_pre);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[size<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;给定一个数组，它的第 &lt;em&gt;i&lt;/em&gt; 个元素是一支给定股票第 &lt;em&gt;i&lt;/em&gt; 天的价格。&lt;/p&gt;
&lt;p&gt;如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。&lt;/p&gt;
&lt;p&gt;注意你不能在买入股票前卖出股票。&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>70爬楼梯</title>
    <link href="https://cblog.club/ck3a6ilfl001ujsg44thi0js3.html"/>
    <id>https://cblog.club/ck3a6ilfl001ujsg44thi0js3.html</id>
    <published>2019-11-19T11:42:03.000Z</published>
    <updated>2019-11-19T11:49:30.206Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>假设你正在爬楼梯。需要 <em>n</em> 阶你才能到达楼顶。每次你可以爬 1 或 2 个台阶。</p><p>你有多少种不同的方法可以爬到楼顶呢？</p><p><strong>注意：</strong>给定 <em>n</em> 是一个正整数。</p><a id="more"></a><blockquote><p><strong>示例 1：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入： 2</span><br><span class="line">输出： 2</span><br><span class="line">解释： 有两种方法可以爬到楼顶。</span><br><span class="line">1.  1 阶 + 1 阶</span><br><span class="line">2.  2 阶</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入： 3</span><br><span class="line">输出： 3</span><br><span class="line">解释： 有三种方法可以爬到楼顶。</span><br><span class="line">1.  1 阶 + 1 阶 + 1 阶</span><br><span class="line">2.  1 阶 + 2 阶</span><br><span class="line">3.  2 阶 + 1 阶</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：这一题刚开始在想，这题和动态规划有关系吗？也没有什么最优子结构什么的啊？细细一想，这不就是斐波那契数吗-（原理很类似），我们这样考虑：假设我们当前处于第四层，那么我们是怎么上来的呢？一共有两种可能，第一：从第三层上来的，第二：从第二层上来的，那么此时我们就会有两种可能，同理，第三层，第二层也都是这么上来的，故我们自底向上（动态规划的思想出现了），第一层只有一种可能，第二层有两种可能，从第三层开始，当前层-n-1-层-n-2-层-（这不就是斐波那契数列的原型吗-，只不过数不一样了）。当然，空间复杂度还可以优化为O-1-，如第二种方法所示。"><a href="#解题思路：这一题刚开始在想，这题和动态规划有关系吗？也没有什么最优子结构什么的啊？细细一想，这不就是斐波那契数吗-（原理很类似），我们这样考虑：假设我们当前处于第四层，那么我们是怎么上来的呢？一共有两种可能，第一：从第三层上来的，第二：从第二层上来的，那么此时我们就会有两种可能，同理，第三层，第二层也都是这么上来的，故我们自底向上（动态规划的思想出现了），第一层只有一种可能，第二层有两种可能，从第三层开始，当前层-n-1-层-n-2-层-（这不就是斐波那契数列的原型吗-，只不过数不一样了）。当然，空间复杂度还可以优化为O-1-，如第二种方法所示。" class="headerlink" title="解题思路：这一题刚开始在想，这题和动态规划有关系吗？也没有什么最优子结构什么的啊？细细一想，这不就是斐波那契数吗= =（原理很类似），我们这样考虑：假设我们当前处于第四层，那么我们是怎么上来的呢？一共有两种可能，第一：从第三层上来的，第二：从第二层上来的，那么此时我们就会有两种可能，同理，第三层，第二层也都是这么上来的，故我们自底向上（动态规划的思想出现了），第一层只有一种可能，第二层有两种可能，从第三层开始，当前层=(n-1)层+(n-2)层,（这不就是斐波那契数列的原型吗= =，只不过数不一样了）。当然，空间复杂度还可以优化为O(1)，如第二种方法所示。"></a>解题思路：这一题刚开始在想，这题和动态规划有关系吗？也没有什么最优子结构什么的啊？细细一想，这不就是斐波那契数吗= =（原理很类似），我们这样考虑：假设我们当前处于第四层，那么我们是怎么上来的呢？一共有两种可能，第一：从第三层上来的，第二：从第二层上来的，那么此时我们就会有两种可能，同理，第三层，第二层也都是这么上来的，故我们自底向上（动态规划的思想出现了），第一层只有一种可能，第二层有两种可能，从第三层开始，当前层=(n-1)层+(n-2)层,（这不就是斐波那契数列的原型吗= =，只不过数不一样了）。当然，空间复杂度还可以优化为O(1)，如第二种方法所示。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">class Solution &#123;</span></span><br><span class="line"><span class="comment">public:</span></span><br><span class="line"><span class="comment">    int climbStairs(int n) &#123;</span></span><br><span class="line"><span class="comment">        vector&lt;int&gt;dp(n+2);</span></span><br><span class="line"><span class="comment">        dp[1]=1;</span></span><br><span class="line"><span class="comment">        dp[2]=2;</span></span><br><span class="line"><span class="comment">        for(int i=3;i&lt;=n;i++)&#123;</span></span><br><span class="line"><span class="comment">            dp[i]=dp[i-1]+dp[i-2];</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        return dp[n];</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;;*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">climbStairs</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>)<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> pre=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> cur=<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> sum;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n<span class="number">-2</span>;i++)&#123;</span><br><span class="line">            sum=cur+pre;</span><br><span class="line">            pre=cur;</span><br><span class="line">            cur=sum;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cur;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;假设你正在爬楼梯。需要 &lt;em&gt;n&lt;/em&gt; 阶你才能到达楼顶。每次你可以爬 1 或 2 个台阶。&lt;/p&gt;
&lt;p&gt;你有多少种不同的方法可以爬到楼顶呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;给定 &lt;em&gt;n&lt;/em&gt; 是一个正整数。&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>322零钱兑换</title>
    <link href="https://cblog.club/ck3a6ildx000hjsg4fn9bgg7e.html"/>
    <id>https://cblog.club/ck3a6ildx000hjsg4fn9bgg7e.html</id>
    <published>2019-11-19T11:33:23.000Z</published>
    <updated>2019-11-19T11:41:57.625Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 <code>-1</code>。 </p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: coins = [1, 2, 5], amount = 11</span><br><span class="line">输出: 3 </span><br><span class="line">解释: 11 = 5 + 5 + 1</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: coins = [2], amount = 3</span><br><span class="line">输出: -1</span><br></pre></td></tr></table></figure><p><strong>说明</strong>:<br>你可以认为每种硬币的数量是无限的。</p></blockquote><h6 id="解题思路：这一题是动态规划的入门题目，可以说是很经典的一道题，对于动态规划，关键在于你是否能够写出状态转移方程（能写出来就已经成功了80-），这一题的状态转移方程主要是dp-i-min-dp-i-1-dp-i-coin-其中coin为零钱的面额，最后返回dp-总金额-即可。"><a href="#解题思路：这一题是动态规划的入门题目，可以说是很经典的一道题，对于动态规划，关键在于你是否能够写出状态转移方程（能写出来就已经成功了80-），这一题的状态转移方程主要是dp-i-min-dp-i-1-dp-i-coin-其中coin为零钱的面额，最后返回dp-总金额-即可。" class="headerlink" title="解题思路：这一题是动态规划的入门题目，可以说是很经典的一道题，对于动态规划，关键在于你是否能够写出状态转移方程（能写出来就已经成功了80%），这一题的状态转移方程主要是dp[i]=min(dp[i],1+dp[i-coin])其中coin为零钱的面额，最后返回dp[总金额]即可。"></a>解题思路：这一题是动态规划的入门题目，可以说是很经典的一道题，对于动态规划，关键在于你是否能够写出状态转移方程（能写出来就已经成功了80%），这一题的状态转移方程主要是dp[i]=min(dp[i],1+dp[i-coin])其中coin为零钱的面额，最后返回dp[总金额]即可。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">class Solution &#123;</span></span><br><span class="line"><span class="comment">public:</span></span><br><span class="line"><span class="comment">    int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123;</span></span><br><span class="line"><span class="comment">        vector&lt;int&gt;dp(amount+1,amount+1);</span></span><br><span class="line"><span class="comment">        dp[0]=0;</span></span><br><span class="line"><span class="comment">        for(int i=0;i&lt;=amount;i++)&#123;</span></span><br><span class="line"><span class="comment">            for(int coin:coins)&#123;</span></span><br><span class="line"><span class="comment">                if(i&lt;coin)continue;</span></span><br><span class="line"><span class="comment">                dp[i]=min(dp[i],1+dp[i-coin]);</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        return (dp[amount]==amount+1)?-1:dp[amount];</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;;*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">coinChange</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;memo(amount+<span class="number">1</span>,<span class="number">-2</span>);</span><br><span class="line">        <span class="keyword">return</span> helper(coins,amount,memo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">helper</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; memo)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(amount==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(memo[amount]!=<span class="number">-2</span>)<span class="keyword">return</span> memo[amount];</span><br><span class="line">        <span class="keyword">int</span> ans=__INT_MAX__;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> coin:coins)&#123;</span><br><span class="line">            <span class="keyword">if</span>(amount&lt;coin)<span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">int</span> sub_curcoin=helper(coins,amount-coin,memo);</span><br><span class="line">            <span class="keyword">if</span>(sub_curcoin==<span class="number">-1</span>)<span class="keyword">continue</span>;</span><br><span class="line">            ans=min(ans,<span class="number">1</span>+sub_curcoin);</span><br><span class="line">        &#125;</span><br><span class="line">        memo[amount]=(ans==__INT_MAX__)?<span class="number">-1</span>:ans;</span><br><span class="line">        <span class="keyword">return</span> memo[amount];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 &lt;code&gt;-1&lt;/code&gt;。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>动态规划</title>
    <link href="https://cblog.club/ck3a6ilh0002zjsg41p66c7wc.html"/>
    <id>https://cblog.club/ck3a6ilh0002zjsg41p66c7wc.html</id>
    <published>2019-11-19T11:10:56.000Z</published>
    <updated>2019-11-19T11:33:29.566Z</updated>
    
    <content type="html"><![CDATA[<p>最近在知乎上看到了一篇讲动态规划的文章，感觉还可以，比较好理解。</p><p>出于对作者的尊重，特别感谢作者，其知乎： <a href="https://www.zhihu.com/search?type=content&q=动态规划" target="_blank" rel="noopener">https://www.zhihu.com/search?type=content&amp;q=%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92</a> </p><p>动态规划算法似乎是一种很高深莫测的算法，你会在一些面试或算法书籍的高级技巧部分看到相关内容，什么状态转移方程，重叠子问题，最优子结构等高大上的词汇也可能让你望而却步。</p><a id="more"></a><p>而且，当你去看用动态规划解决某个问题的代码时，你会觉得这样解决问题竟然如此巧妙，但却难以理解，你可能惊讶于人家是怎么想到这种解法的。</p><p>实际上，动态规划是一种常见的「算法设计技巧」，并没有什么高深莫测，至于各种高大上的术语，那是吓唬别人用的，只要你亲自体验几把，这些名词的含义其实显而易见，再简单不过了。</p><p>至于为什么最终的解法看起来如此精妙，是因为动态规划遵循一套固定的流程：<strong>递归的暴力解法 -&gt; 带备忘录的递归解法 -&gt; 非递归的动态规划解法</strong>。这个过程是层层递进的解决问题的过程，你如果没有前面的铺垫，直接看最终的非递归动态规划解法，当然会觉得牛逼而不可及了。</p><p>当然，见的多了，思考多了，是可以一步写出非递归的动态规划解法的。任何技巧都需要练习，我们先遵循这个流程走，算法设计也就这些套路，除此之外，真的没啥高深的。</p><p>以下，先通过两个个比较简单的例子：斐波那契和凑零钱问题，揭开动态规划的神秘面纱，描述上述三个流程。后续还会写几篇文章探讨如何使用动态规划技巧解决比较复杂的经典问题。</p><p>首先，第一个快被举烂了的例子，斐波那契数列。<strong>请读者不要嫌弃这个例子简单，因为简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上</strong>，而不会被那些隐晦的细节问题搞的莫名其妙。后续，困难的例子有的是。</p><p> <strong>步骤一、暴力的递归算法</strong> </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fib</span><span class="params">(<span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (N == <span class="number">1</span> || N == <span class="number">2</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> fib(N - <span class="number">1</span>) + fib(N - <span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个不用多说了，学校老师讲递归的时候似乎都是拿这个举例。我们也知道这样写代码虽然简洁易懂，但是十分低效，低效在哪里？假设 n = 20，请画出递归树。</p><p>PS：但凡遇到需要递归的问题，最好都画出递归树，这对你分析算法的复杂度，寻找算法低效的原因都有巨大帮助。</p><img src="/ck3a6ilh0002zjsg41p66c7wc/1.jpg" class=""><p>这个递归树怎么理解？就是说想要计算原问题 f(20)，我就得先计算出子问题 f(19) 和 f(18)，然后要计算 f(19)，我就要先算出子问题 f(18) 和 f(17)，以此类推。最后遇到 f(1) 或者 f(2) 的时候，结果已知，就能直接返回结果，递归树不再向下生长了。</p><p> <strong>递归算法的时间复杂度怎么计算？子问题个数乘以解决一个子问题需要的时间。</strong> </p><p>子问题个数，即递归树中节点的总数。显然二叉树节点总数为指数级别，所以子问题个数为 O(2^n)。</p><p>解决一个子问题的时间，在本算法中，没有循环，只有 f(n - 1) + f(n - 2) 一个加法操作，时间为 O(1)。</p><p>所以，这个算法的时间复杂度为 O(2^n)，指数级别，爆炸。</p><p>观察递归树，很明显发现了算法低效的原因：存在大量重复计算，比如 f(18) 被计算了两次，而且你可以看到，以 f(18) 为根的这个递归树体量巨大，多算一遍，会耗费巨大的时间。更何况，还不止 f(18) 这一个节点被重复计算，所以这个算法极其低效。</p><p> 这就是动态规划问题的第一个性质：<strong>重叠子问题</strong>。下面，我们想办法解决这个问题。 </p><p><strong>步骤二、带备忘录的递归解法</strong></p><p>明确了问题，其实就已经把问题解决了一半。即然耗时的原因是重复计算，那么我们可以造一个「备忘录」，每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，如果发现之前已经解决过这个问题了，直接把答案拿出来用，不要再耗时去计算了。</p><p>一般使用一个数组充当这个「备忘录」，当然你也可以使用哈希表（字典），思想都是一样的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fib</span><span class="params">(<span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (N &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 备忘录全初始化为 0</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; memo(N + <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 初始化最简情况</span></span><br><span class="line">    memo[<span class="number">1</span>] = memo[<span class="number">2</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> helper(memo, N);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">helper</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; memo, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 未被计算过</span></span><br><span class="line">    <span class="keyword">if</span> (n &gt; <span class="number">0</span> &amp;&amp; memo[n] == <span class="number">0</span>) </span><br><span class="line">        memo[n] = helper(memo, n - <span class="number">1</span>) + </span><br><span class="line">                  helper(memo, n - <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">return</span> memo[n];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 现在，画出递归树，你就知道「备忘录」到底做了什么。 </p><img src="/ck3a6ilh0002zjsg41p66c7wc/2.jpg" class=""><p>实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过「剪枝」，改造成了一幅不存在冗余的递归图，极大减少了子问题（即递归图中节点）的个数。</p><p>递归算法的时间复杂度怎么算？子问题个数乘以解决一个子问题需要的时间。</p><p>子问题个数，即图中节点的总数，由于本算法不存在冗余计算，子问题就是 f(1), f(2), f(3) … f(20)，数量和输入规模 n = 20 成正比，所以子问题个数为 O(n)。</p><p>解决一个子问题的时间，同上，没有什么循环，时间为 O(1)。</p><p>所以，本算法的时间复杂度是 O(n)。比起暴力算法，是降维打击。</p><p>至此，带备忘录的递归解法的效率已经和动态规划一样了。实际上，这种解法和动态规划的思想已经差不多了，只不过这种方法叫做「自顶向下」，动态规划叫做「自底向上」。</p><p>啥叫「自顶向下」？注意我们刚才画的递归树（或者说图），是从上向下延伸，都是从一个规模较大的原问题比如说 f(20)，向下逐渐分解规模，直到 f(1) 和 f(2) 触底，然后逐层返回答案，这就叫「自顶向下」。</p><p>啥叫「自底向上」？反过来，我们直接从最底下，最简单，问题规模最小的 f(1) 和 f(2) 开始往上推，直到推到我们想要的答案 f(20)，这就是动态规划的思路，这也是为什么动态规划一般都脱离了递归，而是由循环迭代完成计算。</p><p> <strong>步骤三、动态规划</strong> </p><p> 有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，就叫做 DP table 吧，在这张表上完成「自底向上」的推算岂不美哉！ </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fib</span><span class="params">(<span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(N + <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">    dp[<span class="number">1</span>] = dp[<span class="number">2</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">3</span>; i &lt;= N; i++)</span><br><span class="line">        dp[i] = dp[i - <span class="number">1</span>] + dp[i - <span class="number">2</span>];</span><br><span class="line">    <span class="keyword">return</span> dp[N];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="/ck3a6ilh0002zjsg41p66c7wc/3.jpg" class=""><p>画个图就很好理解了，而且你发现这个 DP table 特别像之前那个「剪枝」后的结果，只是反过来算而已。实际上，带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以说这两种解法其实是差不多的，大部分情况下，效率也基本相同。</p><p>这里，引出「动态转移方程」这个名词，实际上就是描述问题结构的数学形式：</p><img src="/ck3a6ilh0002zjsg41p66c7wc/4.jpg" class=""><p>为啥叫「状态转移方程」？为了听起来高端。你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，这就叫状态转移，仅此而已。</p><p>你会发现，上面的几种解法中的所有操作，例如 return f(n - 1) + f(n - 2)，dp[i] = dp[i - 1] + dp[i - 2]，以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。可见列出「状态转移方程」的重要性，它是解决问题的核心。很容易发现，其实状态转移方程直接代表着暴力解法。</p><p><strong>千万不要看不起暴力解，动态规划问题最困难的就是写出状态转移方程</strong>，即这个暴力解。优化方法无非是用备忘录或者 DP table，再无奥妙可言。</p><p>这个例子的最后，讲一个细节优化。细心的读者会发现，根据斐波那契数列的状态转移方程，当前状态只和之前的两个状态有关，其实并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态就行了。所以，可以进一步优化，把空间复杂度降为 O(1)：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fib</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">2</span>) <span class="keyword">return</span> n;</span><br><span class="line">    <span class="keyword">int</span> prev = <span class="number">0</span>, curr = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> sum = prev + curr;</span><br><span class="line">        prev = curr;</span><br><span class="line">        curr = sum;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> curr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有人会问，动态规划的另一个重要特性「最优子结构」，怎么没有涉及？下面会涉及。斐波那契数列的例子严格来说不算动态规划，以上旨在演示算法设计螺旋上升的过程。当问题中要求求一个最优解或在代码中看到循环和 max、min 等函数时，十有八九，需要动态规划大显身手。</p><p>下面，看第二个例子，凑零钱问题，有了上面的详细铺垫，这个问题会很快解决。</p><p>题目：给你 k 种面值的硬币，面值分别为 c1, c2 … ck，再给一个总金额 n，问你最少需要几枚硬币凑出这个金额，如果不可能凑出，则回答 -1 。</p><p>比如说，k = 3，面值分别为 1，2，5，总金额 n = 11，那么最少需要 3 枚硬币，即 11 = 5 + 5 + 1 。下面走流程。</p><p><strong>一、暴力解法</strong></p><p>首先是最困难的一步，写出状态转移方程，这个问题比较好写：</p><img src="/ck3a6ilh0002zjsg41p66c7wc/5.jpg" class=""><p>其实，这个方程就用到了<strong>「最优子结构」性质：原问题的解由子问题的最优解构成。</strong>即 f(11) 由 f(10), f(9), f(6) 的最优解转移而来。</p><p>记住，<strong>要符合「最优子结构」，子问题间必须互相独立。</strong>啥叫相互独立？你肯定不想看数学证明，我用一个直观的例子来讲解。</p><p>比如说，你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，这就是最高的总成绩。</p><p>得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，“每门科目考到最高”这些子问题是互相独立，互不干扰的。</p><p>但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，此消彼长。这样的话，显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，所以最优子结构被破坏。</p><p>回到凑零钱问题，显然子问题之间没有相互制约，而是互相独立的。所以这个状态转移方程是可以得到正确答案的。</p><p>之后就没啥难点了，按照方程写暴力递归算法即可。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">coinChange</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (amount == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> ans = INT_MAX;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> coin : coins) &#123;</span><br><span class="line">        <span class="comment">// 金额不可达</span></span><br><span class="line">        <span class="keyword">if</span> (amount - coin &lt; <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">int</span> subProb = coinChange(coins, amount - coin);</span><br><span class="line">        <span class="comment">// 子问题无解</span></span><br><span class="line">        <span class="keyword">if</span> (subProb == <span class="number">-1</span>) <span class="keyword">continue</span>;</span><br><span class="line">        ans = min(ans, subProb + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans == INT_MAX ? <span class="number">-1</span> : ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 画出递归树： </p><img src="/ck3a6ilh0002zjsg41p66c7wc/6.jpg" class=""><p> 时间复杂度分析：子问题总数 x 每个子问题的时间。子问题总数为递归树节点个数，这个比较难看出来，是 O(n^k)，总之是指数级别的。每个子问题中含有一个 for 循环，复杂度为 O(k)。所以总时间复杂度为 O(k*n^k)，指数级别。 </p><p><strong>二、带备忘录的递归算法</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">coinChange</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 备忘录初始化为 -2</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; memo(amount + <span class="number">1</span>, <span class="number">-2</span>);</span><br><span class="line">    <span class="keyword">return</span> helper(coins, amount, memo);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">helper</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; memo)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (amount == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (memo[amount] != <span class="number">-2</span>) <span class="keyword">return</span> memo[amount];</span><br><span class="line">    <span class="keyword">int</span> ans = INT_MAX;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> coin : coins) &#123;</span><br><span class="line">        <span class="comment">// 金额不可达</span></span><br><span class="line">        <span class="keyword">if</span> (amount - coin &lt; <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">int</span> subProb = helper(coins, amount - coin, memo);</span><br><span class="line">        <span class="comment">// 子问题无解</span></span><br><span class="line">        <span class="keyword">if</span> (subProb == <span class="number">-1</span>) <span class="keyword">continue</span>;</span><br><span class="line">        ans = min(ans, subProb + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 记录本轮答案</span></span><br><span class="line">    memo[amount] = (ans == INT_MAX) ? <span class="number">-1</span> : ans;</span><br><span class="line">    <span class="keyword">return</span> memo[amount];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 不画图了，很显然「备忘录」大大减小了子问题数目，完全消除了子问题的冗余，所以子问题总数不会超过金额数 n，即子问题数目为 O(n)。处理一个子问题的时间不变，仍是 O(k)，所以总的时间复杂度是 O(kn)。 </p><p> <strong>三、动态规划</strong> </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">coinChange</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(amount + <span class="number">1</span>, amount + <span class="number">1</span>);</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; dp.size(); i++) &#123;</span><br><span class="line">        <span class="comment">// 内层 for 在求所有子问题 + 1 的最小值</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> coin : coins) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i - coin &lt; <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">            dp[i] = min(dp[i], <span class="number">1</span> + dp[i - coin]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (dp[amount] == amount + <span class="number">1</span>) ? <span class="number">-1</span> : dp[amount];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="/ck3a6ilh0002zjsg41p66c7wc/7.jpg" class=""><p><strong>最后总结</strong></p><p>如果你不太了解动态规划，还能看到这里，真得给你鼓掌，相信你已经掌握了这个算法的设计技巧。</p><p>计算机解决问题其实没有任何奇技淫巧，它唯一的解决办法就是穷举，穷举所有可能性。算法设计无非就是先思考“如何穷举”，然后再追求“如何聪明地穷举”。</p><p>列出动态转移方程，就是在解决“如何穷举”的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。</p><p>备忘录、DP table 就是在追求“如何聪明地穷举”。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在知乎上看到了一篇讲动态规划的文章，感觉还可以，比较好理解。&lt;/p&gt;
&lt;p&gt;出于对作者的尊重，特别感谢作者，其知乎： &lt;a href=&quot;https://www.zhihu.com/search?type=content&amp;q=动态规划&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.zhihu.com/search?type=content&amp;amp;q=%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;动态规划算法似乎是一种很高深莫测的算法，你会在一些面试或算法书籍的高级技巧部分看到相关内容，什么状态转移方程，重叠子问题，最优子结构等高大上的词汇也可能让你望而却步。&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法" scheme="https://cblog.club/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://cblog.club/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch_Day2</title>
    <link href="https://cblog.club/ck3a6ilfx0023jsg4gfo03axd.html"/>
    <id>https://cblog.club/ck3a6ilfx0023jsg4gfo03axd.html</id>
    <published>2019-11-19T03:26:51.000Z</published>
    <updated>2019-11-20T14:33:08.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Autograd-自动求导机制"><a href="#Autograd-自动求导机制" class="headerlink" title="Autograd: 自动求导机制"></a>Autograd: 自动求导机制</h2><p>PyTorch 中所有神经网络的核心是 autograd 包。 我们先简单介绍一下这个包，然后训练第一个简单的神经网络。<br>autograd包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。</p><h3 id="张量Tensor"><a href="#张量Tensor" class="headerlink" title="张量Tensor"></a>张量Tensor</h3><ul><li>torch.Tensor 是包的核心类。如果将其属性 .requires_grad 设置为 True，则会开始跟踪针对 tensor 的所有操作。完成计算后，您可以调用 .backward() 来自动计算所有梯度。该张量的梯度将累积到 .grad 属性中。</li><li>要停止 tensor 历史记录的跟踪，您可以调用 .detach()，它将其与计算历史记录分离，并防止将来的计算被跟踪。</li><li>要停止跟踪历史记录（和使用内存），您还可以将代码块使用 with torch.no_grad(): 包装起来。在评估模型时，这是特别有用，因为模型在训练阶段具有 requires_grad = True 的可训练参数有利于调参，但在评估阶段我们不需要梯度。</li><li>还有一个类对于 autograd 实现非常重要那就是 Function。Tensor 和 Function 互相连接并构建一个非循环图，它保存整个完整的计算过程的历史信息。每个张量都有一个 .grad_fn 属性保存着创建了张量的 Function 的引用，（如果用户自己创建张量，则grad_fn 是 None ）。</li><li>如果你想计算导数，你可以调用 Tensor.backward()。如果 Tensor 是标量（即它包含一个元素数据），则不需要指定任何参数backward()，但是如果它有更多元素，则需要指定一个gradient 参数来指定张量的形状。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><h4 id="创建一个tensor张量，并且设置requires-grad-True用来追踪他的计算历史"><a href="#创建一个tensor张量，并且设置requires-grad-True用来追踪他的计算历史" class="headerlink" title="创建一个tensor张量，并且设置requires_grad=True用来追踪他的计算历史"></a>创建一个tensor张量，并且设置requires_grad=True用来追踪他的计算历史</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.ones(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[1., 1.],        [1., 1.]], requires_grad=True)</code></pre><h4 id="结果y已经被计算出来了，所以，grad-fn已经被自动生成了"><a href="#结果y已经被计算出来了，所以，grad-fn已经被自动生成了" class="headerlink" title="结果y已经被计算出来了，所以，grad_fn已经被自动生成了"></a>结果y已经被计算出来了，所以，grad_fn已经被自动生成了</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y=x+<span class="number">2</span></span><br><span class="line">print(y)</span><br><span class="line">print(y .grad_fn)</span><br></pre></td></tr></table></figure><pre><code>tensor([[3., 3.],        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)&lt;AddBackward0 object at 0x000001A29043E080&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">z=y*y*<span class="number">3</span></span><br><span class="line"><span class="comment">#mean() 返回数组的算术平均值</span></span><br><span class="line">out=z.mean()</span><br><span class="line">print(z,out)</span><br></pre></td></tr></table></figure><pre><code>tensor([[27., 27.],        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)</code></pre><h4 id="requires-grad-…-可以改变现有张量的-requires-grad属性。-如果没有指定的话，默认输入的flag是-False"><a href="#requires-grad-…-可以改变现有张量的-requires-grad属性。-如果没有指定的话，默认输入的flag是-False" class="headerlink" title=".requires_grad_( … ) 可以改变现有张量的 requires_grad属性。 如果没有指定的话，默认输入的flag是 False"></a>.requires_grad_( … ) 可以改变现有张量的 requires_grad属性。 如果没有指定的话，默认输入的flag是 False</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a=torch.randn(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">a=(a*<span class="number">3</span>)/(a<span class="number">-1</span>)</span><br><span class="line">print(a.requires_grad)</span><br><span class="line">a.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">print(a.requires_grad)</span><br><span class="line">b=(a*a).sum()</span><br><span class="line">print(b.grad_fn)</span><br></pre></td></tr></table></figure><pre><code>FalseTrue&lt;SumBackward0 object at 0x000001A29097A748&gt;</code></pre><h3 id="梯度Gradient"><a href="#梯度Gradient" class="headerlink" title="梯度Gradient"></a>梯度Gradient</h3><p>反向传播，因为上文中的out是一个纯量(scalar)，out.backward()等于out.backwad(torch.tensor(1))</p><ul><li>x梯度计算不是很理解原理</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#out.backward()       #只能使用一次 </span></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([[4.5000, 4.5000],        [4.5000, 4.5000]])</code></pre><h4 id="现在让我们看一个雅可比向量积的例子：-不理解"><a href="#现在让我们看一个雅可比向量积的例子：-不理解" class="headerlink" title="现在让我们看一个雅可比向量积的例子：(不理解= =)"></a>现在让我们看一个雅可比向量积的例子：(不理解= =)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x=torch.randn(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=x*<span class="number">2</span></span><br><span class="line"><span class="comment">#torch.norm是对输入的Tensor求范数</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm()&lt;<span class="number">1000</span>:</span><br><span class="line">    y=y*<span class="number">2</span></span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([-340.3439, 1044.5084, -227.5869], grad_fn=&lt;MulBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gradients=torch.tensor([<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">0.0001</span>],dtype=torch.float)</span><br><span class="line"><span class="comment">#y.backward(gradients)</span></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])</code></pre><h4 id="如果-requires-grad-True但是你又不希望进行autograd的计算，-那么可以将变量包裹在-with-torch-no-grad-中"><a href="#如果-requires-grad-True但是你又不希望进行autograd的计算，-那么可以将变量包裹在-with-torch-no-grad-中" class="headerlink" title="如果.requires_grad=True但是你又不希望进行autograd的计算， 那么可以将变量包裹在 with torch.no_grad()中:"></a>如果.requires_grad=True但是你又不希望进行autograd的计算， 那么可以将变量包裹在 with torch.no_grad()中:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(x.requires_grad)</span><br><span class="line">print((x**<span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    print((x**<span class="number">2</span>).requires_grad)</span><br></pre></td></tr></table></figure><pre><code>TrueTrueFalse</code></pre><h2 id="神经网络Neural-Networks"><a href="#神经网络Neural-Networks" class="headerlink" title="神经网络Neural Networks"></a>神经网络Neural Networks</h2><p>神经网络可以通过 torch.nn 包来构建。<br>上一讲已经讲过了autograd，nn包依赖autograd包来定义模型并求导。 一个nn.Module包含各个层和一个forward(input)方法，该方法返回output。<br>例如，看一下数字图片识别的网络：</p><img src="/ck3a6ilfx0023jsg4gfo03axd/1.jpg" class=""><p>它是一个简单的前馈神经网络，它接受一个输入，然后一层接着一层地传递，最后输出计算的结果。<br>神经网络的典型训练过程如下：</p><ul><li>定义包含一些可学习的参数(或者叫权重)神经网络模型；</li><li>在数据集上迭代；</li><li>通过神经网络处理输入；</li><li>计算损失(输出结果和正确值的差值大小)；</li><li>将梯度反向传播回网络的参数；</li><li>更新网络的参数，主要使用如下简单的更新原则： weight = weight - learning_rate * gradient</li></ul><h3 id="定义一个网络"><a href="#定义一个网络" class="headerlink" title="定义一个网络"></a>定义一个网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#继承</span></span><br><span class="line">        super(Net,self).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#建立了两个卷积层，self.conv1, self.conv2，注意，这些层都是不包含激活函数的</span></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">1</span>,<span class="number">6</span>,<span class="number">5</span>)</span><br><span class="line">        self.conv2=nn.Conv2d(<span class="number">6</span>,<span class="number">16</span>,<span class="number">5</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#三个全连接层</span></span><br><span class="line">        self.fc1=nn.Linear(<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>,<span class="number">120</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">120</span>,<span class="number">84</span>)</span><br><span class="line">        self.fc3=nn.Linear(<span class="number">84</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="comment">#max_pooling池化操作   2x2的框</span></span><br><span class="line">        x=F.max_pool2d(F.relu(self.conv1(x)),(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        <span class="comment">#只写一个参数，相当于默认2x2</span></span><br><span class="line">        x=F.max_pool2d(F.relu(self.conv2(x)),<span class="number">2</span>)</span><br><span class="line">        x=x.view(<span class="number">-1</span>,self.num_falt_features(x))</span><br><span class="line">        x=F.relu(self.fc1(x))</span><br><span class="line">        x=F.relu(self.fc2(x))</span><br><span class="line">        x=self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_falt_features</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        size=x.size()[<span class="number">1</span>:]</span><br><span class="line">        num_features=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features*=s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line">        </span><br><span class="line">net =Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><ul><li>你只需定义forward函数,backward函数(计算梯度)在使用autograd时自动为你创建.你可以在forward函数中使用Tensor的任何操作。</li></ul><h4 id="net-parameters-返回模型需要学习的参数。"><a href="#net-parameters-返回模型需要学习的参数。" class="headerlink" title="net.parameters()返回模型需要学习的参数。"></a>net.parameters()返回模型需要学习的参数。</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params=list(net.parameters())</span><br><span class="line">print(len(params))</span><br><span class="line">print(params[<span class="number">0</span>].size())</span><br></pre></td></tr></table></figure><pre><code>10torch.Size([6, 1, 5, 5])</code></pre><ul><li>为什么是10呢？ 因为不仅有weights，还有bias(偏置)， 10=5*2。</li><li>forward的输入和输出都是autograd.Variable.注意:这个网络(LeNet)期望的输入大小是32x32.如果使用MNIST数据集来训练这个网络,请把图片大小重新调整到32x32.</li><li>注意，2D卷积层的输入data维数是 batchsize channel height width</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input=torch.randn(<span class="number">1</span>,<span class="number">1</span>,<span class="number">32</span>,<span class="number">32</span>)</span><br><span class="line">out=net(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><pre><code>tensor([[-0.0662,  0.0852,  0.0259, -0.0536, -0.0588,  0.1479,  0.1092, -0.1086,          0.0060, -0.0747]], grad_fn=&lt;AddmmBackward&gt;)</code></pre><h4 id="将所有参数的梯度缓存清零-然后进行随机梯度的的反向传播"><a href="#将所有参数的梯度缓存清零-然后进行随机梯度的的反向传播" class="headerlink" title="将所有参数的梯度缓存清零,然后进行随机梯度的的反向传播."></a>将所有参数的梯度缓存清零,然后进行随机梯度的的反向传播.</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure><p>注意</p><ul><li>torch.nn 只支持小批量输入,整个torch.nn包都只支持小批量样本,而不支持单个样本</li><li>例如,nn.Conv2d将接受一个4维的张量,每一维分别是$nSamples\times nChannels\times Height\times Width$(样本数x通道数x高x宽).</li><li>如果你有单个样本,只需使用input.unsqueeze(0)来添加其它的维数.</li></ul><h4 id="在继续之前-我们回顾一下到目前为止见过的所有类"><a href="#在继续之前-我们回顾一下到目前为止见过的所有类" class="headerlink" title="在继续之前,我们回顾一下到目前为止见过的所有类."></a>在继续之前,我们回顾一下到目前为止见过的所有类.</h4><ul><li>torch.Tensor-支持自动编程操作（如backward()）的多维数组。 同时保持梯度的张量。</li><li>nn.Module-神经网络模块.封装参数,移动到GPU上运行,导出,加载等</li><li>nn.Parameter-一种张量,当把它赋值给一个Module时,被自动的注册为参数.</li><li>autograd.Function-实现一个自动求导操作的前向和反向定义, 每个张量操作都会创建至少一个Function节点，该节点连接到创建张量并对其历史进行编码的函数。 </li></ul><h4 id="现在-我们包含了如下内容"><a href="#现在-我们包含了如下内容" class="headerlink" title="现在,我们包含了如下内容:"></a>现在,我们包含了如下内容:</h4><ul><li>定义一个神经网络</li><li>处理输入和调用backward</li></ul><h4 id="剩下的内容"><a href="#剩下的内容" class="headerlink" title="剩下的内容:"></a>剩下的内容:</h4><ul><li>计算损失值</li><li>更新神经网络的权值</li></ul><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><ul><li>一个损失函数接受一对(output, target)作为输入(output为网络的输出,target为实际值),计算一个值来估计网络的输出和目标值相差多少。</li><li>在nn包中有几种不同的损失函数.一个简单的损失函数是:nn.MSELoss,它计算输入和目标之间的均方误差。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">out=net(input)</span><br><span class="line"><span class="comment">#一个虚拟的目标（举个例子用的）</span></span><br><span class="line">target=torch.randn(<span class="number">10</span>)</span><br><span class="line">target=target.view(<span class="number">1</span>,<span class="number">-1</span>)</span><br><span class="line">criterion=nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss=criterion(out,target)</span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure><pre><code>tensor(1.4106, grad_fn=&lt;MseLossBackward&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(loss.grad_fn)</span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>].next_functions[<span class="number">0</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;MseLossBackward object at 0x000001A29B005DD8&gt;&lt;AddmmBackward object at 0x000001A29B005DD8&gt;&lt;AccumulateGrad object at 0x000001A29B083358&gt;</code></pre><p>现在,你反向跟踪loss,使用它的.grad_fn属性,你会看到向下面这样的一个计算图:</p><p>input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear -&gt; MSELoss -&gt; loss</p><p>所以, 当你调用loss.backward(),整个图被区分为损失以及图中所有具有requires_grad = True的张量，并且其.grad 张量的梯度累积。</p><h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><ul><li><p>为了反向传播误差,我们所需做的是调用loss.backward().你需要清除已存在的梯度,否则梯度将被累加到已存在的梯度。</p></li><li><p>现在,我们将调用loss.backward(),并查看conv1层的偏置项在反向传播前后的梯度。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line">loss.backward()</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([0., 0., 0., 0., 0., 0.])tensor([-0.0026,  0.0136, -0.0092, -0.0128, -0.0098, -0.0080])</code></pre><h4 id="更新网络的权重"><a href="#更新网络的权重" class="headerlink" title="更新网络的权重"></a>更新网络的权重</h4><p>实践中最简单的更新规则是随机梯度下降(SGD)．</p><ul><li>weight=weight−learning_rate∗gradient</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data*learning_rate)</span><br></pre></td></tr></table></figure><p>然而,当你使用神经网络是,你想要使用各种不同的更新规则,比如SGD,Nesterov-SGD,Adam, RMSPROP等.为了能做到这一点,我们构建了一个包torch.optim实现了所有的这些规则.使用他们非常简单:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment">#自定义优化器</span></span><br><span class="line">optimizer=optim.SGD(net.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在训练过程中循环</span></span><br><span class="line">optimizer.zero_grad()  <span class="comment">#将梯度缓冲区置0</span></span><br><span class="line">out=net(input)</span><br><span class="line">loss=criterion(out,target)</span><br><span class="line">loss.backward()</span><br><span class="line"><span class="comment">#更新</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Autograd-自动求导机制&quot;&gt;&lt;a href=&quot;#Autograd-自动求导机制&quot; class=&quot;headerlink&quot; title=&quot;Autograd: 自动求导机制&quot;&gt;&lt;/a&gt;Autograd: 自动求导机制&lt;/h2&gt;&lt;p&gt;PyTorch 中所有神经网络的
      
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch_Day1</title>
    <link href="https://cblog.club/ck3a6ilg9002ejsg4006602sj.html"/>
    <id>https://cblog.club/ck3a6ilg9002ejsg4006602sj.html</id>
    <published>2019-11-18T12:57:55.000Z</published>
    <updated>2019-11-18T14:21:46.550Z</updated>
    
    <content type="html"><![CDATA[<p>之前一直在看keras，但是看了之后，给我一种感觉就是：本来深度学习就已经够黑盒了，你再给我封装的这么死，我不想成为调包侠= =，然后Pytorch最近比较流行，在封装性上也没有keras那么死板，所以尝试学习一下。</p><a id="more"></a><h3 id="PyTorch简介"><a href="#PyTorch简介" class="headerlink" title="PyTorch简介"></a>PyTorch简介</h3><p>PyTorch是一个基于 Python 的科学计算包，主要定位两类人群：</p><ul><li>NumPy的替代品，可以利用GPU的性能进行计算</li><li>深度学习研究平台拥有足够的灵活性和速度</li></ul><p>要介绍PyTorch之前，不得不说一下Torch。Torch是一个有大量机器学习算法支持的科学计算框架，是一个与Numpy类似的张量（Tensor） 操作库，其特点是特别灵活，但因其采用了小众的编程语言是Lua，所以流行度不高，这也就有了PyTorch的出现。所以其实Torch是 PyTorch的前身，它们的底层语言相同，只是使用了不同的上层包装语言。</p><p>PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。它主要由Facebookd的人工智能小组开发，不仅能够 实现强大的GPU加速，同时还支持动态神经网络，这一点是现在很多主流框架如TensorFlow都不支持的。 PyTorch提供了两个高级功能： <em>具有强大的GPU加速的张量计算（如Numpy）</em> 包含自动求导系统的深度神经网络。</p><p>TensorFlow和Caffe都是命令式的编程语言，而且是静态的，首先必须构建一个神经网络，然后一次又一次使用相同的结构，如果想要改 变网络的结构，就必须从头开始。但是对于PyTorch，通过反向求导技术，可以让你零延迟地任意改变神经网络的行为，而且其实现速度快。正是这一灵活性是PyTorch对比TensorFlow的最大优势。</p><p>另外，PyTorch的代码对比TensorFlow而言，更加简洁直观，底层代码也更容易看懂，这对于使用它的人来说理解底层肯定是一件令人激动的事。</p><p>所以，总结一下PyTorch的优点： <strong>支持GPU</strong>，灵活，支持动态神经网络 <strong>底层代码易于理解</strong> 命令式体验、 自定义扩展。</p><p>当然，现今任何一个深度学习框架都有其缺点，PyTorch也不例外，对比TensorFlow，其全面性处于劣势，目前PyTorch还不支持快速傅里 叶、沿维翻转张量和检查无穷与非数值张量；针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；其次因为这个框 架较新，使得他的社区没有那么强大，在文档方面其C库大多数没有文档。 </p><h3 id="PyTorch安装"><a href="#PyTorch安装" class="headerlink" title="PyTorch安装"></a>PyTorch安装</h3><p>直接官网下载： <a href="https://pytorch.org" target="_blank" rel="noopener">https://pytorch.org</a>，在anaconda中输入以下命令即可（先查看自己的cudatoolkit是什么版本，选择对应版本）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</span><br></pre></td></tr></table></figure><p>在下载过程中可能由于是网速不快，pytorch又有点大，所以总是下载失败，可以设置一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="built_in">set</span> remote_read_timeout_secs 600.0</span><br></pre></td></tr></table></figure><p>最后检查PyTorch是否在用GPU加速：</p><ul><li>方法一：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.cuda.is_available()</span><br><span class="line">print(a)</span><br><span class="line">ngpu= <span class="number">1</span></span><br><span class="line"><span class="comment"># Decide which device we want to run on</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> (torch.cuda.is_available() <span class="keyword">and</span> ngpu &gt; <span class="number">0</span>) <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">print(device)</span><br><span class="line">print(torch.cuda.get_device_name(<span class="number">0</span>))</span><br><span class="line">print(torch.rand(<span class="number">3</span>,<span class="number">3</span>).cuda())</span><br></pre></td></tr></table></figure><p>结果如下即可（每个人显卡不一样，这里是自己的电脑配置）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">True</span></span><br><span class="line">cuda:<span class="number">0</span></span><br><span class="line">GeForce GTX <span class="number">950</span>M</span><br><span class="line">tensor([[<span class="number">0.8102</span>, <span class="number">0.1912</span>, <span class="number">0.2961</span>],</span><br><span class="line">        [<span class="number">0.9527</span>, <span class="number">0.1479</span>, <span class="number">0.8146</span>],</span><br><span class="line">        [<span class="number">0.4283</span>, <span class="number">0.3469</span>, <span class="number">0.3501</span>]], device=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></table></figure><ul><li>方法二</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><p>输出为<code>True</code>即可</p><h3 id="开始学习"><a href="#开始学习" class="headerlink" title="开始学习"></a>开始学习</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.cuda.is_available()</span><br><span class="line">print(a)</span><br><span class="line">ngpu= <span class="number">1</span></span><br><span class="line"><span class="comment"># Decide which device we want to run on</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> (torch.cuda.is_available() <span class="keyword">and</span> ngpu &gt; <span class="number">0</span>) <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">print(device)</span><br><span class="line">print(torch.cuda.get_device_name(<span class="number">0</span>))</span><br><span class="line">print(torch.rand(<span class="number">3</span>,<span class="number">3</span>).cuda())</span><br></pre></td></tr></table></figure><pre><code>Truecuda:0GeForce GTX 950Mtensor([[0.2935, 0.9656, 0.2542],        [0.3013, 0.2124, 0.9071],        [0.5502, 0.8500, 0.2255]], device=&apos;cuda:0&apos;)</code></pre><h4 id="Tensors张量，类似于Numpy里的ndarrays，同时Tensors可以使用GPU进行计算"><a href="#Tensors张量，类似于Numpy里的ndarrays，同时Tensors可以使用GPU进行计算" class="headerlink" title="Tensors张量，类似于Numpy里的ndarrays，同时Tensors可以使用GPU进行计算"></a>Tensors张量，类似于Numpy里的ndarrays，同时Tensors可以使用GPU进行计算</h4><ul><li>在开头加上from _<em>future_</em> import print_function这句之后，即使在python2.X，使用print就得像python3.X那样加括号使用python2.X中print不需要括号，而在python3.X中则需要。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br></pre></td></tr></table></figure><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><h4 id="构造一个5x3的矩阵，不初始化"><a href="#构造一个5x3的矩阵，不初始化" class="headerlink" title="构造一个5x3的矩阵，不初始化"></a>构造一个5x3的矩阵，不初始化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[9.2755e-39, 8.4490e-39, 1.0286e-38],        [1.0102e-38, 1.0837e-38, 1.0286e-38],        [1.0653e-38, 1.0194e-38, 4.1328e-39],        [4.2245e-39, 4.2245e-39, 4.2245e-39],        [4.9592e-39, 9.1836e-39, 1.0561e-38]])</code></pre><h4 id="构造一个随机初始化的矩阵"><a href="#构造一个随机初始化的矩阵" class="headerlink" title="构造一个随机初始化的矩阵"></a>构造一个随机初始化的矩阵</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0.9536, 0.5859, 0.3502],        [0.2301, 0.2587, 0.7727],        [0.3513, 0.1247, 0.0136],        [0.6168, 0.2126, 0.5314],        [0.8289, 0.0799, 0.9224]])</code></pre><h4 id="构造一个矩阵全为0，且数据类型为long"><a href="#构造一个矩阵全为0，且数据类型为long" class="headerlink" title="构造一个矩阵全为0，且数据类型为long"></a>构造一个矩阵全为0，且数据类型为long</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.zeros(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.long)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0, 0, 0],        [0, 0, 0],        [0, 0, 0],        [0, 0, 0],        [0, 0, 0]])</code></pre><h4 id="构造一个张量，直接使用设定的数据"><a href="#构造一个张量，直接使用设定的数据" class="headerlink" title="构造一个张量，直接使用设定的数据"></a>构造一个张量，直接使用设定的数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.tensor([<span class="number">5.5</span>,<span class="number">3</span>])</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([5.5000, 3.0000])</code></pre><h4 id="创建一个张量（Tensor）基于已经存在的张量-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖"><a href="#创建一个张量（Tensor）基于已经存在的张量-这些方法将重用输入张量的属性，例如，-dtype，除非设置新的值进行覆盖" class="headerlink" title="创建一个张量（Tensor）基于已经存在的张量,这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖"></a>创建一个张量（Tensor）基于已经存在的张量,这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖</h4><ul><li>new_*方法来创建对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=x.new_ones(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.double)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]], dtype=torch.float64)</code></pre><ul><li>覆盖了dtype，但是对象的size还是相同的，只是值和类型发生了变化<ul><li>使用size方法与Numpy的shape属性返回的相同，张量也支持shape属性，后面会详细介绍</li><li>torch.Size 返回值是 tuple类型, 所以它支持tuple类型的所有操作.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=torch.randn_like(x,dtype=torch.float)</span><br><span class="line">print(x)</span><br><span class="line">print(x.size())</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.3013,  0.9319, -1.0935],        [-1.9418,  0.3797,  1.4079],        [ 0.4928, -0.9644, -0.5722],        [-0.3585,  0.5682, -0.6689],        [-0.5044, -0.4755, -1.2299]])torch.Size([5, 3])</code></pre><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><ul><li>加法操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y=torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">print(x+y)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.7946,  1.0250, -0.8948],        [-1.2244,  0.6311,  1.6266],        [ 0.5959, -0.7320,  0.3882],        [-0.1263,  0.8522,  0.0948],        [-0.4211,  0.1972, -0.4704]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(torch.add(x,y))</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.7946,  1.0250, -0.8948],        [-1.2244,  0.6311,  1.6266],        [ 0.5959, -0.7320,  0.3882],        [-0.1263,  0.8522,  0.0948],        [-0.4211,  0.1972, -0.4704]])</code></pre><h4 id="提供输出tensor作为参数"><a href="#提供输出tensor作为参数" class="headerlink" title="提供输出tensor作为参数"></a>提供输出tensor作为参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result=torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">torch.add(x,y,out=result)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.7946,  1.0250, -0.8948],        [-1.2244,  0.6311,  1.6266],        [ 0.5959, -0.7320,  0.3882],        [-0.1263,  0.8522,  0.0948],        [-0.4211,  0.1972, -0.4704]])</code></pre><h4 id="任何-以-结尾的操作都会用结果替换原变量-例如-x-copy-y-x-t-都会改变x"><a href="#任何-以-结尾的操作都会用结果替换原变量-例如-x-copy-y-x-t-都会改变x" class="headerlink" title="任何 以 _ 结尾的操作都会用结果替换原变量. 例如: x.copy_(y), x.t_(), 都会改变x."></a>任何 以 _ 结尾的操作都会用结果替换原变量. 例如: x.copy_(y), x.t_(), 都会改变x.</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.7946</span>,  <span class="number">1.0250</span>, <span class="number">-0.8948</span>],</span><br><span class="line">        [<span class="number">-1.2244</span>,  <span class="number">0.6311</span>,  <span class="number">1.6266</span>],</span><br><span class="line">        [ <span class="number">0.5959</span>, <span class="number">-0.7320</span>,  <span class="number">0.3882</span>],</span><br><span class="line">        [<span class="number">-0.1263</span>,  <span class="number">0.8522</span>,  <span class="number">0.0948</span>],</span><br><span class="line">        [<span class="number">-0.4211</span>,  <span class="number">0.1972</span>, <span class="number">-0.4704</span>]])</span><br></pre></td></tr></table></figure><h4 id="你可以使用与NumPy索引方式相同的操作来进行对张量的操作"><a href="#你可以使用与NumPy索引方式相同的操作来进行对张量的操作" class="headerlink" title="你可以使用与NumPy索引方式相同的操作来进行对张量的操作"></a>你可以使用与NumPy索引方式相同的操作来进行对张量的操作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(x)</span><br><span class="line">print(x[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0.3013</span>,  <span class="number">0.9319</span>, <span class="number">-1.0935</span>],</span><br><span class="line">        [<span class="number">-1.9418</span>,  <span class="number">0.3797</span>,  <span class="number">1.4079</span>],</span><br><span class="line">        [ <span class="number">0.4928</span>, <span class="number">-0.9644</span>, <span class="number">-0.5722</span>],</span><br><span class="line">        [<span class="number">-0.3585</span>,  <span class="number">0.5682</span>, <span class="number">-0.6689</span>],</span><br><span class="line">        [<span class="number">-0.5044</span>, <span class="number">-0.4755</span>, <span class="number">-1.2299</span>]])</span><br><span class="line">tensor([ <span class="number">0.9319</span>,  <span class="number">0.3797</span>, <span class="number">-0.9644</span>,  <span class="number">0.5682</span>, <span class="number">-0.4755</span>])</span><br></pre></td></tr></table></figure><h4 id="torch-view-可以改变张量的维度和大小-与Numpy的reshape类似"><a href="#torch-view-可以改变张量的维度和大小-与Numpy的reshape类似" class="headerlink" title="torch.view: 可以改变张量的维度和大小, 与Numpy的reshape类似"></a>torch.view: 可以改变张量的维度和大小, 与Numpy的reshape类似</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x=torch.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">print(x.size())</span><br><span class="line">y=x.view(<span class="number">16</span>)</span><br><span class="line"><span class="comment"># size -1 从其他维度推断</span></span><br><span class="line">z=x.view(<span class="number">-1</span>,<span class="number">8</span>)</span><br><span class="line">print(y.size())</span><br><span class="line">print(z.size())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">torch.Size([<span class="number">16</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure><h4 id="如果你有只有一个元素的张量，使用-item-来得到Python数据类型的数值"><a href="#如果你有只有一个元素的张量，使用-item-来得到Python数据类型的数值" class="headerlink" title="如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值"></a>如果你有只有一个元素的张量，使用.item()来得到Python数据类型的数值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=torch.randn(<span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line">print(x.item())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">0.0918</span>])</span><br><span class="line"><span class="number">0.0918206200003624</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前一直在看keras，但是看了之后，给我一种感觉就是：本来深度学习就已经够黑盒了，你再给我封装的这么死，我不想成为调包侠= =，然后Pytorch最近比较流行，在封装性上也没有keras那么死板，所以尝试学习一下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
      <category term="深度学习" scheme="https://cblog.club/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>347前K个高频元素</title>
    <link href="https://cblog.club/ck3a6ile1000kjsg46v4jc407.html"/>
    <id>https://cblog.club/ck3a6ile1000kjsg46v4jc407.html</id>
    <published>2019-11-18T12:06:04.000Z</published>
    <updated>2019-11-18T12:12:17.093Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个非空的整数数组，返回其中出现频率前 <strong>k</strong> 高的元素。 </p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: nums = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>], k = <span class="number">2</span></span><br><span class="line">输出: [<span class="number">1</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: nums = [<span class="number">1</span>], k = <span class="number">1</span></span><br><span class="line">输出: [<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p><strong>说明：</strong></p><ul><li>你可以假设给定的 <em>k</em> 总是合理的，且 1 ≤ k ≤ 数组中不相同的元素的个数。</li><li>你的算法的时间复杂度<strong>必须</strong>优于 O(<em>n</em> log <em>n</em>) , <em>n</em> 是数组的大小。</li></ul></blockquote><h6 id="解题思路：其实本题思路还是比较容易想到的，我们把key设计成数组中出现的元素值，value设置成其出现的次数，然后使用sort函数按照value的值进行降序排列，但是sort只能给顺序类容器排序，而map的元素是pair类型，所以我们将一个pair类型插入到数组中，然后自定义排序规则，最后在使用sort排序即可，这种自定义sort排序，还是要掌握一点，这样遇到和排序相关的题目就可以直接用即可（快排一定手撕一下）。"><a href="#解题思路：其实本题思路还是比较容易想到的，我们把key设计成数组中出现的元素值，value设置成其出现的次数，然后使用sort函数按照value的值进行降序排列，但是sort只能给顺序类容器排序，而map的元素是pair类型，所以我们将一个pair类型插入到数组中，然后自定义排序规则，最后在使用sort排序即可，这种自定义sort排序，还是要掌握一点，这样遇到和排序相关的题目就可以直接用即可（快排一定手撕一下）。" class="headerlink" title="解题思路：其实本题思路还是比较容易想到的，我们把key设计成数组中出现的元素值，value设置成其出现的次数，然后使用sort函数按照value的值进行降序排列，但是sort只能给顺序类容器排序，而map的元素是pair类型，所以我们将一个pair类型插入到数组中，然后自定义排序规则，最后在使用sort排序即可，这种自定义sort排序，还是要掌握一点，这样遇到和排序相关的题目就可以直接用即可（快排一定手撕一下）。"></a>解题思路：其实本题思路还是比较容易想到的，我们把key设计成数组中出现的元素值，value设置成其出现的次数，然后使用sort函数按照value的值进行降序排列，但是sort只能给顺序类容器排序，而map的元素是pair类型，所以我们将一个pair类型插入到数组中，然后自定义排序规则，最后在使用sort排序即可，这种自定义sort排序，还是要掌握一点，这样遇到和排序相关的题目就可以直接用即可（快排一定手撕一下）。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; topKFrequent(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;umap;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;result;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.size();i++)&#123;</span><br><span class="line">            umap[nums[i]]++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;&gt;vec_umap(umap.begin(), umap.end());</span><br><span class="line">        sort(vec_umap.begin(), vec_umap.end(), </span><br><span class="line">        [](<span class="keyword">const</span> pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; &amp;x, <span class="keyword">const</span> pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; &amp;y) -&gt; <span class="keyword">int</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> x.second &gt; y.second;</span><br><span class="line">    &#125;);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;k;i++)&#123;</span><br><span class="line">            result.push_back(vec_umap[i].first);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个非空的整数数组，返回其中出现频率前 &lt;strong&gt;k&lt;/strong&gt; 高的元素。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
  </entry>
  
</feed>

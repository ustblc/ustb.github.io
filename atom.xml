<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">
  <title>lemon</title>
  
  <subtitle>一直在路上</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://cblog.club/"/>
  <updated>2019-11-25T11:37:48.973Z</updated>
  <id>https://cblog.club/</id>
  
  <author>
    <name>lemon</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CTC简单了解</title>
    <link href="https://cblog.club/ck3ecxtpq0028v0g49iwz7cvf.html"/>
    <id>https://cblog.club/ck3ecxtpq0028v0g49iwz7cvf.html</id>
    <published>2019-11-25T11:34:20.000Z</published>
    <updated>2019-11-25T11:37:48.973Z</updated>
    
    <content type="html"><![CDATA[<p>CTC（ Connectionist Temporal Classification ）算法</p><p>读了一篇关于水表数字识别的论文，里面有个名词CTC，没有接触过，所以找了一些资料来看，特此记录一下，主要是记录下它的作用，具体的算法及其推导，暂时还没看 = =！（太难了）</p><a id="more"></a><p>现实应用中许多问题可以抽象为序列学习（sequence learning）问题，比如词性标注（POS Tagging）、语音识别（Speech Recognition）、手写字识别（Handwriting Recognition）、机器翻译（Machine Translation）等应用，其核心问题都是训练模型把一个领域的（输入）序列转成另一个领域的（输出）序列。近年来基于RNN的序列到序列模型（sequence-to-sequence models）在序列学习任务中取得了显著的效果提升，本文介绍一种RNN（Recurrent Neural Networks）的端到端训练方法——CTC（Connectionist Temporal Classification）算法，它可以让RNN直接对序列数据进行学习，而无需事先标注好训练数据中输入序列和输出序列的映射关系，打破了RNN应用于语音识别、手写字识别等领域的数据依赖约束，使得RNN模型在序列学习任务中取得更好的应用效果。 </p><p>在序列学习任务中，RNN模型对训练样本一般有这样的依赖条件：输入序列和输出序列之间的映射关系已经事先标注好了。比如，在词性标注任务中，训练样本中每个词（或短语）对应的词性会事先标注好，如下图（DT、NN等都是词性的标注，具体含义请参考 <a href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" target="_blank" rel="noopener">链接</a> ）。由于输入序列和输出序列是一一对应的，所以RNN模型的训练和预测都是端到端的，即可以根据输出序列和标注样本间的差异来直接定义RNN模型的Loss函数，传统的RNN训练和预测方式可直接适用。 </p><img src="/ck3ecxtpq0028v0g49iwz7cvf/image-20191125192036324.png" class=""><p>然而，在语音识别、手写字识别等任务中，由于音频数据和图像数据都是从现实世界中将模拟信号转为数字信号采集得到，这些数据天然就很难进行“分割”，这使得我们很难获取到包含输入序列和输出序列映射关系的大规模训练样本（人工标注成本巨高，且启发式挖掘方法存在很大局限性）。因此，在这种条件下，RNN无法直接进行端到端的训练和预测。</p><p>如下图，输入是“apple”对应的一段说话音频和手写字图片，从连续的音频信号和图像信号中逐一分割并标注出对应的输出序列非常费时费力，在大规模训练下这种数据要求是完全不切实际的。而如果输入序列和输出序列之间映射关系没有提前标注好，那传统的RNN训练方式就不能直接适用了，无法直接对音频数据和图像数据进行训练。</p><img src="/ck3ecxtpq0028v0g49iwz7cvf/image-20191125192114162.png" class=""><p>因此，在语音识别、图像识别等领域中，由于数据天然无法切割，且难以标注出输入和输出的序列映射关系，导致传统的RNN训练方法不能直接适用。那么，如何让RNN模型实现端到端的训练成为了关键问题。 </p><p>Connectionist Temporal Classification（CTC）[1]是Alex Graves等人在ICML 2006上提出的一种端到端的RNN训练方法，它可以让RNN直接对序列数据进行学习，而无需事先标注好训练数据中输入序列和输入序列的映射关系，使得RNN模型在语音识别等序列学习任务中取得更好的效果，在语音识别和图像识别等领域CTC算法都有很比较广泛的应用。总的来说，CTC的核心思路主要分为以下几部分： </p><ul><li><p>它扩展了RNN的输出层，在输出序列和最终标签之间增加了多对一的空间映射，并在此基础上定义了CTC Loss函数 </p></li><li><p>它借鉴了HMM（Hidden Markov Model）的Forward-Backward算法思路，利用动态规划算法有效地计算CTC Loss函数及其导数，从而解决了RNN端到端训练的问题 </p></li><li><p>最后，结合CTC Decoding算法RNN可以有效地对序列数据进行端到端的预测 </p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CTC（ Connectionist Temporal Classification ）算法&lt;/p&gt;
&lt;p&gt;读了一篇关于水表数字识别的论文，里面有个名词CTC，没有接触过，所以找了一些资料来看，特此记录一下，主要是记录下它的作用，具体的算法及其推导，暂时还没看 = =！（太难了）&lt;/p&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="https://cblog.club/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://cblog.club/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>全卷积序列识别网络用于水表数字识别</title>
    <link href="https://cblog.club/ck3ecxtr1003qv0g4dgm5f8nu.html"/>
    <id>https://cblog.club/ck3ecxtr1003qv0g4dgm5f8nu.html</id>
    <published>2019-11-25T08:04:54.000Z</published>
    <updated>2019-11-25T08:27:46.049Z</updated>
    
    <content type="html"><![CDATA[<p>最近，读了一篇FCN的论文，然后记录一下，准备回看~</p><h2 id="Fully-Convolutional-Sequence-Recognition-Network-for-Water-Meter-Number-Reading"><a href="#Fully-Convolutional-Sequence-Recognition-Network-for-Water-Meter-Number-Reading" class="headerlink" title="Fully Convolutional Sequence Recognition Network for Water Meter Number Reading"></a>Fully Convolutional Sequence Recognition Network for Water Meter Number Reading</h2><p>全卷积序列识别网络用于水表数字识别（团队来自华南理工大学电子与信息工程学院）</p><a id="more"></a><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>卷积循环神经网络（CRNN）是图像序列识别中应用最为广泛的框架之一，它使用卷积神经网络（CNN）进行特征提取，使用递归神经网络（RNN）进行序列建模。然而，RNN在训练和推理方面都存在计算量大的问题，限制了它在有时间约束的系统中的应用。一些模型用序列建模的注意机制代替RNN，但是仍然需要昂贵的迭代计算。本文认为，具有足够深度的CNN可以捕获上下文信息，消除重复操作和并行化的需要。我们关注水表读数（WNR）的问题，这是一个典型的序列识别任务，但很少被研究。我们提出了一个完整的进化序列识别网络（FCSRN），用于快速准确地读取水表编号。此外，我们还设计了一个增加损失（AugLoss）函数来有效地管理数字的中间状态，提高了性能。实验结果表明，该函数具有捕获上下文信息和消除循环层需求的能力，同时需要的参数更少，计算量更少。带AugLoss的FCSRN优于基于RNN和基于注意的模型。此外，AugLoss可以有效地提高基于RNN和基于注意的模型的性能。此外，我们构建并发布了一个包含6000张带有标签的水表图像的数据集，可在<a href="https://github.com/HCIILAB/water-meter-Number-dataset" target="_blank" rel="noopener">https://github.com/HCIILAB/water-meter-Number-dataset</a> 上找到。</p><h3 id="I-引言"><a href="#I-引言" class="headerlink" title="I.引言"></a>I.引言</h3><p>自动化的水表数字识别在许多实际应用中都有很大的需求，如用水收费系统和实时监测用水量。在文献中提出的水表读数方法中，最常见的是使用嵌入式电子装置（例如光电装置或超声波装置）来计算或测量水流量。近年来，一种新的方法开始引起研究人员的注意，它利用摄像机捕捉水表图像，然后识别图像中的数字。该方法具有灵活性高、易于实现、能充分利用现有测量设备的优点。例如，机械式水表是输水系统中最受欢迎、最稳定的测量设备，在可预见的将来很难被电子式水表取代。最重要的一点是，水表图像的捕获可以用来防止关于用水的欺骗，因为目前，在电子设备上比在图像上更容易欺骗。水表图像中的水表号码读取流程包括：首先检测和裁剪图像中的号码区域，然后识别裁剪图像中的水表号码。本文的第二部分（也就是我们所关注的）是水表读数问题，它是一个典型的基于图像的序列识别任务。</p><p>基于图像的序列识别任务有几种通用的解决方案。</p><ul><li>第一类是基于分割的方法，它包括两个步骤：数字分割和识别。例如，Bissacco等人使用边界框检测到数字，使用预先训练的卷积神经网络（CNN）模型识别检测到的数字，最后结合上下文信息得到识别结果。这种方法要求每个数字都易于定位和标记，因此不适合识别数字难以分割的图像。</li><li>第二类解决方案称为无分割方法，包括整体方法、基于循环神经网络（RNN）的方法和基于注意力（attention）的方法。<ul><li>整体方法将图像中的一串数字识别为一个整体，而不识别每个单独的数字。例如，Jaderberg等人训练CNN对不同的英语单词进行直接分类。这些方法严重依赖于预定义的词汇表，并且缺乏识别词汇表外单词的能力。此外，对于带有“0 0 0 0 0”等标签的水表图像（水表图像只有五个数字，但每个数字的范围为“0”到“19”），可能的组合的总数可以高达20^5=3.2×10^6，这就排除了使用整体方法的可能性。</li><li>基于RNN的方法通过在特征序列（通常来自CNN）上迭代，并在每个时间步执行识别来避免分割问题。大多数无分割序列识别系统使用具有长短期记忆单元（LSTM）的RNN，其成功地证明了无需精确分割即可使输入和输出序列一致的能力（也就是正确的识别）。虽然基于RNN的系统的结果是令人印象深刻的，但存在两个重要缺点：（1）由于循环层中的在时间步长上的迭代矩阵乘法，这导致训练速度可能很慢；（2）优化过程可能遭受梯度消失/爆炸问题。<ul><li>简单介绍一下什么是梯度消失（比如说0.9^30）和梯度爆炸（比如说1.1^30）： 两种情况下梯度消失经常出现，一是在<strong>深层网络</strong>中，二是采用了<strong>不合适的损失函数</strong>，比如sigmoid。梯度爆炸一般出现在深层网络和<strong>权值初始化值太大</strong>的情况下。</li></ul></li><li>最近，注意机制已经成为各种任务中引人注目的序列建模和转换模型的重要组成部分，从而允许在不考虑输入或输出序列中的距离的情况下建立依赖关系的模型。在大多数情况下，注意机制与RNN结合使用。然而，一般来说，注意机制可用于任何基于神经网络的模型。Gehring等人提出了卷积seq2seq学习模型。（ 顾名思义，seq2seq 模型就像一个翻译模型，输入是一个序列（比如一个英文句子），输出也是一个序列（比如该英文句子所对应的法文翻译。这种结构最重要的地方在于输入序列和输出序列的长度是可变的，它们不一定等长的。 ）输入的表示是由CNN以并行方式为注意机制计算的；解码器状态也由CNN确定，这个CNN具有已经产生的特征。虽然基于注意的卷积系统的结果是令人印象深刻的，但存在一个缺点：注意力权重的计算只能在训练期间完全并行化，而在推理时，当前时间步的注意权重的计算必须依赖于上一个时间步的输出，这是不容易并行化的。</li></ul></li></ul><p>水表数字识别WNR与文本识别任务相似，但其解码过程略有不同，因为在WNR中存在一些“中间状态”字符。为了建立一个快速、准确的WNR系统，我们提出了一个全卷积序列识别网络（FCSRN），它将全卷积网络（FCN）和CTC结合起来，不需要任何中间循环连接。此外，通过分析解码后的后处理方法，我们提出了一个增加损失（AugLoss）函数来有效地提高网络性能。</p><p>实验结果表明，FCSRN具有捕获上下文信息、消除循环层的能力，同时所需参数少、计算量小。带AugLoss的FCSRN优于基于RNN和基于注意的模型。此外，AugLoss可以有效地提高基于RNN和基于注意的模型的性能。</p><p>本文的其余部分组织如下：在第二节中，我们描述了构建的水表图像数据集。然后，我们在第三节介绍了所提出的FCSRN，在第四节介绍了AugLoss，在第五节介绍了实验结果，并对本文进行了总结。</p><h3 id="II-水表图像数据集"><a href="#II-水表图像数据集" class="headerlink" title="II.水表图像数据集"></a>II.水表图像数据集</h3><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191124170829347.png" class=""><pre><code>图1</code></pre><p>为了研究WNR，我们构建了一个名为SCUT-WMN的非商业用途数据集，可在<a href="https://github.com/HCIILAB/Water-Meter-Number-dataset" target="_blank" rel="noopener">https://github.com/HCIILAB/Water-Meter-Number-dataset</a> 上获得。据我们所知，这是第一个公共水表图像数据集。水表图像由摄像机拍摄，并使用边界框和水表数字进行标记。我们裁剪了边界框区域以构建用于识别的数据集。数据集由两部分组成。第一部分包含5000个困难样品（如图1a所示）。在这些困难的样本中，由于光照、折射和遮挡等原因，会产生很大的变化。第二部分包含1000个简单样本（如图1b所示）。困难样本和简单样本都用连续字符标记，如“1  2 2 5 8”。此外，数据集中每个字符的数量如下图表所示。</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191124171646580.png" class="">    <p>​                                                                                                            图2</p><p>在WNR中，存在一些“中间状态”字符，如图2所示。考虑到第4个图片，图2b（第二行第一列）中的图片作为示例，数字超过“20369”，但未达到“20370”，因此数字中的最后两个字符显示在“中间状态”。此外，正确的水表编号应为“20369.5”。为了管理“中间状态”字符，我们将它们视为单独的类，标签范围从“10”到“19”，如图2所示。标签L∈[10,19]表示超过“L-10”（称为“低状态”）但未达到“L-9”（称为“高状态”）的字符。举个例子吧，比较直观，你看16（还是上文中的图），他就代表超过了6（16-10，这个我们叫低状态），但是没有超过7（16-9，这个我们叫高状态） = =！</p><p>特殊情况下，标签“L=19”表示字符处于“9”和“0”之间的“中间状态”（忽略进位）。在这种设置中，图2b中的第四章图片的标签是“2  0 3 16 19”。该标签序列可进一步处理为第III-D节所述的水表编号“20369.5”，这在实际应用中更为合理和实用。</p><h3 id="全卷积序列识别网络"><a href="#全卷积序列识别网络" class="headerlink" title="|||.全卷积序列识别网络"></a>|||.全卷积序列识别网络</h3><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191124173018340.png" class="">    <p>​                                                                                                        图3</p><p>所提出的FCSRN由三个部分组成：全卷积骨干网、时间映射器和转录层（如图3所示）。卷积层在从图像中学习特征方面非常强大，我们使用FCN作为骨干网络。在FCN的基础上，利用时间映射器从二维特征图中生成一维特征序列。最后，转录层将这些序列特征转化为最终的标签序列。</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191124173318716.png" class="">    <p>​                                                                                                                        图4</p><h4 id="A-全卷积网络"><a href="#A-全卷积网络" class="headerlink" title="A.全卷积网络"></a>A.全卷积网络</h4><p>我们使用何恺明大神在深度残差网络中提出的剩余块来构建FCN作为骨干网。我们的FCSRN采用了两种类型的剩余块，如图4所示。当输入x和输出y的维数相同时，剩余块A（如左图所示）用于从增加深度的模型中获得较大的感受野，并避免臭名昭著的梯度消失/爆炸问题，而剩余块B（右示）用于减少特征映射，并增加一倍滤波器数量以增加模型能力并保持模型复杂度。在每个卷积层之后使用BN层（批处理归一化，也是用于防止梯度消失/爆炸）和ReLU激活函数。</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191124174235546.png" class="">    <p>​                                                                                                                                表2</p><p>我们构造了一个16层FCN，其中包含残差块，用于从输入图像中提取特征，如表2所示。我们使用较小的卷积核大小（3×3）来学习精细的局部特征，并使用堆栈多卷积层来提取具有大感受野的长期特征。响应图中的位置对应于输入图像中的矩形区域（称为感受野）。计算准确位置和感受野大小的分层公式如下（1，2）：</p><img class="-20191124174819870.png">    <p>其中ri是i层的局部区域大小，k是卷积核的大小，s是步长大小，p表示位置，d是特定层的填充大小。我们发现，深度足够的CNN中的高层特征对应于大的感受野，并且能够利用上下文信息捕获长期依赖关系。</p><h4 id="B-时间映射器"><a href="#B-时间映射器" class="headerlink" title="B.时间映射器"></a>B.时间映射器</h4><p>由于从FCN中提取的特征已经包含上下文信息，因此我们使用时间映射器而不是任何循环或全连接层来在转换层之前生成特征序列。时间映射器由卷积层、批处理规范化BN层和高度规范化HN层（没听说这个= =）组成。卷积层输出K（总字符类加空白）通道特征映射，为每个对应类别生成一个特征映射。</p><p>卷积层优先于完全连接层，因为卷积结构更自然地加强特征映射和类别之间的对应关系[34]。卷积层的核大小、步长和填充大小分别设置为3×3、1和1。我们假设输入特征映射的每一列都是要预测的时间步；因此，我们使用高度规范化层（也称为平均池层）来规范化每一列的特征。因此，我们可以将二维特征映射到一维序列特征，这些序列特征将被输入到最终的转录层中。如第V-D3节所述，映射的序列特征包含转录所需的上下文信息。</p><h4 id="C-转换层"><a href="#C-转换层" class="headerlink" title="C.转换层"></a>C.转换层</h4><p>在WNR中，转录用于将特征转换为从“0”到“19”范围内的字符序列。我们使用连接主义时间分类（CTC）作为转换层。CTC允许在输入序列和标签之间没有任何预先对齐的情况下对模型进行训练。（ CTC，Connectionist Temporal Classification，用来解决输入序列和输出序列难以一一对应的问题。 ）</p><p>让我们将字符表示为C={0,1，···，19，blank}，其中blank表示在相应的时间步没有预测。给定输入特征序列“s^k=s1^k  s2^k··st^k” ，通道k=21，总时间步长t，CTC通过对每个时间步长应用softmax函数指定序列上的分布，并提供在相应时间步长输出预测字符的概率。从该分布中采样的每个潜序列可以使用映射函数SGM变换成输出序列，该映射函数首先将连续重复的非空字符合并为一个字符，然后去除空白字符。例如，“1 2 2 5 8”可以由序列“b b 1 1 b 2 2 2 b b 2 b b b 5 8 8 b b b”的σ变换（其中b表示空白，T=20，过程就是先把连续重复的数字合并为一个字符，比如”b b 1 b 2 b b 2 b b b 5 8 b b b “，然后再把空字符删掉，就变成了”1 2 2 5 8”）。最终的输出序列概率是应用函数σ后对模拟目标结果的所有可能序列的总和。</p><h4 id="D-解码"><a href="#D-解码" class="headerlink" title="D.解码"></a>D.解码</h4><p>我们使用naive(天真的)解码算法（也称为最佳路径解码）来对FCSRN的输出进行预测。我们首先在每个时间步上使用一个softmax函数，然后在每个时间步t上考虑最可能的标签lt，得到预测序列，最后使用函数σ（见第III-C节）映射结果。</p><p>如第二节所述，解码后的图像（在图2b中，在第2行，第1列）的转换结果为：“2 0 3 16  19”，并且在实际应用中，该预测应转换为“20369.5”。因此，我们为处于“中间状态”的每个字符c引入一种后处理方法：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191124192303530.png" class=""><p>如果预测的数字在序列的末尾并且处于“中间状态”（详见第二节），则我们从该数字中减去9.5。例如，对于预测结果“12”，即对应的数字超过“2”，但未达到“3”，我们选择将其预测为“2”，并通过将0.5添加到最终数字来向结果附加“中间状态”标志。如果“中间状态”字符不是最后一个字符，那么我们只需从数字中减去10，从而表明选择了“较低状态”，这在直觉上更为合理。</p><h3 id="IV-增广损失函数"><a href="#IV-增广损失函数" class="headerlink" title="IV.增广损失函数"></a>IV.增广损失函数</h3><h4 id="A-CTC的增广损失函数"><a href="#A-CTC的增广损失函数" class="headerlink" title="A.CTC的增广损失函数"></a>A.CTC的增广损失函数</h4><p>对于基于FCSRN和RNN的模型，我们使用CTC作为目标函数。给定长度为T的输入序列x，使用softmax函数对向量yt进行规范化，然后解释为在时间步t时刻索引k的标签（或空白）的概率（对应于数字）：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125141133902.png" class=""><p>其中yk是yt的元素k。CTC校准a是长度为T的空白和标签序列。a的概率Pr（a |x）是每个时间步的排放概率的乘积：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125141601563.png" class=""><p>对于一个给定的转录序列，有尽可能多的可能的排列方式，以不同的方式将标签与空白区分开。另外，输出转录y的总概率等于与之对应的排列的概率之和：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125141731428.png" class=""><p>给定目标转录y*，然后可以训练该模型以最小化CTC目标函数</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125141817667.png" class=""><p>如第二节所述，超过“5”（“低状态”）但未达到“6”（“高状态”）的字符定义为“中间状态”，应标记为“15”。直观地说，模型区分“低状态”、“中状态”和“高状态”字符是令人困惑的。然而，对于标签为“1 2 12 15 8”的样本，我们是是可以容忍将他们转换成这样的，举个例子：例如“1 12 12 15 8”或“1 12 2 15 8”，因为所有这些可能的预测都可以解码为相同的结果“12258”，如第III-D节所述。因此，我们引入一个增加损失（表示为AugLoss），它用相应的“低状态”标签（表示为y’）计算预测的CTC损失，以及用真值标签计算的正常CTC损失（表示为CTCLoss）：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125142604569.png" class=""><p>直观地说，这两个损失都是WNR中识别精度的指标。我们联合训练这两种损失的网络，以提高辨别能力：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125142707145.png" class=""><p>其中调整参数α表示AugLoss损失的权重。AugLoss可以解释为将“中间状态”偏向“较低状态”，而不是“高状态”或“非状态”（例如预测“1”到“7”）预测。我们将第一种情况称为“错误状态”错误（MSE），将其他情况称为“错误识别”错误（MRE）。如V-E节所示，Au’gLoss损失可以有效地降MRE，提高性能。</p><h4 id="B-基于注意力的模型的增加损失"><a href="#B-基于注意力的模型的增加损失" class="headerlink" title="B.基于注意力的模型的增加损失"></a>B.基于注意力的模型的增加损失</h4><p>对于基于注意的模型，我们使用softmax交叉熵函数作为目标函数。输出y的概率PrA（y | x）是每个时间步的排放概率的乘积：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125143147521.png" class=""><p>给定目标转录y∗，然后可以训练该模型以最小化以下目标函数：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125143242520.png" class=""><p>如第IV-A节所述，我们将增加损失函数定义如下：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125143325808.png" class=""><p>此外，基于注意力的模型的损失函数是：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125143354016.png" class=""><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="A-数据预处理"><a href="#A-数据预处理" class="headerlink" title="A.数据预处理"></a>A.数据预处理</h4><p>SCUT-WMN数据集包含5000个困难样本和1000个简单样本，这些样本包含广泛的图像大小和比率。所有（困难和容易）样本的最大和最小宽度分别为418和201像素。最大和最小高度分别为111和37像素。此外，最大和最小纵横比（宽度/高度）分别为6.619和2.933。</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125143609688.png" class=""><p>为了并行计算，我们调整了所有图像的大小，使其具有相同的高度和宽度w，并在图像的相对较短的一侧使用必要的零填充（通过将图像比率与w/H进行比较）。数据预处理的目的是管理不同的图像大小，同时保留比例以避免失真。设W（宽度）=160，H（高度）=48，如图5所示。</p><h4 id="B-性能评估"><a href="#B-性能评估" class="headerlink" title="B.性能评估"></a>B.性能评估</h4><p>对于WNR，我们使用两个标准来衡量性能：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125143905837.png" class=""><p>其中，LCR表示线正确率，AR表示准确率。Nc是正确识别的样本数，Nl是测试样本数，Nt是测试集中的字符数。替换错误、删除错误和插入错误是通过使用动态编程的纠错字符串匹配来计算的。我们还提出了另一个标准，称为线部分准确率（LPR）：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125144508213.png" class=""><p>其中Nc’是部分正确识别的样本数，指预测包含错误字符但可以解码为正确目标数的样本，如第III-D节所述。例如，真实值“1  2 12 15 8”和预测值“1 12 12 15 8”或“1 12 2 15  8”的样本是部分正确识别的样本，因为这两个预测值可以解码为相同的水表数字：“12258”。</p><p>存在几种可能的预测，在解码后产生相同的目标数。因此，LPR是一种更精确的模型性能测量方法。此外，由“错误识别”和“错误状态”（如第四节所述）引起的错误率分别表示为：</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125144820237.png" class=""><h4 id="C-训练细节"><a href="#C-训练细节" class="headerlink" title="C.训练细节"></a>C.训练细节</h4><p>我们基于SCUT-WMN数据集构造训练集。训练集包含4000个困难样本，测试集由剩余的1000个困难样本构成。对于数据增强实验，我们在训练集中添加了1000个简单样本。</p><p>使用随机梯度下降法最小化模型的目标函数，使用100的批量大小，将学习率、动量和重量衰减分别设置为0.01、0.9和0.0001。网络参数的初始化使用了一个范围为0.01的均匀分布。我们使用MxNet深度学习框架对每个模型进行了100个轮次的训练。</p><h4 id="D-与最先进的方法的比较"><a href="#D-与最先进的方法的比较" class="headerlink" title="D.与最先进的方法的比较"></a>D.与最先进的方法的比较</h4><p>我们评估了WNR任务的各种方法。对于基于分割的方法，我们评估了两个卷积神经网络（ResNet[30]和FCSRN的骨干网络，我们称之为CharNet）。由于SCUT-WMN中的所有图像都包含五位数字，因此我们首先按照第V-A节的说明执行数据预处理，然后手动将每个处理过的图像分成五个等长列。</p><p>然后，任务就变成了单独的字符识别的问题。然而，值得注意的是，在实际应用中，水表可能有各种数字。对于无分割方法，我们评估了所提出的FCSRN、基于RNN的CRNN和基于注意的ConvS2S模型。具体如下：</p><ul><li>1）单独字符识别我们训练了一个18层ResNet作为基准线（输出通道设置为20）。为了与FCSRN进行公平比较，我们训练了一个CNN，该CNN由与FCSRN相同的骨干网、卷积层（核大小设置为3×3、步长设置为1×1、输出通道设置为20）、批处理规范化层和全局池层组成。我们称这个网络为CharNet。目标函数为softmax交叉熵损失函数。</li><li>2）基于RNN的CRNN和基于注意的CONVS2：为了公平比较FCSRN和CRNN，我们构造了一系列模型来确定最优超参数。CRNN模型的骨干网与FCSRN中的FCN相同。我们使用了一个多层LSTM（有k层，其中每层包含n个隐藏单元）和两个完全连接的层（分别输出c和2121通道特征），然后在最后的CTC层之上。我们训练了一系列k∈[1,2,3,4]，n∈[32,48,64128]和c∈[32,48,64,96128256]的模型，得到了在k=1，n=32，c=64时的最优结果。对于基于注意的ConvS2S模型，骨干网与FCSRN相同。我们对编码器和解码器都使用了64个隐藏单元。所有的嵌入，包括解码器在最终线性层（linear）之前产生的输出，都有32个维度。</li><li>3）提出的FCSRN和增加损失：我们评估了有/无AugLoss的FCSRN。对于有AugLoss的FCSRN，分别采用两个时间映射器和两个转录层来计算CTCLoss和AugLoss，并在两个损失中共享相同的FCN。我们训练了一系列模型来确定等式（9）中定义的最优超参数α，并报告了在α=0.2时获得的最佳结果（在下一节中解释）。</li></ul><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125150708754.png" class=""><p>​                                                                                                                        表3</p><p>上述模型的实验结果见表3。我们可以观察到，FCSRN比数字识别模型（ResNet18和CharNet）表现得更好，并且与最佳CRNN和ConvS2S模型具有可比性。因此，我们可以得出结论，具有足够深度和一个大的上下文窗口的卷积模型也能够学习转录所需的上下文依赖性（如第III-a节所述）。与CRNN（convs2）相比，FCSRN的训练时间减少了35%（25%），所涉及的参数减少了45%（33%）。</p><p>FCSRN比CRNN和convs2具有更高的训练速度，这主要是由于卷积运算的并行性，因为循环模型中的计算是连续的，不容易并行化，而注意机制中的解码器需要参数，因此需要更多的训练时间。</p><p>带有AugLoss的FCSRN在很大程度上优于单独字符识别、基于RNN和基于注意机制的模型。与无AugLoss的FCSRN相比，MRE相对降低了54.29%。AugLoss将“低状态”和“中间状态”字符视为同一类；也就是说，标签为“2”且预测为“2”或“12”，不会导致AugLoss出错。但是，标签为“5”的字符预测为“12”时，CTCLoss和AugLoss都会产生错误。因此，该模型学会了在针对AugLoss进行优化时避免MRE，并区分“不同状态”以最小化CTCLoss。因此，AugLoss有效地降低了MRE，提高了性能。</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125151543102.png" class=""><p>​                                                                                                                 表4</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125151643981.png" class=""><p>​                                                                                                                 表5</p><img src="/ck3ecxtr1003qv0g4dgm5f8nu/image-20191125151712556.png" class=""><p>​                                                                                                                 表6</p><h4 id="E-增加损失的效率"><a href="#E-增加损失的效率" class="headerlink" title="E.增加损失的效率"></a>E.增加损失的效率</h4><p>所提出的AugLoss不仅可以用于FCSRN，而且可以改善CharNet、CRNN和ConvS2S的性能，我们用所提出的损失函数对这些模型进行训练，并进行了一系列实验来确定每个模型的最优超参数α。实验结果见表6，最佳结果见表4进行比较。FCSRN、CRNN、ConvS2S和CharNet的最佳优化超参数α* 分别是0.2、0.3、0.2和0.8，相对MRE分别降低54.29%、64.00%、40.30%和40.26%。我们的结论是，AugLoss是一种有效提高WNR任务性能的通用技术。</p><h4 id="F-数据增广"><a href="#F-数据增广" class="headerlink" title="F.数据增广"></a>F.数据增广</h4><p>我们采用了数据增强来提高性能。训练集由4000个困难样本和1000个简单样本组成，在增加图像噪声的情况下，随机调整亮度、饱和度、色调和对比度，然后进行非独立高斯分布的叠加噪声、泊松分布噪声、盐噪声、胡椒噪声和这些噪声的随机组合。实验结果（见表5）表明，数据增强稍微提高了性能。今后的工作将考虑进一步改进。</p><h3 id="VI总结"><a href="#VI总结" class="headerlink" title="VI总结"></a>VI总结</h3><p>本文主要研究了一种典型的基于图像的序列识别问题WNR。我们构建了一个开放式研究的数据集SCUT-WMN，并提出了快速准确识别的FCSRN。此外，还提出了一个增广损失函数来管理字符的中间状态并减少MRE。实验结果表明，FCSRN具有捕获上下文信息和消除重复层的能力，同时所需参数少，计算量小。带AugLoss的FCSRN优于基于RNN和基于注意的模型。此外，AugLoss有效地提高了基于RNN和基于注意的模型的性能。WNR在现实世界中有着许多有前途的应用，我们希望我们的方法和数据集一起能够有助于今后对这一课题的研究。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，读了一篇FCN的论文，然后记录一下，准备回看~&lt;/p&gt;
&lt;h2 id=&quot;Fully-Convolutional-Sequence-Recognition-Network-for-Water-Meter-Number-Reading&quot;&gt;&lt;a href=&quot;#Fully-Convolutional-Sequence-Recognition-Network-for-Water-Meter-Number-Reading&quot; class=&quot;headerlink&quot; title=&quot;Fully Convolutional Sequence Recognition Network for Water Meter Number Reading&quot;&gt;&lt;/a&gt;Fully Convolutional Sequence Recognition Network for Water Meter Number Reading&lt;/h2&gt;&lt;p&gt;全卷积序列识别网络用于水表数字识别（团队来自华南理工大学电子与信息工程学院）&lt;/p&gt;
    
    </summary>
    
    
      <category term="论文" scheme="https://cblog.club/categories/%E8%AE%BA%E6%96%87/"/>
    
      <category term="图像领域" scheme="https://cblog.club/categories/%E8%AE%BA%E6%96%87/%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F/"/>
    
    
      <category term="论文" scheme="https://cblog.club/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="图像领域" scheme="https://cblog.club/tags/%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Django单元测试</title>
    <link href="https://cblog.club/ck3ecxtpy002gv0g43x573303.html"/>
    <id>https://cblog.club/ck3ecxtpy002gv0g43x573303.html</id>
    <published>2019-11-25T01:20:19.000Z</published>
    <updated>2019-11-25T01:43:38.455Z</updated>
    
    <content type="html"><![CDATA[<p>今天又重新回头看了一点关于Django单元测试的内容，写测试真的是一个很好的事情，对于代码重构，后期维护都非常有用。以下是Django文档中关于测试方面的内容，可以作为参考，当然，面对不同的项目，测试也不尽相同，写测试，真的很需要经验，一开始还真是无从下手= =！</p><a id="more"></a><h4 id="Django为测试提供了什么？"><a href="#Django为测试提供了什么？" class="headerlink" title="Django为测试提供了什么？"></a>Django为测试提供了什么？</h4><p>测试网站是一项复杂的任务，因为它由多层逻辑组成 - 从 HTTP 级请求处理，查询模型，到表单验证和处理，以及模板呈现。 </p><p>Django 提供了一个测试框架，其中包含基于 Python 标准<code>unittest</code>库的小型层次结构。尽管名称如此，但该测试框架适用于单元测试和集成测试。 Django 框架添加了 API 方法和工具，以帮助测试 Web 和 Django 特定的行为。这允许您模拟请求，插入测试数据以及检查应用程序的输出。 Django 还提供了一个API（<a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#liveservertestcase" target="_blank" rel="noopener">LiveServerTestCase</a>）和<a href="https://docs.djangoproject.com/en/2.0/topics/testing/advanced/#other-testing-frameworks" target="_blank" rel="noopener">使用不同测试框架</a>的工具，例如，您可以与流行的 <a href="https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing/Cross_browser_testing/Your_own_automation_environment" target="_blank" rel="noopener">Selenium</a> 框架集成，以模拟用户与实时浏览器交互。 </p><p>要编写测试，您可以从任何 Django（或unittest）测试基类（<a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#simpletestcase" target="_blank" rel="noopener">SimpleTestCase</a>, <a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#transactiontestcase" target="_blank" rel="noopener">TransactionTestCase</a>, <a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#testcase" target="_blank" rel="noopener">TestCase</a>, <a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#liveservertestcase" target="_blank" rel="noopener">LiveServerTestCase</a>）派生，然后编写单独的方法，来检查特定功能，是否按预期工作（测试使用 “assert” 方法来测试表达式导致 <code>True</code>或 <code>False</code>值，或者两个值相等，等等。）当您开始测试运行时，框架将在派生类中执行所选的测试方法。测试方法独立运行，具有在类中定义的常见设置和/或拆卸行为，如下所示。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YourTestClass</span><span class="params">(TestCase)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#Setup run before every test method.</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tearDown</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#Clean up run after every test method.</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_something_that_will_pass</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.assertFalse(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_something_that_will_fail</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.assertTrue(<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>大多数测试的最佳基类是 <a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#testcase" target="_blank" rel="noopener">django.test.TestCase</a>。此测试类在运行测试之前，创建一个干净的数据库，并在自己的事务中，运行每个测试函数。该类还拥有一个<a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#django.test.Client" target="_blank" rel="noopener">测试客户端</a>，您可以使用该客户端，模拟在视图级别与代码交互的用户。在下面的部分中，我们将集中讨论使用此<a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#testcase" target="_blank" rel="noopener">TestCase</a> 基类创建的单元测试。 </p><p><strong>注意:</strong> <a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#testcase" target="_blank" rel="noopener">django.test.TestCase</a> 类非常方便，但可能会导致某些测试，比它们需要的速度慢（并非每个测试，都需要设置自己的数据库，或模拟视图交互）。一旦熟悉了这个类可以做什么，您可能希望用可以用更简单的测试类，替换一些测试。 </p><h4 id="你应该测试什么？"><a href="#你应该测试什么？" class="headerlink" title="你应该测试什么？"></a>你应该测试什么？</h4><p>您应该测试自己代码的所有方面，但不要测试 Python 或 Django 的一部分提供的任何库或功能。</p><p>例如，考虑下面定义的 <code>Author</code>模型。您不需要显式测试 <code>first_name</code> 和 <code>last_name</code> 是否已在数据库中正确储存为<code>CharField</code>，因为这是 Django 定义的内容（当然，在实践中，您将不可避免地在开发期间测试此功能）。你也不需要测试<code>date_of_birth</code>是否已被验证为日期字段，因为这也是 Django 中实现的东西。</p><p> 但是，您应该检查用于标签的文本（名字，姓氏，出生日期，死亡），以及为文本分配的字段大小（100个字符），因为这些是您的设计的一部分，可能会在将来被打破/改变。 </p><p>官方文档使用一个在线图书馆为例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Author</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    first_name = models.CharField(max_length=<span class="number">100</span>)</span><br><span class="line">    last_name = models.CharField(max_length=<span class="number">100</span>)</span><br><span class="line">    date_of_birth = models.DateField(null=<span class="literal">True</span>, blank=<span class="literal">True</span>)</span><br><span class="line">    date_of_death = models.DateField(<span class="string">'Died'</span>, null=<span class="literal">True</span>, blank=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_absolute_url</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> reverse(<span class="string">'author-detail'</span>, args=[str(self.id)])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'%s, %s'</span> % (self.last_name, self.first_name)</span><br></pre></td></tr></table></figure><p>同样，您应该检查自定义方法 <code>get_absolute_url()</code> 和 <code>__str__()</code> 是否符合要求，因为它们是您的代码/业务逻辑。在<code>get_absolute_url()</code>的情况下，您可以相信 Django <code>reverse()</code>方法已经正确实现，因此您正在测试的是实际上已经定义了关联的视图。 </p><h4 id="测试结构概述"><a href="#测试结构概述" class="headerlink" title="测试结构概述"></a>测试结构概述</h4><p>在我们详细讨论“测试内容”之前，让我们先简要介绍一下测试的定位和方式。</p><p>Django 使用 unittest 模块的<a href="https://docs.python.org/3/library/unittest.html#unittest-test-discovery" target="_blank" rel="noopener">内置测试查找</a>，它将在任何使用模式<strong>test*.py</strong> 命名的文件中，查找当前工作目录下的测试。如果您正确命名文件，则可以使用您喜欢的任何结构。我们建议您为测试代码创建一个模块，并为模型，视图，表单和您需要测试的任何其他类型的代码，分别创建文件。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">KIMS/</span><br><span class="line">  /tests/</span><br><span class="line">    __init__.py</span><br><span class="line">    test_models.py</span><br><span class="line">    test_forms.py</span><br><span class="line">    test_views.py</span><br></pre></td></tr></table></figure><p>在 LocalLibrary 项目中，创建如上所示的文件结构。<strong>_<em>init_</em>.py</strong> 应该是一个空文件（这告诉 Python 该目录是一个套件包）。您可以通过复制和重命名框架测试文件<strong>/catalog/tests.py</strong>，来创建三个测试文件。 </p><p><strong>注意:</strong> 我们构建 Django 骨架网站时，会自动创建骨架测试文件<strong>/catalog/tests.py</strong> 。将所有测试放入其中是完全“合法的”，但如果测试正确，您将很快得到一个非常庞大且难以管理的测试文件。(全部测试都放在一个文件下，太难管理了= =)</p><p>删除骨架文件，因为我们不需要它。</p><p> 打开 <strong>/catalog/tests/test_models.py</strong>。 该文件应导入<code>django.test.TestCase</code>，如下所示： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.test <span class="keyword">import</span> TestCase</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create your tests here.</span></span><br></pre></td></tr></table></figure><p>通常，您将为要测试的每个模型/视图/表单添加测试类别，并使用个别方法来测试特定功能。在其他情况下，您可能希望有一个分开的类别，来测试特定用例，使用个别的测试函数，来测试该用例的各个方面（例如，测试模型字段已正确验证的类，以及测试每个可能的失败案例的函数）。相同地，这样的结构非常适合您，但最好您能保持一致。</p><p>将下面的测试类别，添加到文件的底部。该类别演示了，如何通过派生<code>TestCase</code>，构建测试用例类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YourTestClass</span><span class="params">(TestCase)</span>:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUpTestData</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"setUpTestData: Run once to set up non-modified data for all class methods."</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"setUp: Run once for every test method to setup clean data."</span>)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_false_is_false</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Method: test_false_is_false."</span>)</span><br><span class="line">        self.assertFalse(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_false_is_true</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Method: test_false_is_true."</span>)</span><br><span class="line">        self.assertTrue(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_one_plus_one_equals_two</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Method: test_one_plus_one_equals_two."</span>)</span><br><span class="line">        self.assertEqual(<span class="number">1</span> + <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>新的类别定义了两个可用于测试之前的配置的方法（例如，创建测试所需的任何模型或其他对象）： </p><ul><li><p><code>setUpTestData()</code> 用于类级别设置，在<strong>测试运行开始的时侯，会调用一次</strong>。您可以使用它来创建在任何测试方法中，都不会修改或更改的对象。 </p></li><li><p><code>setUp()</code> 在<strong>每个测试函数之前被调用</strong>，以设置可能被测试修改的任何对象（每个测试函数，都将获得这些对象的 “新” 版本）。 </p></li></ul><p><strong>注意</strong>：测试类别还有一个我们还没有使用的<code>tearDown()</code>方法。此方法对数据库测试不是特别有用，因为<code>TestCase</code>基类会为您处理数据库拆卸。 </p><p>下面我们有一些测试方法，它们使用 <code>Assert</code>函数来测试条件是真，假或相等（<code>AssertTrue</code>, <code>AssertFalse</code>, <code>AssertEqual</code>）。如果条件评估不如预期，则测试将失败，并将错误报告给控制台。</p><p><code>AssertTrue</code>, <code>AssertFalse</code>, <code>AssertEqual</code>是 <strong>unittest</strong> 提供的标准断言。框架中还有其他标准断言，还有 <a href="https://docs.djangoproject.com/en/2.0/topics/testing/tools/#assertions" target="_blank" rel="noopener">Django 特定的断言</a>，来测试视图是否重定向（<code>assertRedirects</code>），或测试是否已使用特定模板（<code>assertTemplateUsed</code>）等。</p><h4 id="如何运行测试"><a href="#如何运行测试" class="headerlink" title="如何运行测试"></a>如何运行测试</h4><p>要运行所有测试，最简单的方法，是使用以下命令： </p><p><code>python manage.py test</code></p><p>这将查找当前目录下，使用模式 <strong>test*.py</strong> 命名的所有文件，并运行使用适当基类定义的所有测试（这里我们有许多测试文件，但只有 <strong>/catalog/tests/test_models.py</strong> 目前包含任何测试。）。默认情况下，测试将仅单独报告测试失败，然后是测试摘要。 </p><p>如果您收到类似于以下内容的错误：<code>ValueError: Missing staticfiles manifest entry ...</code> 这可能是因为默认情况下，测试不会运行 collectstatic，而您的应用程序正在使用需要它的储存类别（有关更多信息，请参阅 <a href="https://docs.djangoproject.com/en/2.0/ref/contrib/staticfiles/#django.contrib.staticfiles.storage.ManifestStaticFilesStorage.manifest_strict" target="_blank" rel="noopener">manifest_strict</a>）。有许多方法可以解决这个问题 - 最简单的方法，是在运行测试之前，简单地运行collectstatic： </p><p><code>python manage.py collectstatic</code></p><p> 在 LocalLibrary 的根目录中，运行测试。您应该看到如下所示的输出 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;python manage.py <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">Creating <span class="built_in">test</span> database <span class="keyword">for</span> <span class="built_in">alias</span> <span class="string">'default'</span>...</span><br><span class="line">setUpTestData: Run once to <span class="built_in">set</span> up non-modified data <span class="keyword">for</span> all class methods.</span><br><span class="line">setUp: Run once <span class="keyword">for</span> every <span class="built_in">test</span> method to setup clean data.</span><br><span class="line">Method: test_false_is_false.</span><br><span class="line">.setUp: Run once <span class="keyword">for</span> every <span class="built_in">test</span> method to setup clean data.</span><br><span class="line">Method: test_false_is_true.</span><br><span class="line">FsetUp: Run once <span class="keyword">for</span> every <span class="built_in">test</span> method to setup clean data.</span><br><span class="line">Method: test_one_plus_one_equals_two.</span><br><span class="line">.</span><br><span class="line">======================================================================</span><br><span class="line">FAIL: test_false_is_true (catalog.tests.tests_models.YourTestClass)</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"D:\Github\django_tmp\library_w_t_2\locallibrary\catalog\tests\tests_models.py"</span>, line 22, <span class="keyword">in</span> test_false_is_true</span><br><span class="line">    self.assertTrue(False)</span><br><span class="line">AssertionError: False is not <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">Ran 3 tests <span class="keyword">in</span> 0.075s</span><br><span class="line"></span><br><span class="line">FAILED (failures=1)</span><br><span class="line">Destroying <span class="built_in">test</span> database <span class="keyword">for</span> <span class="built_in">alias</span> <span class="string">'default'</span>...</span><br></pre></td></tr></table></figure><p>在这里，我们看到有一个测试失败，我们可以确切地看到哪个函数失败了、为什么失败（这个失败是预期的，因为 <code>False</code>不是 <code>True</code>！）。 </p><p><strong>提示:</strong> 从上面的测试输出中，学到的最重要事情是，如果为对象和方法使用描述性/信息性名称，它会更有价值。 </p><p>上面以<strong>粗体</strong>显示的文本，通常不会出现在测试输出中（这是由我们的测试中的<code>print()</code>函数生成的）。这显示了如何为类调用<code>setUpTestData()</code>方法，并在每个方法之前调用<code>setUp()</code>。 </p><p>接下来的部分，将介绍如何运行特定测试，以及如何控制测试显示的信息量。 </p><h4 id="显示更多测试信息"><a href="#显示更多测试信息" class="headerlink" title="显示更多测试信息"></a>显示更多测试信息</h4><p>如果您想获得有关测试运行的更多信息，可以更改详细程度。例如，要列出测试成功和失败（以及有关如何设置测试数据库的大量信息），您可以将详细程度设置为 “2”，如下所示： </p><p><code>python manage.py test --verbosity 2</code></p><p>允许的详细级别为 0, 1 ,2 和 3，默认值为 “1”。 </p><h4 id="运行特定测试"><a href="#运行特定测试" class="headerlink" title="运行特定测试"></a>运行特定测试</h4><p>如果要运行测试的子集，可以通过指定包，模块，<code>TestCase</code>子类或方法的完整路径（包含点）来执行此操作： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python manage.py <span class="built_in">test</span> catalog.tests   <span class="comment"># 运行特定的测试，该文件在项目的tests文件夹下</span></span><br><span class="line">python manage.py <span class="built_in">test</span> catalog.tests.test_models  <span class="comment"># 运行上方文件下的特定的测试文件</span></span><br><span class="line">python manage.py <span class="built_in">test</span> catalog.tests.test_models.YourTestClass <span class="comment"># 运行上方文件的特定测试类</span></span><br><span class="line">python manage.py <span class="built_in">test</span> catalog.tests.test_models.YourTestClass.test_one_plus_one_equals_two  <span class="comment"># 运行上方测试类的特定的方法</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天又重新回头看了一点关于Django单元测试的内容，写测试真的是一个很好的事情，对于代码重构，后期维护都非常有用。以下是Django文档中关于测试方面的内容，可以作为参考，当然，面对不同的项目，测试也不尽相同，写测试，真的很需要经验，一开始还真是无从下手= =！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Django" scheme="https://cblog.club/categories/Django/"/>
    
      <category term="自动化测试" scheme="https://cblog.club/categories/Django/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="Django" scheme="https://cblog.club/tags/Django/"/>
    
      <category term="自动化测试" scheme="https://cblog.club/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>46全排列</title>
    <link href="https://cblog.club/ck3ecxtoo0019v0g42yb275sx.html"/>
    <id>https://cblog.club/ck3ecxtoo0019v0g42yb275sx.html</id>
    <published>2019-11-25T01:03:23.000Z</published>
    <updated>2019-11-25T01:19:24.555Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个<strong>没有重复</strong>数字的序列，返回其所有可能的全排列。 </p><a id="more"></a><blockquote><p><strong>示例:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">输出:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">  [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题是经典回溯问题的入门题目，详细回溯算法，可以看回溯那一章博客，主要问题还是你得理解递归的细节过程，能自己推出过程，然后这一题再找是否有重复出现的数字时，可以采用visited-bool数组标记是否选过，当然也可以将走过的数字插入到一个数组中，然后再在数组中寻找，时间复杂度就比较高了，也有交换数字的方法，很高效，但是还没有仔细看，这一题需要重构，多用几种方法。"><a href="#解题思路：本题是经典回溯问题的入门题目，详细回溯算法，可以看回溯那一章博客，主要问题还是你得理解递归的细节过程，能自己推出过程，然后这一题再找是否有重复出现的数字时，可以采用visited-bool数组标记是否选过，当然也可以将走过的数字插入到一个数组中，然后再在数组中寻找，时间复杂度就比较高了，也有交换数字的方法，很高效，但是还没有仔细看，这一题需要重构，多用几种方法。" class="headerlink" title="解题思路：本题是经典回溯问题的入门题目，详细回溯算法，可以看回溯那一章博客，主要问题还是你得理解递归的细节过程，能自己推出过程，然后这一题再找是否有重复出现的数字时，可以采用visited bool数组标记是否选过，当然也可以将走过的数字插入到一个数组中，然后再在数组中寻找，时间复杂度就比较高了，也有交换数字的方法，很高效，但是还没有仔细看，这一题需要重构，多用几种方法。"></a>解题思路：本题是经典回溯问题的入门题目，详细回溯算法，可以看回溯那一章博客，主要问题还是你得理解递归的细节过程，能自己推出过程，然后这一题再找是否有重复出现的数字时，可以采用visited bool数组标记是否选过，当然也可以将走过的数字插入到一个数组中，然后再在数组中寻找，时间复杂度就比较高了，也有交换数字的方法，很高效，但是还没有仔细看，这一题需要重构，多用几种方法。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; permute(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;result;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;init_path;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;visited(nums.size(),<span class="literal">false</span>);</span><br><span class="line">        Backtracking(init_path,nums,result,visited);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Backtracking</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp;path,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp;select,<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp;result,<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp;visited)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(path.size()==select.size())&#123;</span><br><span class="line">            result.push_back(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;select.size();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(visited[i]==<span class="literal">true</span>)<span class="keyword">continue</span>;</span><br><span class="line">            path.push_back(select[i]);</span><br><span class="line">            visited[i]=<span class="literal">true</span>;</span><br><span class="line">            Backtracking(path,select,result,visited);</span><br><span class="line">            path.pop_back();</span><br><span class="line">            visited[i]=<span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个&lt;strong&gt;没有重复&lt;/strong&gt;数字的序列，返回其所有可能的全排列。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="回溯" scheme="https://cblog.club/categories/leetcode/%E5%9B%9E%E6%BA%AF/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="回溯" scheme="https://cblog.club/tags/%E5%9B%9E%E6%BA%AF/"/>
    
  </entry>
  
  <entry>
    <title>63不同路径II</title>
    <link href="https://cblog.club/ck3ecxtpc001vv0g43mpg1nc7.html"/>
    <id>https://cblog.club/ck3ecxtpc001vv0g43mpg1nc7.html</id>
    <published>2019-11-24T00:49:21.000Z</published>
    <updated>2019-11-24T00:55:54.530Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>一个机器人位于一个 <em>m x n</em> 网格的左上角 （起始点在下图中标记为“Start” ）。</p><p>机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。</p><p>现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？</p><p>网格中的障碍物和空位置分别用 <code>1</code> 和 <code>0</code> 来表示。</p><p><strong>说明</strong>：<strong>m</strong> 和 <strong>n</strong> 的值均不超过 100。</p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">输入:</span><br><span class="line">[</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">  [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">]</span><br><span class="line">输出: <span class="number">2</span></span><br><span class="line">解释:</span><br><span class="line"><span class="number">3</span>x3 网格的正中间有一个障碍物。</span><br><span class="line">从左上角到右下角一共有 <span class="number">2</span> 条不同的路径：</span><br><span class="line"><span class="number">1.</span> 向右 -&gt; 向右 -&gt; 向下 -&gt; 向下</span><br><span class="line"><span class="number">2.</span> 向下 -&gt; 向下 -&gt; 向右 -&gt; 向右</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题就是不同路径的微升级版，只不过增加了障碍物，思路一样，但是初始化不能是第一行，第一列初始为1了，因为第一行，第一列，包括原点都有可能是障碍物，这需要判断一下，直接从原地开始双层循环，越界情况，需要设置一下即可。还有需要注意的是对于二维的vector来说，获取行数用变量-size-，获取列数用变量-0-size，除此之外，数据有可能溢出，需要用long，这点没有考虑-！"><a href="#解题思路：本题就是不同路径的微升级版，只不过增加了障碍物，思路一样，但是初始化不能是第一行，第一列初始为1了，因为第一行，第一列，包括原点都有可能是障碍物，这需要判断一下，直接从原地开始双层循环，越界情况，需要设置一下即可。还有需要注意的是对于二维的vector来说，获取行数用变量-size-，获取列数用变量-0-size，除此之外，数据有可能溢出，需要用long，这点没有考虑-！" class="headerlink" title="解题思路：本题就是不同路径的微升级版，只不过增加了障碍物，思路一样，但是初始化不能是第一行，第一列初始为1了，因为第一行，第一列，包括原点都有可能是障碍物，这需要判断一下，直接从原地开始双层循环，越界情况，需要设置一下即可。还有需要注意的是对于二维的vector来说，获取行数用变量.size()，获取列数用变量[0].size，除此之外，数据有可能溢出，需要用long，这点没有考虑~！"></a>解题思路：本题就是不同路径的微升级版，只不过增加了障碍物，思路一样，但是初始化不能是第一行，第一列初始为1了，因为第一行，第一列，包括原点都有可能是障碍物，这需要判断一下，直接从原地开始双层循环，越界情况，需要设置一下即可。还有需要注意的是对于二维的vector来说，获取行数用变量.size()，获取列数用变量[0].size，除此之外，数据有可能溢出，需要用long，这点没有考虑~！</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">uniquePathsWithObstacles</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; obstacleGrid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">int</span> row,col;</span><br><span class="line">        row=obstacleGrid.size();</span><br><span class="line">        col=obstacleGrid[<span class="number">0</span>].size();</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">int</span> dp[row][col];</span><br><span class="line">        <span class="keyword">if</span>(obstacleGrid[<span class="number">0</span>][<span class="number">0</span>]!=<span class="number">1</span>)dp[<span class="number">0</span>][<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> dp[<span class="number">0</span>][<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;row;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;col;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(obstacleGrid[i][j]==<span class="number">1</span>)dp[i][j]=<span class="number">0</span>;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i<span class="number">-1</span>&gt;=<span class="number">0</span>&amp;&amp;j<span class="number">-1</span>&gt;=<span class="number">0</span>)dp[i][j]=dp[i<span class="number">-1</span>][j]+dp[i][j<span class="number">-1</span>];</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(i<span class="number">-1</span>&lt;<span class="number">0</span>&amp;&amp;j<span class="number">-1</span>&gt;=<span class="number">0</span>)dp[i][j]=<span class="number">0</span>+dp[i][j<span class="number">-1</span>];</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(i<span class="number">-1</span>&gt;=<span class="number">0</span>&amp;&amp;j<span class="number">-1</span>&lt;=<span class="number">0</span>)dp[i][j]=<span class="number">0</span>+dp[i<span class="number">-1</span>][j];</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j]=dp[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[row<span class="number">-1</span>][col<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;一个机器人位于一个 &lt;em&gt;m x n&lt;/em&gt; 网格的左上角 （起始点在下图中标记为“Start” ）。&lt;/p&gt;
&lt;p&gt;机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。&lt;/p&gt;
&lt;p&gt;现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？&lt;/p&gt;
&lt;p&gt;网格中的障碍物和空位置分别用 &lt;code&gt;1&lt;/code&gt; 和 &lt;code&gt;0&lt;/code&gt; 来表示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;：&lt;strong&gt;m&lt;/strong&gt; 和 &lt;strong&gt;n&lt;/strong&gt; 的值均不超过 100。&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch_CNN</title>
    <link href="https://cblog.club/ck3ecxtq6002rv0g4ajyher3r.html"/>
    <id>https://cblog.club/ck3ecxtq6002rv0g4ajyher3r.html</id>
    <published>2019-11-23T13:42:34.000Z</published>
    <updated>2019-11-23T13:52:28.764Z</updated>
    
    <content type="html"><![CDATA[<h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><ul><li>MNIST举例</li></ul><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设备的配置（这里使用GPU来跑训练）</span></span><br><span class="line">device=torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">print(device)</span><br></pre></td></tr></table></figure><pre><code>cuda</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设定超参数</span></span><br><span class="line">num_classes=<span class="number">10</span></span><br><span class="line">num_epochs=<span class="number">30</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载MNIST数据集</span></span><br><span class="line">train_dataset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">test_dataset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br></pre></td></tr></table></figure><pre><code>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz100.1%Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/rawDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz113.5%Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/rawDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz100.4%Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/rawDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz180.4%Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/rawProcessing...Done!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义数据加载器（数据输入流水线）</span></span><br><span class="line">train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_dataloader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个卷积神经网络（两个卷积层）</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_classes=<span class="number">10</span>)</span>:</span></span><br><span class="line">        super(ConvNet,self).__init__()</span><br><span class="line">        self.layer1=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,kernel_size=<span class="number">5</span>,stride=<span class="number">1</span>,padding=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>))</span><br><span class="line">        self.layer2=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,kernel_size=<span class="number">5</span>,stride=<span class="number">1</span>,padding=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>))</span><br><span class="line">        self.fc=nn.Linear(<span class="number">7</span>*<span class="number">7</span>*<span class="number">32</span>,num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        out=self.layer1(x)</span><br><span class="line">        out=self.layer2(out)</span><br><span class="line">        out=out.reshape(out.size(<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">        out=self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model=ConvNet(num_classes).to(device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义损失函数和优化器</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">total_step=len(train_dataloader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> enumerate(train_dataloader):</span><br><span class="line">        images=images.to(device)</span><br><span class="line">        labels=labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        outputs=model(images)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度置0+反向传播+更新权重</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;'</span> .format(epoch+<span class="number">1</span>, num_epochs, i+<span class="number">1</span>, total_step, loss.item()))</span><br></pre></td></tr></table></figure><pre><code>Epoch [1/30], Step [100/600], Loss: 0.1577Epoch [1/30], Step [200/600], Loss: 0.1438Epoch [1/30], Step [300/600], Loss: 0.1884Epoch [1/30], Step [400/600], Loss: 0.2141Epoch [1/30], Step [500/600], Loss: 0.1059Epoch [1/30], Step [600/600], Loss: 0.2351Epoch [2/30], Step [100/600], Loss: 0.1536Epoch [2/30], Step [200/600], Loss: 0.2595Epoch [2/30], Step [300/600], Loss: 0.1568Epoch [2/30], Step [400/600], Loss: 0.1574Epoch [2/30], Step [500/600], Loss: 0.1640Epoch [2/30], Step [600/600], Loss: 0.1491Epoch [3/30], Step [100/600], Loss: 0.1316Epoch [3/30], Step [200/600], Loss: 0.1286Epoch [3/30], Step [300/600], Loss: 0.1090Epoch [3/30], Step [400/600], Loss: 0.1225Epoch [3/30], Step [500/600], Loss: 0.1855Epoch [3/30], Step [600/600], Loss: 0.2051Epoch [4/30], Step [100/600], Loss: 0.1919Epoch [4/30], Step [200/600], Loss: 0.0978Epoch [4/30], Step [300/600], Loss: 0.1332Epoch [4/30], Step [400/600], Loss: 0.0695Epoch [4/30], Step [500/600], Loss: 0.1611Epoch [4/30], Step [600/600], Loss: 0.1686Epoch [5/30], Step [100/600], Loss: 0.0865Epoch [5/30], Step [200/600], Loss: 0.0943Epoch [5/30], Step [300/600], Loss: 0.0437Epoch [5/30], Step [400/600], Loss: 0.1014Epoch [5/30], Step [500/600], Loss: 0.1270Epoch [5/30], Step [600/600], Loss: 0.0938Epoch [6/30], Step [100/600], Loss: 0.1868Epoch [6/30], Step [200/600], Loss: 0.1830Epoch [6/30], Step [300/600], Loss: 0.1203Epoch [6/30], Step [400/600], Loss: 0.1165Epoch [6/30], Step [500/600], Loss: 0.1225Epoch [6/30], Step [600/600], Loss: 0.0663Epoch [7/30], Step [100/600], Loss: 0.1232Epoch [7/30], Step [200/600], Loss: 0.0919Epoch [7/30], Step [300/600], Loss: 0.0830Epoch [7/30], Step [400/600], Loss: 0.1185Epoch [7/30], Step [500/600], Loss: 0.1438Epoch [7/30], Step [600/600], Loss: 0.1936Epoch [8/30], Step [100/600], Loss: 0.0454Epoch [8/30], Step [200/600], Loss: 0.0440Epoch [8/30], Step [300/600], Loss: 0.1723Epoch [8/30], Step [400/600], Loss: 0.1465Epoch [8/30], Step [500/600], Loss: 0.1301Epoch [8/30], Step [600/600], Loss: 0.1120Epoch [9/30], Step [100/600], Loss: 0.1239Epoch [9/30], Step [200/600], Loss: 0.0668Epoch [9/30], Step [300/600], Loss: 0.1200Epoch [9/30], Step [400/600], Loss: 0.0720Epoch [9/30], Step [500/600], Loss: 0.1159Epoch [9/30], Step [600/600], Loss: 0.0869Epoch [10/30], Step [100/600], Loss: 0.0502Epoch [10/30], Step [200/600], Loss: 0.1090Epoch [10/30], Step [300/600], Loss: 0.0604Epoch [10/30], Step [400/600], Loss: 0.0823Epoch [10/30], Step [500/600], Loss: 0.1274Epoch [10/30], Step [600/600], Loss: 0.0921Epoch [11/30], Step [100/600], Loss: 0.0766Epoch [11/30], Step [200/600], Loss: 0.0915Epoch [11/30], Step [300/600], Loss: 0.0680Epoch [11/30], Step [400/600], Loss: 0.0537Epoch [11/30], Step [500/600], Loss: 0.0872Epoch [11/30], Step [600/600], Loss: 0.0501Epoch [12/30], Step [100/600], Loss: 0.0640Epoch [12/30], Step [200/600], Loss: 0.1074Epoch [12/30], Step [300/600], Loss: 0.0648Epoch [12/30], Step [400/600], Loss: 0.1053Epoch [12/30], Step [500/600], Loss: 0.1114Epoch [12/30], Step [600/600], Loss: 0.0853Epoch [13/30], Step [100/600], Loss: 0.0316Epoch [13/30], Step [200/600], Loss: 0.0837Epoch [13/30], Step [300/600], Loss: 0.1915Epoch [13/30], Step [400/600], Loss: 0.0859Epoch [13/30], Step [500/600], Loss: 0.0947Epoch [13/30], Step [600/600], Loss: 0.0501Epoch [14/30], Step [100/600], Loss: 0.0765Epoch [14/30], Step [200/600], Loss: 0.0526Epoch [14/30], Step [300/600], Loss: 0.0773Epoch [14/30], Step [400/600], Loss: 0.0578Epoch [14/30], Step [500/600], Loss: 0.0845Epoch [14/30], Step [600/600], Loss: 0.0521Epoch [15/30], Step [100/600], Loss: 0.1169Epoch [15/30], Step [200/600], Loss: 0.0391Epoch [15/30], Step [300/600], Loss: 0.0686Epoch [15/30], Step [400/600], Loss: 0.0966Epoch [15/30], Step [500/600], Loss: 0.0331Epoch [15/30], Step [600/600], Loss: 0.0582Epoch [16/30], Step [100/600], Loss: 0.0694Epoch [16/30], Step [200/600], Loss: 0.0841Epoch [16/30], Step [300/600], Loss: 0.1188Epoch [16/30], Step [400/600], Loss: 0.0712Epoch [16/30], Step [500/600], Loss: 0.0655Epoch [16/30], Step [600/600], Loss: 0.0883Epoch [17/30], Step [100/600], Loss: 0.1239Epoch [17/30], Step [200/600], Loss: 0.0856Epoch [17/30], Step [300/600], Loss: 0.0598Epoch [17/30], Step [400/600], Loss: 0.0667Epoch [17/30], Step [500/600], Loss: 0.0577Epoch [17/30], Step [600/600], Loss: 0.0958Epoch [18/30], Step [100/600], Loss: 0.0657Epoch [18/30], Step [200/600], Loss: 0.0419Epoch [18/30], Step [300/600], Loss: 0.0927Epoch [18/30], Step [400/600], Loss: 0.1247Epoch [18/30], Step [500/600], Loss: 0.1200Epoch [18/30], Step [600/600], Loss: 0.1246Epoch [19/30], Step [100/600], Loss: 0.0615Epoch [19/30], Step [200/600], Loss: 0.0164Epoch [19/30], Step [300/600], Loss: 0.0816Epoch [19/30], Step [400/600], Loss: 0.1274Epoch [19/30], Step [500/600], Loss: 0.0988Epoch [19/30], Step [600/600], Loss: 0.0349Epoch [20/30], Step [100/600], Loss: 0.1025Epoch [20/30], Step [200/600], Loss: 0.1068Epoch [20/30], Step [300/600], Loss: 0.0400Epoch [20/30], Step [400/600], Loss: 0.0398Epoch [20/30], Step [500/600], Loss: 0.0671Epoch [20/30], Step [600/600], Loss: 0.0874Epoch [21/30], Step [100/600], Loss: 0.0413Epoch [21/30], Step [200/600], Loss: 0.1078Epoch [21/30], Step [300/600], Loss: 0.0597Epoch [21/30], Step [400/600], Loss: 0.0410Epoch [21/30], Step [500/600], Loss: 0.0644Epoch [21/30], Step [600/600], Loss: 0.1118Epoch [22/30], Step [100/600], Loss: 0.0907Epoch [22/30], Step [200/600], Loss: 0.0542Epoch [22/30], Step [300/600], Loss: 0.2506Epoch [22/30], Step [400/600], Loss: 0.0521Epoch [22/30], Step [500/600], Loss: 0.0435Epoch [22/30], Step [600/600], Loss: 0.0573Epoch [23/30], Step [100/600], Loss: 0.0587Epoch [23/30], Step [200/600], Loss: 0.0452Epoch [23/30], Step [300/600], Loss: 0.0409Epoch [23/30], Step [400/600], Loss: 0.0517Epoch [23/30], Step [500/600], Loss: 0.0404Epoch [23/30], Step [600/600], Loss: 0.0853Epoch [24/30], Step [100/600], Loss: 0.0939Epoch [24/30], Step [200/600], Loss: 0.0728Epoch [24/30], Step [300/600], Loss: 0.0334Epoch [24/30], Step [400/600], Loss: 0.0385Epoch [24/30], Step [500/600], Loss: 0.0339Epoch [24/30], Step [600/600], Loss: 0.1187Epoch [25/30], Step [100/600], Loss: 0.0291Epoch [25/30], Step [200/600], Loss: 0.0209Epoch [25/30], Step [300/600], Loss: 0.0638Epoch [25/30], Step [400/600], Loss: 0.1146Epoch [25/30], Step [500/600], Loss: 0.0283Epoch [25/30], Step [600/600], Loss: 0.0954Epoch [26/30], Step [100/600], Loss: 0.0835Epoch [26/30], Step [200/600], Loss: 0.0453Epoch [26/30], Step [300/600], Loss: 0.0255Epoch [26/30], Step [400/600], Loss: 0.0836Epoch [26/30], Step [500/600], Loss: 0.0456Epoch [26/30], Step [600/600], Loss: 0.0207Epoch [27/30], Step [100/600], Loss: 0.1213Epoch [27/30], Step [200/600], Loss: 0.0258Epoch [27/30], Step [300/600], Loss: 0.0545Epoch [27/30], Step [400/600], Loss: 0.0296Epoch [27/30], Step [500/600], Loss: 0.0507Epoch [27/30], Step [600/600], Loss: 0.0386Epoch [28/30], Step [100/600], Loss: 0.0545Epoch [28/30], Step [200/600], Loss: 0.0468Epoch [28/30], Step [300/600], Loss: 0.2291Epoch [28/30], Step [400/600], Loss: 0.1048Epoch [28/30], Step [500/600], Loss: 0.0407Epoch [28/30], Step [600/600], Loss: 0.0895Epoch [29/30], Step [100/600], Loss: 0.0504Epoch [29/30], Step [200/600], Loss: 0.0448Epoch [29/30], Step [300/600], Loss: 0.0254Epoch [29/30], Step [400/600], Loss: 0.0468Epoch [29/30], Step [500/600], Loss: 0.0783Epoch [29/30], Step [600/600], Loss: 0.0542Epoch [30/30], Step [100/600], Loss: 0.0531Epoch [30/30], Step [200/600], Loss: 0.0461Epoch [30/30], Step [300/600], Loss: 0.0339Epoch [30/30], Step [400/600], Loss: 0.0592Epoch [30/30], Step [500/600], Loss: 0.0287Epoch [30/30], Step [600/600], Loss: 0.0403</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试模型</span></span><br><span class="line">model.eval()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    correct=<span class="number">0</span></span><br><span class="line">    total=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_dataloader:</span><br><span class="line">        images=images.to(device)</span><br><span class="line">        labels=labels.to(device)</span><br><span class="line">        outputs=model(images)</span><br><span class="line">        _,predicted=torch.max(outputs.data,<span class="number">1</span>)</span><br><span class="line">        total+=labels.size(<span class="number">0</span>)</span><br><span class="line">        correct+=(predicted==labels).sum().item()</span><br><span class="line">        </span><br><span class="line">    print(<span class="string">'Test Accuracy of the model on the 10000 test images:&#123;&#125;%'</span>.format(<span class="number">100</span>*correct/total))</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型的权重</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'cnn.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>Test Accuracy of the model on the 10000 test images:98.37%</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;卷积神经网络&quot;&gt;&lt;a href=&quot;#卷积神经网络&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络&quot;&gt;&lt;/a&gt;卷积神经网络&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;MNIST举例&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-Day5</title>
    <link href="https://cblog.club/ck3ecxtqk0037v0g464o66j3n.html"/>
    <id>https://cblog.club/ck3ecxtqk0037v0g464o66j3n.html</id>
    <published>2019-11-23T13:41:39.000Z</published>
    <updated>2019-11-23T13:52:17.369Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><ul><li>这里仍然使用MNIST数据集</li></ul><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设备的配置（这里使用GPU来跑训练）</span></span><br><span class="line">device=torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">print(device)</span><br></pre></td></tr></table></figure><pre><code>cuda</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设定超参数</span></span><br><span class="line">input_size=<span class="number">784</span></span><br><span class="line">hidden_size=<span class="number">500</span></span><br><span class="line">num_classes=<span class="number">10</span></span><br><span class="line">num_epochs=<span class="number">30</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载MNIST数据集</span></span><br><span class="line">train_dataset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">test_dataset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义数据加载器（数据输入流水线）</span></span><br><span class="line">train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_dataloader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#一个隐含层的全连接神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_size,hidden_size,num_classes)</span>:</span></span><br><span class="line">        super(NeuralNet,self).__init__()</span><br><span class="line">        self.fc1=nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu=nn.ReLU()</span><br><span class="line">        self.fc2=nn.Linear(hidden_size,num_classes)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        out=self.fc1(x)</span><br><span class="line">        out=self.relu(out)</span><br><span class="line">        out=self.fc2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model=NeuralNet(input_size,hidden_size,num_classes).to(device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义损失函数和优化器</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">total_step=len(train_dataloader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> enumerate(train_dataloader):</span><br><span class="line">        <span class="comment">#将tensor张量移动到GPU上</span></span><br><span class="line">        images=images.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels=labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        outputs=model(images)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度置0+反向传播+更新权重</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;'</span> .format(epoch+<span class="number">1</span>, num_epochs, i+<span class="number">1</span>, total_step, loss.item()))</span><br></pre></td></tr></table></figure><pre><code>Epoch [1/30], Step [100/600], Loss: 2.2577Epoch [1/30], Step [200/600], Loss: 2.2602Epoch [1/30], Step [300/600], Loss: 2.2123Epoch [1/30], Step [400/600], Loss: 2.2026Epoch [1/30], Step [500/600], Loss: 2.1547Epoch [1/30], Step [600/600], Loss: 2.1598Epoch [2/30], Step [100/600], Loss: 2.0920Epoch [2/30], Step [200/600], Loss: 2.0759Epoch [2/30], Step [300/600], Loss: 2.0557Epoch [2/30], Step [400/600], Loss: 2.0411Epoch [2/30], Step [500/600], Loss: 1.9963Epoch [2/30], Step [600/600], Loss: 1.9562Epoch [3/30], Step [100/600], Loss: 1.8933Epoch [3/30], Step [200/600], Loss: 1.8954Epoch [3/30], Step [300/600], Loss: 1.8854Epoch [3/30], Step [400/600], Loss: 1.9073Epoch [3/30], Step [500/600], Loss: 1.8073Epoch [3/30], Step [600/600], Loss: 1.7214Epoch [4/30], Step [100/600], Loss: 1.7209Epoch [4/30], Step [200/600], Loss: 1.6359Epoch [4/30], Step [300/600], Loss: 1.6842Epoch [4/30], Step [400/600], Loss: 1.6216Epoch [4/30], Step [500/600], Loss: 1.6705Epoch [4/30], Step [600/600], Loss: 1.5234Epoch [5/30], Step [100/600], Loss: 1.4869Epoch [5/30], Step [200/600], Loss: 1.4968Epoch [5/30], Step [300/600], Loss: 1.4577Epoch [5/30], Step [400/600], Loss: 1.5792Epoch [5/30], Step [500/600], Loss: 1.4062Epoch [5/30], Step [600/600], Loss: 1.3446Epoch [6/30], Step [100/600], Loss: 1.3835Epoch [6/30], Step [200/600], Loss: 1.2209Epoch [6/30], Step [300/600], Loss: 1.3533Epoch [6/30], Step [400/600], Loss: 1.2524Epoch [6/30], Step [500/600], Loss: 1.1529Epoch [6/30], Step [600/600], Loss: 1.1282Epoch [7/30], Step [100/600], Loss: 1.1611Epoch [7/30], Step [200/600], Loss: 1.1645Epoch [7/30], Step [300/600], Loss: 1.0757Epoch [7/30], Step [400/600], Loss: 1.1130Epoch [7/30], Step [500/600], Loss: 1.1147Epoch [7/30], Step [600/600], Loss: 0.9933Epoch [8/30], Step [100/600], Loss: 0.9965Epoch [8/30], Step [200/600], Loss: 1.0421Epoch [8/30], Step [300/600], Loss: 0.9947Epoch [8/30], Step [400/600], Loss: 0.9643Epoch [8/30], Step [500/600], Loss: 0.8699Epoch [8/30], Step [600/600], Loss: 0.9051Epoch [9/30], Step [100/600], Loss: 0.9915Epoch [9/30], Step [200/600], Loss: 0.8200Epoch [9/30], Step [300/600], Loss: 0.8870Epoch [9/30], Step [400/600], Loss: 0.7617Epoch [9/30], Step [500/600], Loss: 0.8657Epoch [9/30], Step [600/600], Loss: 0.8298Epoch [10/30], Step [100/600], Loss: 0.8165Epoch [10/30], Step [200/600], Loss: 0.8207Epoch [10/30], Step [300/600], Loss: 0.8202Epoch [10/30], Step [400/600], Loss: 0.8262Epoch [10/30], Step [500/600], Loss: 0.8131Epoch [10/30], Step [600/600], Loss: 0.8367Epoch [11/30], Step [100/600], Loss: 0.8376Epoch [11/30], Step [200/600], Loss: 0.8952Epoch [11/30], Step [300/600], Loss: 0.8049Epoch [11/30], Step [400/600], Loss: 0.8018Epoch [11/30], Step [500/600], Loss: 0.6761Epoch [11/30], Step [600/600], Loss: 0.7581Epoch [12/30], Step [100/600], Loss: 0.6733Epoch [12/30], Step [200/600], Loss: 0.7217Epoch [12/30], Step [300/600], Loss: 0.7343Epoch [12/30], Step [400/600], Loss: 0.6188Epoch [12/30], Step [500/600], Loss: 0.6395Epoch [12/30], Step [600/600], Loss: 0.6714Epoch [13/30], Step [100/600], Loss: 0.7165Epoch [13/30], Step [200/600], Loss: 0.6684Epoch [13/30], Step [300/600], Loss: 0.6127Epoch [13/30], Step [400/600], Loss: 0.6626Epoch [13/30], Step [500/600], Loss: 0.6130Epoch [13/30], Step [600/600], Loss: 0.6483Epoch [14/30], Step [100/600], Loss: 0.5773Epoch [14/30], Step [200/600], Loss: 0.6234Epoch [14/30], Step [300/600], Loss: 0.5617Epoch [14/30], Step [400/600], Loss: 0.6304Epoch [14/30], Step [500/600], Loss: 0.5647Epoch [14/30], Step [600/600], Loss: 0.6992Epoch [15/30], Step [100/600], Loss: 0.7693Epoch [15/30], Step [200/600], Loss: 0.5023Epoch [15/30], Step [300/600], Loss: 0.6256Epoch [15/30], Step [400/600], Loss: 0.5553Epoch [15/30], Step [500/600], Loss: 0.5332Epoch [15/30], Step [600/600], Loss: 0.6705Epoch [16/30], Step [100/600], Loss: 0.5651Epoch [16/30], Step [200/600], Loss: 0.6031Epoch [16/30], Step [300/600], Loss: 0.6298Epoch [16/30], Step [400/600], Loss: 0.6218Epoch [16/30], Step [500/600], Loss: 0.5065Epoch [16/30], Step [600/600], Loss: 0.5554Epoch [17/30], Step [100/600], Loss: 0.5246Epoch [17/30], Step [200/600], Loss: 0.6190Epoch [17/30], Step [300/600], Loss: 0.5547Epoch [17/30], Step [400/600], Loss: 0.5002Epoch [17/30], Step [500/600], Loss: 0.6297Epoch [17/30], Step [600/600], Loss: 0.6091Epoch [18/30], Step [100/600], Loss: 0.5265Epoch [18/30], Step [200/600], Loss: 0.4593Epoch [18/30], Step [300/600], Loss: 0.5204Epoch [18/30], Step [400/600], Loss: 0.5156Epoch [18/30], Step [500/600], Loss: 0.5276Epoch [18/30], Step [600/600], Loss: 0.5380Epoch [19/30], Step [100/600], Loss: 0.4246Epoch [19/30], Step [200/600], Loss: 0.4761Epoch [19/30], Step [300/600], Loss: 0.5177Epoch [19/30], Step [400/600], Loss: 0.5698Epoch [19/30], Step [500/600], Loss: 0.5143Epoch [19/30], Step [600/600], Loss: 0.4552Epoch [20/30], Step [100/600], Loss: 0.4989Epoch [20/30], Step [200/600], Loss: 0.4384Epoch [20/30], Step [300/600], Loss: 0.5648Epoch [20/30], Step [400/600], Loss: 0.4323Epoch [20/30], Step [500/600], Loss: 0.4153Epoch [20/30], Step [600/600], Loss: 0.5401Epoch [21/30], Step [100/600], Loss: 0.4298Epoch [21/30], Step [200/600], Loss: 0.4795Epoch [21/30], Step [300/600], Loss: 0.4865Epoch [21/30], Step [400/600], Loss: 0.6770Epoch [21/30], Step [500/600], Loss: 0.4689Epoch [21/30], Step [600/600], Loss: 0.5034Epoch [22/30], Step [100/600], Loss: 0.4461Epoch [22/30], Step [200/600], Loss: 0.3873Epoch [22/30], Step [300/600], Loss: 0.4634Epoch [22/30], Step [400/600], Loss: 0.4536Epoch [22/30], Step [500/600], Loss: 0.5801Epoch [22/30], Step [600/600], Loss: 0.3840Epoch [23/30], Step [100/600], Loss: 0.4354Epoch [23/30], Step [200/600], Loss: 0.3644Epoch [23/30], Step [300/600], Loss: 0.5900Epoch [23/30], Step [400/600], Loss: 0.5235Epoch [23/30], Step [500/600], Loss: 0.4935Epoch [23/30], Step [600/600], Loss: 0.4815Epoch [24/30], Step [100/600], Loss: 0.3946Epoch [24/30], Step [200/600], Loss: 0.5413Epoch [24/30], Step [300/600], Loss: 0.4906Epoch [24/30], Step [400/600], Loss: 0.4895Epoch [24/30], Step [500/600], Loss: 0.5062Epoch [24/30], Step [600/600], Loss: 0.4927Epoch [25/30], Step [100/600], Loss: 0.5096Epoch [25/30], Step [200/600], Loss: 0.5281Epoch [25/30], Step [300/600], Loss: 0.5560Epoch [25/30], Step [400/600], Loss: 0.3325Epoch [25/30], Step [500/600], Loss: 0.5069Epoch [25/30], Step [600/600], Loss: 0.4295Epoch [26/30], Step [100/600], Loss: 0.3942Epoch [26/30], Step [200/600], Loss: 0.5095Epoch [26/30], Step [300/600], Loss: 0.4046Epoch [26/30], Step [400/600], Loss: 0.4315Epoch [26/30], Step [500/600], Loss: 0.4742Epoch [26/30], Step [600/600], Loss: 0.4902Epoch [27/30], Step [100/600], Loss: 0.5214Epoch [27/30], Step [200/600], Loss: 0.5570Epoch [27/30], Step [300/600], Loss: 0.4271Epoch [27/30], Step [400/600], Loss: 0.4110Epoch [27/30], Step [500/600], Loss: 0.3797Epoch [27/30], Step [600/600], Loss: 0.4555Epoch [28/30], Step [100/600], Loss: 0.4667Epoch [28/30], Step [200/600], Loss: 0.4648Epoch [28/30], Step [300/600], Loss: 0.4887Epoch [28/30], Step [400/600], Loss: 0.3500Epoch [28/30], Step [500/600], Loss: 0.4439Epoch [28/30], Step [600/600], Loss: 0.4054Epoch [29/30], Step [100/600], Loss: 0.5129Epoch [29/30], Step [200/600], Loss: 0.4508Epoch [29/30], Step [300/600], Loss: 0.4131Epoch [29/30], Step [400/600], Loss: 0.4463Epoch [29/30], Step [500/600], Loss: 0.5682Epoch [29/30], Step [600/600], Loss: 0.3458Epoch [30/30], Step [100/600], Loss: 0.3850Epoch [30/30], Step [200/600], Loss: 0.4949Epoch [30/30], Step [300/600], Loss: 0.3873Epoch [30/30], Step [400/600], Loss: 0.4957Epoch [30/30], Step [500/600], Loss: 0.3352Epoch [30/30], Step [600/600], Loss: 0.4667</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试模型（在测试阶段不需要再计算梯度）</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    correct=<span class="number">0</span></span><br><span class="line">    total=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_dataloader:</span><br><span class="line">        images=images.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels=labels.to(device)</span><br><span class="line">        outputs=model(images)</span><br><span class="line">        _,predicted=torch.max(outputs.data,<span class="number">1</span>)</span><br><span class="line">        total+=labels.size(<span class="number">0</span>)</span><br><span class="line">        correct+=(predicted==labels).sum().item()</span><br><span class="line">print(<span class="string">'Accuracy of the network on the 10000 test images:&#123;&#125;%'</span>.format(<span class="number">100</span>*correct/total))</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'NeuralNet.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the network on the 10000 test images:89.47%</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前馈神经网络&quot;&gt;&lt;a href=&quot;#前馈神经网络&quot; class=&quot;headerlink&quot; title=&quot;前馈神经网络&quot;&gt;&lt;/a&gt;前馈神经网络&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;这里仍然使用MNIST数据集&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>安装anaconda虚拟环境、pytorch和jupyter notebook（远程访问）</title>
    <link href="https://cblog.club/ck3ecxtr7003yv0g44nxb71v7.html"/>
    <id>https://cblog.club/ck3ecxtr7003yv0g44nxb71v7.html</id>
    <published>2019-11-23T12:45:04.000Z</published>
    <updated>2019-11-23T13:38:32.894Z</updated>
    
    <content type="html"><![CDATA[<p>最近在学习Pytorch，然后实验室有一台双卡的服务器，显卡是特斯拉（貌似很nb），所以就想在服务器上跑代码，炼丹。今天花了点时间配置了一下环境，主要安装了anaconda和pytorch(gpu版本)，为此记录一下= =。</p><a id="more"></a><h3 id="Anaconda简介"><a href="#Anaconda简介" class="headerlink" title="Anaconda简介"></a>Anaconda简介</h3><p>anaconda 是一个python的发行版，包括了python和很多常见的软件库, 和一个包管理器conda。<br>常见的科学计算类的库都包含在里面了，使得安装比常规python安装要容易。主要是！装了anaconda就不需要单独装python了。<br>因为Anaconda就是用来管理我们不同版本的python环境的。</p><p>对整个python环境, 最关键的是需要有一个解释器, 和一个包集合，所有的第三方包都放在site-packages文件夹里面。<br>比如说一个爬虫脚本用到了第三方的requests包,而另一台计算机是刚刚是装好原始python的, 也就是说根本没有任何第三方包,<br>那么这个爬虫脚本是无法在另一台机器上运行的。（因为需要requests包的支持。）</p><h3 id="Anaconda安装"><a href="#Anaconda安装" class="headerlink" title="Anaconda安装"></a>Anaconda安装</h3><p>Anaconda和Python版本是对应的，所以需要选择安装对应Python2.7版本的还是Python3.7版本或其他版本的，根据自己的需要下载合适的安装包。</p><p>下载链接：<a href="https://www.anaconda.com/download/#linux" target="_blank" rel="noopener">https://www.anaconda.com/download/#linux</a></p><p> 点击下面的64-Bit (x86) Installer ,下载64位的版本，下载完成是：Anaconda3-日期-Linux-x86_64.sh，这是一个shell脚本文件。 </p><h4 id="安装步骤："><a href="#安装步骤：" class="headerlink" title="安装步骤："></a>安装步骤：</h4><ul><li><p>进入安装包Anaconda3-日期-Linux-x86_64.sh所在目录，打开终端</p></li><li><p>执行：bash Anaconda3-日期-Linux-x86_64.sh，然后一路回车，知道出现提示，输入yes</p></li><li><p>回车选择默认路径，然后开始安装，最后会询问你是否添加到环境变量，输入yes</p></li><li><p>这样就安装OK了，不需要重启</p></li></ul><h4 id="检查是否成功："><a href="#检查是否成功：" class="headerlink" title="检查是否成功："></a>检查是否成功：</h4><ul><li>打开新终端，输入python，里边含有Anaconda信息即可</li><li>或者输入<code>conda --version</code>，如果有版本号，也是OK的</li></ul><h3 id="管理虚拟环境"><a href="#管理虚拟环境" class="headerlink" title="管理虚拟环境"></a>管理虚拟环境</h3><p> 安装了anaconda以后，我们可以用它来创建我们一个个独立的python环境 </p><h4 id="创建独立的虚拟环境"><a href="#创建独立的虚拟环境" class="headerlink" title="创建独立的虚拟环境"></a>创建独立的虚拟环境</h4><p><code>conda create -n pytorch_gpu python=3.7</code></p><h4 id="source-activate命令进入到虚拟环境"><a href="#source-activate命令进入到虚拟环境" class="headerlink" title="source activate命令进入到虚拟环境"></a>source activate命令进入到虚拟环境</h4><p><code>source activate pytorch_gpu</code></p><h4 id="activate命令进入到虚拟环境"><a href="#activate命令进入到虚拟环境" class="headerlink" title="activate命令进入到虚拟环境"></a>activate命令进入到虚拟环境</h4><p><code>source activate pytorch_gpu</code></p><h4 id="显示当前虚拟环境所安装的包"><a href="#显示当前虚拟环境所安装的包" class="headerlink" title="显示当前虚拟环境所安装的包"></a>显示当前虚拟环境所安装的包</h4><p><code>conda list</code></p><h4 id="安装需要的包"><a href="#安装需要的包" class="headerlink" title="安装需要的包"></a>安装需要的包</h4><p><code>conda install 包的名字</code></p><h3 id="安装pytorch-GPU版本"><a href="#安装pytorch-GPU版本" class="headerlink" title="安装pytorch(GPU版本)"></a>安装pytorch(GPU版本)</h3><p>准备工作（ 用conda安装Pytorch过程中会连接失败，这是因为Anaconda.org的服务器在国外，需要切换到国内镜像源 ）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br></pre></td></tr></table></figure><p>官网一步到位： <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">https://pytorch.org/get-started/locally/</a> </p><p>选择适合自己的版本即可，我看了Ubuntu的显卡信息<code>nvidia-smi</code>,发现cuda是10.0版本的，所以cudatoolkit改成10.0</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</span><br></pre></td></tr></table></figure><p>最后安装完成，打开python，<code>import torch</code>不出错即可 </p><p>查看GPU是否可用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device=torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">print(device)</span><br></pre></td></tr></table></figure><h3 id="Jupyter-notebook简介"><a href="#Jupyter-notebook简介" class="headerlink" title="Jupyter notebook简介"></a>Jupyter notebook简介</h3><blockquote><p>Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。——<a href="https://link.jianshu.com?t=https%3A%2F%2Fjupyter-notebook.readthedocs.io%2Fen%2Fstable%2Fnotebook.html" target="_blank" rel="noopener">Jupyter Notebook官方介绍</a></p></blockquote><p>简而言之，Jupyter Notebook是以网页的形式打开，可以在网页页面中<strong>直接</strong>编写代码和运行代码，代码的运行结果也会直接在代码块下显示。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。</p><h3 id="安装Jupyter-Notebook"><a href="#安装Jupyter-Notebook" class="headerlink" title="安装Jupyter Notebook"></a>安装Jupyter Notebook</h3><p>之前我已经安装过了anaconda，所以直接使用<code>conda install jupyter</code>即可</p><p>安装完成后，因为我是远程连接服务器，所以就要设置jupyter notebook远程访问，这样写代码比较方便</p><h3 id="Jupyter-nootbook远程访问设置"><a href="#Jupyter-nootbook远程访问设置" class="headerlink" title="Jupyter nootbook远程访问设置"></a>Jupyter nootbook远程访问设置</h3><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>首先，我们需要修改一个名为“upyter_notebook_config.py”的文件，从其命名规则可以看出，这是有关Notebook的配置文件。</p><p>其实，在本质上，它是一个由Python编写的脚本文档。</p><p>通常，这个文档位于我们的家目录（home directory）之下，不同的操作系统，它所处的位置稍有不同，大致如下：</p><p><code>Linux: /home/USERNAME/.jupyter/jupyter_notebook_config.py</code></p><p>上面的「USERNAME」就是前面我们提到的诸如‘jpnb’这样的用户名，我们根据实际情况替换为实际路径即可。</p><p>如果你在上述路径下没有找到这个配置文件，那么就需要在终端运行如下命令：</p><p><code>jupyter notebook --generate-config</code>即可， 这个命令的功能，就是创建Jupyter文件夹和配置文件「jupyter_notebook_config.py」。 </p><h4 id="设置Jupyter远程访问密码"><a href="#设置Jupyter远程访问密码" class="headerlink" title="设置Jupyter远程访问密码"></a>设置Jupyter远程访问密码</h4><h4 id="设置访问密码"><a href="#设置访问密码" class="headerlink" title="设置访问密码"></a>设置访问密码</h4><p>打开终端输入：<code>jupyter notebook password</code></p><h4 id="下面我们还需要手动生成一个hash密码"><a href="#下面我们还需要手动生成一个hash密码" class="headerlink" title="下面我们还需要手动生成一个hash密码,"></a>下面我们还需要手动生成一个hash密码,</h4><p>如果你没有生成这么一个hash密码的话，那么每次通过浏览器远程访问Jupyter时，你都需要输入一次密码，这很繁琐！  但如果我们启用了这个hash密码，只需要首次远程访问Jupyter文档时，输入一次密码，在下次访问时，这个hash密码就好比一个钥匙（token），替我们打开密码之门，也就是免密码登录。 </p><p> 为了生成这个hash密码，我们需要在终端输入“ipython”（全部小写）命令，以进入IPython的交互shell。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">In [<span class="number">2</span>]: passwd()</span><br><span class="line">Enter password:</span><br><span class="line">Verify password:</span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">'sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed'</span></span><br></pre></td></tr></table></figure><p>然后exit()退出IPython</p><h4 id="将hash密码添加到配置文件中"><a href="#将hash密码添加到配置文件中" class="headerlink" title="将hash密码添加到配置文件中"></a>将hash密码添加到配置文件中</h4><p> 下面，我们把前面生成的hash密码，添加到前面生成的配置文件：jupyter_notebook_config.py， </p><p>找到c.NotebookApp.password 所在行，将如下代码：</p><p><code>#c.NotebookApp.password = &#39; &#39;</code>将#注释去掉，然后改成<code>c.NotebookApp.password = u&#39;sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed&#39;</code></p><p> 这里，特别需要注意的是，hash密码字符串前面的那个u不可省略。 </p><h4 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h4><p>将默认值False修改为True，表示允许外部访问，这个设置和下面IP设置，双重保障外部用户访问的可达性：</p><blockquote><p>c.NotebookApp.allow_remote_access = True</p></blockquote><p>等号右边的‘localhost’（仅仅运行本地访问），修改为‘*’，表示允许所有IP皆可访问</p><blockquote><p>c.NotebookApp.ip=’*’</p></blockquote><p>禁止自动打开浏览器</p><blockquote><p>c.NotebookApp.open_browser = False</p></blockquote><p>设置一个固定的notebook服务会监听的IP端口（这里设置为9999），这个值可以任意，只要保证不和其他已经启用的端口号冲突即可。</p><blockquote><p>c.NotebookApp.port = 9999</p></blockquote><p>做完上述配置之后，保存文件并退出。</p><p>但此时修改的配置并没有生效，我们还需要在终端输入“jupyter notebook”命令，这样确保Jupyter重新加载jupyter_notebook_config.py，进而使得新配置起效。</p><p>最后打开浏览器，输入相应IP:端口号即可。</p><h3 id="修改jupyter-notebook的默认工作路径"><a href="#修改jupyter-notebook的默认工作路径" class="headerlink" title="修改jupyter notebook的默认工作路径"></a>修改jupyter notebook的默认工作路径</h3><p>找到刚才的 <strong>jupyter_notebook_config.py</strong> 配置文件，然后定位到 <code>#c.NotebookApp.notebook_dir = &#39;&#39;</code></p><p>然后将其改成你的工作目录即可</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在学习Pytorch，然后实验室有一台双卡的服务器，显卡是特斯拉（貌似很nb），所以就想在服务器上跑代码，炼丹。今天花了点时间配置了一下环境，主要安装了anaconda和pytorch(gpu版本)，为此记录一下= =。&lt;/p&gt;
    
    </summary>
    
    
      <category term="环境配置" scheme="https://cblog.club/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="环境配置" scheme="https://cblog.club/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>139单词拆分</title>
    <link href="https://cblog.club/ck3ecxtn00004v0g4btne0ujz.html"/>
    <id>https://cblog.club/ck3ecxtn00004v0g4btne0ujz.html</id>
    <published>2019-11-23T03:44:50.000Z</published>
    <updated>2019-11-23T04:01:13.433Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个<strong>非空</strong>字符串 <em>s</em> 和一个包含<strong>非空</strong>单词列表的字典 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。 </p><p><strong>说明：</strong></p><ul><li>拆分时可以重复使用字典中的单词。</li><li>你可以假设字典中没有重复的单词。</li></ul><a id="more"></a><blockquote><p><strong>示例 1：</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: s = <span class="string">"leetcode"</span>, wordDict = [<span class="string">"leet"</span>, <span class="string">"code"</span>]</span><br><span class="line">输出: <span class="literal">true</span></span><br><span class="line">解释: 返回 <span class="literal">true</span> 因为 <span class="string">"leetcode"</span> 可以被拆分成 <span class="string">"leet code"</span>。</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入: s = <span class="string">"applepenapple"</span>, wordDict = [<span class="string">"apple"</span>, <span class="string">"pen"</span>]</span><br><span class="line">输出: <span class="literal">true</span></span><br><span class="line">解释: 返回 <span class="literal">true</span> 因为 <span class="string">"applepenapple"</span> 可以被拆分成 <span class="string">"apple pen apple"</span>。</span><br><span class="line">     注意你可以重复使用字典中的单词。</span><br></pre></td></tr></table></figure><p><strong>示例 3：</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: s = <span class="string">"catsandog"</span>, wordDict = [<span class="string">"cats"</span>, <span class="string">"dog"</span>, <span class="string">"sand"</span>, <span class="string">"and"</span>, <span class="string">"cat"</span>]</span><br><span class="line">输出: <span class="literal">false</span></span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题最开始的思路是，遍历字符串，str初试为空，一直加，加到能在字典数组里查到有一个字符串和其相等，然后str再为空，最后能遍历完数组，在最后一位结束也能在字典中查到即可，但是对于aaaaaaa-“aaaa”-“aaa”-，这样的测试数据就没法通过了-，比如aaa，aaa，只剩下一个a，返回false（字典中没有一个a），但是他其实是可以的，先aaaa，再aaa-，所以这种方法宣告失败！后来借鉴了一下动态规划的思想，比较巧妙，dp-i-表示i之前都能够分割完成，相当于将子结构分为两部分，从j的位置开始到i，如果dp-j-1并且-j-i-1-这一部分又能在字典中找到，就意味着i之前这个子结构就是可分的，那么一直遍历到最后，如果字符串长度最后结果还是1的话，代表整个字符串都能够成功分割！"><a href="#解题思路：本题最开始的思路是，遍历字符串，str初试为空，一直加，加到能在字典数组里查到有一个字符串和其相等，然后str再为空，最后能遍历完数组，在最后一位结束也能在字典中查到即可，但是对于aaaaaaa-“aaaa”-“aaa”-，这样的测试数据就没法通过了-，比如aaa，aaa，只剩下一个a，返回false（字典中没有一个a），但是他其实是可以的，先aaaa，再aaa-，所以这种方法宣告失败！后来借鉴了一下动态规划的思想，比较巧妙，dp-i-表示i之前都能够分割完成，相当于将子结构分为两部分，从j的位置开始到i，如果dp-j-1并且-j-i-1-这一部分又能在字典中找到，就意味着i之前这个子结构就是可分的，那么一直遍历到最后，如果字符串长度最后结果还是1的话，代表整个字符串都能够成功分割！" class="headerlink" title="解题思路：本题最开始的思路是，遍历字符串，str初试为空，一直加，加到能在字典数组里查到有一个字符串和其相等，然后str再为空，最后能遍历完数组，在最后一位结束也能在字典中查到即可，但是对于aaaaaaa     “aaaa”   “aaa”   ，这样的测试数据就没法通过了= =，比如aaa，aaa，只剩下一个a，返回false（字典中没有一个a），但是他其实是可以的，先aaaa，再aaa~，所以这种方法宣告失败！后来借鉴了一下动态规划的思想，比较巧妙，dp[i]表示i之前都能够分割完成，相当于将子结构分为两部分，从j的位置开始到i，如果dp[j]=1并且[j,i-1]这一部分又能在字典中找到，就意味着i之前这个子结构就是可分的，那么一直遍历到最后，如果字符串长度最后结果还是1的话，代表整个字符串都能够成功分割！"></a>解题思路：本题最开始的思路是，遍历字符串，str初试为空，一直加，加到能在字典数组里查到有一个字符串和其相等，然后str再为空，最后能遍历完数组，在最后一位结束也能在字典中查到即可，但是对于aaaaaaa     “aaaa”   “aaa”   ，这样的测试数据就没法通过了= =，比如aaa，aaa，只剩下一个a，返回false（字典中没有一个a），但是他其实是可以的，先aaaa，再aaa~，所以这种方法宣告失败！后来借鉴了一下动态规划的思想，比较巧妙，dp[i]表示i之前都能够分割完成，相当于将子结构分为两部分，从j的位置开始到i，如果dp[j]=1并且[j,i-1]这一部分又能在字典中找到，就意味着i之前这个子结构就是可分的，那么一直遍历到最后，如果字符串长度最后结果还是1的话，代表整个字符串都能够成功分割！</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">wordBreak</span><span class="params">(<span class="built_in">string</span> s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; wordDict)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=s.size()+<span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;size;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="built_in">string</span> word : wordDict)&#123;</span><br><span class="line">                <span class="keyword">int</span> wsize=word.size();</span><br><span class="line">                <span class="keyword">if</span>(i&gt;=wsize)&#123;</span><br><span class="line">                    <span class="keyword">int</span> is_exist=s.compare(i-wsize,wsize,word);</span><br><span class="line">                    <span class="keyword">if</span>(is_exist==<span class="number">0</span>&amp;&amp;dp[i-wsize]==<span class="number">1</span>)dp[i]=<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(dp[size<span class="number">-1</span>]==<span class="number">1</span>)<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个&lt;strong&gt;非空&lt;/strong&gt;字符串 &lt;em&gt;s&lt;/em&gt; 和一个包含&lt;strong&gt;非空&lt;/strong&gt;单词列表的字典 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说明：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拆分时可以重复使用字典中的单词。&lt;/li&gt;
&lt;li&gt;你可以假设字典中没有重复的单词。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>DFS深优先度搜索</title>
    <link href="https://cblog.club/ck3ecxtpr002bv0g41j7r8pik.html"/>
    <id>https://cblog.club/ck3ecxtpr002bv0g41j7r8pik.html</id>
    <published>2019-11-22T13:39:02.000Z</published>
    <updated>2019-11-22T14:33:28.128Z</updated>
    
    <content type="html"><![CDATA[<p> 讲搜索当然不能撇开图，搜索思想在图问题中能以最直观的方式展现。 </p><p><strong>深度优先搜索的步骤分为 1.递归下去 2.回溯上来。顾名思义，深度优先，则是以深度为准则，先一条路走到底，直到达到目标。这里称之为递归下去。</strong></p><p><strong>如果既没有达到目标又无路可走了，那么则退回到上一步的状态，走其他路。这便是回溯上来。</strong></p><p>下面结合具体例子来理解。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 讲搜索当然不能撇开图，搜索思想在图问题中能以最直观的方式展现。 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深度优先搜索的步骤分为 1.递归下去 2.回溯上来。顾名思义，深度优先，则是以深度为准则，先一条路走到底，直到达到目标。这里称之为递归下去。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
    
      <category term="算法" scheme="https://cblog.club/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://cblog.club/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch-Day4</title>
    <link href="https://cblog.club/ck3ecxtq7002uv0g4gfmn9234.html"/>
    <id>https://cblog.club/ck3ecxtq7002uv0g4gfmn9234.html</id>
    <published>2019-11-22T13:02:15.000Z</published>
    <updated>2019-11-22T13:37:52.716Z</updated>
    
    <content type="html"><![CDATA[<p>看完官方的入门文档之后，又在github上找了一个教程，这是一个韩国人写的教程，感觉还不错。</p><ul><li>这个资源为深度学习研究人员提供了学习PyTorch的教程</li><li>代码大多数模型都使用少于30行代码实现</li></ul><a id="more"></a><h3 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h3><ul><li>基本的自动求导 例子1</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建张量tensors(这里举得的例子是张量)</span></span><br><span class="line">x = torch.tensor(<span class="number">1.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor(<span class="number">2.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor(<span class="number">3.</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个可以计算的公式 y=2x+3</span></span><br><span class="line">y = w * x + b</span><br><span class="line">y.backward()</span><br><span class="line">print(x.grad)</span><br><span class="line">print(w.grad)</span><br><span class="line">print(b.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor(2.)tensor(1.)tensor(1.)</code></pre><h4 id="来解释一样2，1，1这三个数是怎么来的，首先y-2x-3，那么对于x求梯度（也就是求导）结果为2，以此类推。"><a href="#来解释一样2，1，1这三个数是怎么来的，首先y-2x-3，那么对于x求梯度（也就是求导）结果为2，以此类推。" class="headerlink" title="来解释一样2，1，1这三个数是怎么来的，首先y=2x+3，那么对于x求梯度（也就是求导）结果为2，以此类推。"></a>来解释一样2，1，1这三个数是怎么来的，首先y=2x+3，那么对于x求梯度（也就是求导）结果为2，以此类推。</h4><ul><li>基本的自动求导 例子2</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个 shape(10,3)和(10,2)的张量tensors</span></span><br><span class="line">x=torch.randn(<span class="number">10</span>,<span class="number">3</span>)</span><br><span class="line">y=torch.randn(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个全连接层</span></span><br><span class="line">linear=nn.Linear(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'w:'</span>,linear.weight)</span><br><span class="line">print(<span class="string">'b:'</span>,linear.bias)</span><br></pre></td></tr></table></figure><pre><code>w: Parameter containing:tensor([[-0.1955,  0.2712,  0.5710],        [-0.3143, -0.5540,  0.3058]], requires_grad=True)b: Parameter containing:tensor([-0.2155, -0.1076], requires_grad=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#建立一个损失函数和优化器</span></span><br><span class="line">criterion=nn.MSELoss()</span><br><span class="line">optimizer=torch.optim.SGD(linear.parameters(),lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#前向传播</span></span><br><span class="line">pred=linear(x)</span><br><span class="line"><span class="comment">#计算损失</span></span><br><span class="line">loss=criterion(pre,y)</span><br><span class="line"><span class="comment">#加上item()，就可以转换python中的float型数值</span></span><br><span class="line">print(<span class="string">'loss:'</span>,loss.item())</span><br></pre></td></tr></table></figure><pre><code>loss: 0.9739418625831604</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="comment">#打印输出梯度</span></span><br><span class="line">print(<span class="string">'dl/dw:'</span>,linear.weight.grad)</span><br><span class="line">print(<span class="string">'dl/db:'</span>,linear.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>dl/dw: tensor([[ 0.0576,  0.1626,  0.4199],        [-0.1823, -0.3512,  0.5736]])dl/db: tensor([0.1189, 0.1488])</code></pre><ul><li>optimizer.step()这个方法会更新所有的参数。一旦梯度被如backward()之类的函数计算好后，我们就可以调用这个函数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接着进行梯度下降</span></span><br><span class="line">optimizer.step()</span><br><span class="line"><span class="comment">#打印输出在一次梯度下降优化后的损失</span></span><br><span class="line">pred=linear(x)</span><br><span class="line">loss=criterion(pred,y)</span><br><span class="line">print(<span class="string">'loss after 1 step optimization:'</span>,loss.item())</span><br></pre></td></tr></table></figure><pre><code>loss after 1 step optimization: 0.9595106840133667</code></pre><h4 id="从numpy中加载数据"><a href="#从numpy中加载数据" class="headerlink" title="从numpy中加载数据"></a>从numpy中加载数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先创建一个numpy数组</span></span><br><span class="line">x=np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#将numpy数组转换成torch tensor（torch中的张量）</span></span><br><span class="line">y=torch.from_numpy(x)</span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#再将torch tensor转换成numpy数组</span></span><br><span class="line">z=y.numpy()</span><br><span class="line">print(z)</span><br></pre></td></tr></table></figure><pre><code>tensor([[1, 2],        [3, 4]], dtype=torch.int32)[[1 2] [3 4]]</code></pre><h4 id="定义数据输入流水线（类似于keras中加载数据集的意味）"><a href="#定义数据输入流水线（类似于keras中加载数据集的意味）" class="headerlink" title="定义数据输入流水线（类似于keras中加载数据集的意味）"></a>定义数据输入流水线（类似于keras中加载数据集的意味）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载和创建CIFAR10数据集</span></span><br><span class="line">train_dataset=torchvision.datasets.CIFAR10(root=<span class="string">'./data/'</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取一个数据对(图像和标签)（从磁盘中读取数据）</span></span><br><span class="line">image,label=train_dataset[<span class="number">0</span>]</span><br><span class="line">print(image.size())</span><br><span class="line">print(label)</span><br></pre></td></tr></table></figure><pre><code>Files already downloaded and verifiedtorch.Size([3, 32, 32])6</code></pre><img src="/ck3ecxtq7002uv0g4gfmn9234/1.jpg" class=""><p> 我们可以看出，图片是彩色图像（3通道），尺寸大小是32x32，标签的索引为6，我们知道cifar10：它有如下10个类别:(’airplane’,’automobile’,’bird’,’cat’,’deer’,’dog’,’frog’,’horse’,’ship’,’truck’)，猜测这个6就应该是frog青蛙。嘿，果然他就是！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个显示图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(img)</span>:</span></span><br><span class="line">    img=img/<span class="number">2</span>+<span class="number">0.5</span></span><br><span class="line">    npimg=img.numpy()</span><br><span class="line">    <span class="comment">#transpose对换数组的维度</span></span><br><span class="line">    plt.imshow(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">    print(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)).shape)</span><br><span class="line">    plt.show();</span><br><span class="line"></span><br><span class="line">imshow(image)</span><br></pre></td></tr></table></figure><pre><code>(32, 32, 3)</code></pre><p>这个<code>img=img/2+0.5</code>就是对图像灰度做了点修正，然后transpose对换数组的维度，我们看啊，从数据集中读取的image，它的格式是(3,32,32)，而plt中要显示的图片，它的格式是(32,32,3)所以，要使用这个函数，将图片转换成我们能识别的格式，终于找到原因了= =！~</p><h4 id="数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）"><a href="#数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）" class="headerlink" title="数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）"></a>数据加载到数据加载器中（它以非常简单的方式提供了队列和线程）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#当迭代器开始的时候，队列和线程就会从文件中加载数据</span></span><br><span class="line">data_iter=iter(train_loader)</span><br><span class="line"></span><br><span class="line"><span class="comment">#mini-batch的images和labels</span></span><br><span class="line">images,labels=data_iter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据加载器的实际使用方法如下</span></span><br><span class="line"><span class="keyword">for</span> images,labels <span class="keyword">in</span> train_loader:</span><br><span class="line">    <span class="comment">#训练代码写在这里</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h4 id="为自定义的数据集设计数据输入流水线"><a href="#为自定义的数据集设计数据输入流水线" class="headerlink" title="为自定义的数据集设计数据输入流水线"></a>为自定义的数据集设计数据输入流水线</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先创建自定义的数据集</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDataset</span><span class="params">(torch.utils.data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#To do</span></span><br><span class="line">        <span class="comment">#初始化你的文件路径和文件名列表</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        <span class="comment">#To do</span></span><br><span class="line">        <span class="comment">#首先从文件中取一个数据（举个例子：using numpy.fromfile, PIL.Image.open（打开一个图像文件））</span></span><br><span class="line">        <span class="comment">#接着对数据进行预处理（举个例子：torchvision.Transform）</span></span><br><span class="line">        <span class="comment">#PIL：Python Imaging Library，已经是Python平台事实上的图像处理标准库了。</span></span><br><span class="line">        <span class="comment">#torchvision.Transform对PIL.Image进行变换</span></span><br><span class="line">        <span class="comment">#最后返回一个数据对（image和label）</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#应该将数据集的总大小更改为0，意思就是全部训练完成</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#然后你就可以使用提前创建好的数据加载器</span></span><br><span class="line">custom_dataset=CustomDataset()</span><br><span class="line">train_loader=torch.utils.data.DataLoader(dataset=custom_dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载和加载提前训练好的ResNet-18</span></span><br><span class="line">resnet=torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果你只想微调模型的顶层，可以按照下面设置</span></span><br><span class="line"><span class="keyword">for</span> parm <span class="keyword">in</span> resnet.parameters():</span><br><span class="line">    parm.requires_grad=<span class="literal">False</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#更换顶层进行微调(将原先resnet的全连接层的输入样本大小改为100)</span></span><br><span class="line">resnet.fc=nn.Linear(resnet.fc.in_features,<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#forward省略</span></span><br><span class="line"></span><br><span class="line">images=torch.randn(<span class="number">64</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">outputs=resnet(images)</span><br><span class="line">print(outputs.size())</span><br></pre></td></tr></table></figure><pre><code>Downloading: &quot;https://download.pytorch.org/models/resnet18-5c106cde.pth&quot; to C:\Users\user/.cache\torch\checkpoints\resnet18-5c106cde.pth100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:29&lt;00:00, 1.59MB/s]torch.Size([64, 100])</code></pre><h4 id="保存和加载模型"><a href="#保存和加载模型" class="headerlink" title="保存和加载模型"></a>保存和加载模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存和加载完整的模型</span></span><br><span class="line">torch.save(resnet,<span class="string">'model.ckpt'</span>)</span><br><span class="line">model=torch.load(<span class="string">'model.ckpt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#只保存和加载模型的权重参数（推荐！）</span></span><br><span class="line">torch.save(resnet.state_dict(),<span class="string">'params.ckpt'</span>)</span><br><span class="line">resnet.load_state_dict(torch.load(<span class="string">'params.ckpt'</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;All keys matched successfully&gt;</code></pre><ul><li>state_dict() 以dict返回optimizer的状态。它包含两项。<ul><li>state 一个保存了当前优化状态的dict。optimizer的类别不同，state的内容也会不同。</li><li>param_groups  一个包含了全部参数组的dict。</li></ul></li></ul><h3 id="线性回归练习"><a href="#线性回归练习" class="headerlink" title="线性回归练习"></a>线性回归练习</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的"><a href="#设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的" class="headerlink" title="设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)"></a>设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input_size=<span class="number">1</span></span><br><span class="line">output_size=<span class="number">1</span></span><br><span class="line">num_epochs=<span class="number">60</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#准备数据集Toy dataset（玩具数据集，小数据集，缺乏实验研究，先这样理解，自己玩的数据集（自定义）= =）</span></span><br><span class="line"><span class="comment"># Toy dataset</span></span><br><span class="line">x_train = np.array([[<span class="number">3.3</span>], [<span class="number">4.4</span>], [<span class="number">5.5</span>], [<span class="number">6.71</span>], [<span class="number">6.93</span>], [<span class="number">4.168</span>], </span><br><span class="line">                    [<span class="number">9.779</span>], [<span class="number">6.182</span>], [<span class="number">7.59</span>], [<span class="number">2.167</span>], [<span class="number">7.042</span>], </span><br><span class="line">                    [<span class="number">10.791</span>], [<span class="number">5.313</span>], [<span class="number">7.997</span>], [<span class="number">3.1</span>]], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">y_train = np.array([[<span class="number">1.7</span>], [<span class="number">2.76</span>], [<span class="number">2.09</span>], [<span class="number">3.19</span>], [<span class="number">1.694</span>], [<span class="number">1.573</span>], </span><br><span class="line">                    [<span class="number">3.366</span>], [<span class="number">2.596</span>], [<span class="number">2.53</span>], [<span class="number">1.221</span>], [<span class="number">2.827</span>], </span><br><span class="line">                    [<span class="number">3.465</span>], [<span class="number">1.65</span>], [<span class="number">2.904</span>], [<span class="number">1.3</span>]], dtype=np.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#线性回归的模型,这里输入输出都是一维的，标量，也就是全连接层</span></span><br><span class="line">model=nn.Linear(input_size,output_size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和优化器</span></span><br><span class="line">criterion=nn.MSELoss()</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="comment">#将numpy数组转换成torch tensors</span></span><br><span class="line">    inputs=torch.from_numpy(x_train)</span><br><span class="line">    targets=torch.from_numpy(y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#前向传播</span></span><br><span class="line">    outputs=model(inputs)</span><br><span class="line">    loss=criterion(outputs,targets)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#反向传播和优化</span></span><br><span class="line">    <span class="comment">#zero_grad()将module中的所有模型参数的梯度设置为0.</span></span><br><span class="line">    <span class="comment">#将所有参数的梯度缓存清零,然后进行反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">5</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;],Loss:&#123;:.4f&#125;'</span>.format(epoch+<span class="number">1</span>,num_epochs,loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制图表</span></span><br><span class="line"><span class="comment">#这里如果不加detach()的话，会报错：</span></span><br><span class="line"><span class="comment">#Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.</span></span><br><span class="line"><span class="comment">#无法在需要grad的Variable上调用numpy()。 请改用var.detach().numpy()</span></span><br><span class="line"><span class="comment">#detach()的作用就是不带梯度，返回一个从当前图中分离下来的新的Variable，返回的Variable的requires_grad=False。</span></span><br><span class="line">predicted=model(torch.from_numpy(x_train)).detach().numpy()</span><br><span class="line">plt.plot(x_train,y_train,<span class="string">'ro'</span>,label=<span class="string">'Original data'</span>)</span><br><span class="line">plt.plot(x_train,predicted,label=<span class="string">'Fitted line'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型的权重（推荐，不推荐直接保存网络）</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'linear.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>Epoch [5/60],Loss:10.8415Epoch [10/60],Loss:4.5517Epoch [15/60],Loss:2.0035Epoch [20/60],Loss:0.9710Epoch [25/60],Loss:0.5526Epoch [30/60],Loss:0.3829Epoch [35/60],Loss:0.3140Epoch [40/60],Loss:0.2860Epoch [45/60],Loss:0.2745Epoch [50/60],Loss:0.2696Epoch [55/60],Loss:0.2675Epoch [60/60],Loss:0.2665</code></pre><img src="/ck3ecxtq7002uv0g4gfmn9234/2.jpg" class=""><h3 id="逻辑回归练习"><a href="#逻辑回归练习" class="headerlink" title="逻辑回归练习"></a>逻辑回归练习</h3><h4 id="设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的-1"><a href="#设置超参数Hyper-Parameters-就是人工设定的参数，不是从网络中学到的-1" class="headerlink" title="设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)"></a>设置超参数Hyper-Parameters(就是人工设定的参数，不是从网络中学到的)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input_size=<span class="number">784</span></span><br><span class="line">num_classes=<span class="number">10</span></span><br><span class="line">num_epochs=<span class="number">5</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br></pre></td></tr></table></figure><h4 id="经典的手写数字识别，MNIST数据集（images，labels）"><a href="#经典的手写数字识别，MNIST数据集（images，labels）" class="headerlink" title="经典的手写数字识别，MNIST数据集（images，labels）"></a>经典的手写数字识别，MNIST数据集（images，labels）</h4><ul><li>这里测试集就不需要<code>download=True</code>了，因为经查看文件夹，发现MNIST训练集和测试集在一个包里= =~</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dateset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset=torchvision.datasets.MNIST(root=<span class="string">'./data'</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br></pre></td></tr></table></figure><h4 id="数据加载-设计数据输入流水线"><a href="#数据加载-设计数据输入流水线" class="headerlink" title="数据加载(设计数据输入流水线)"></a>数据加载(设计数据输入流水线)</h4><ul><li>shuffle设置为True时会在每个epoch重新打乱数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_loader=torch.utils.data.DataLoader(dataset=train_dateset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="逻辑回归的模型"><a href="#逻辑回归的模型" class="headerlink" title="逻辑回归的模型"></a>逻辑回归的模型</h4><ul><li><p>这里有必要再介绍一下MNIST数据集，因为你要搞懂输入大小和输出大小的设定是怎么来的</p><ul><li><p>MNIST共有7万张图片。其中6万张用于训练神经网络，1万张用于测试神经网络。</p></li><li><p>每张图片是一个28*28像素点的0~9的手写数字图片。</p></li><li><p>黑底白字。黑底用0表示，白字用0~1之间的浮点数表示，越接近1，颜色越白。</p></li><li><p>我们把784个像素点组成一个长度为784的一维数组，这个一维数据就是我们要喂入神经网络的输入特征。MNIST数据集还提供了每张图片对应的标签，以一个长度为10的一维数组给出。</p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model=nn.Linear(input_size,num_classes)</span><br></pre></td></tr></table></figure><h4 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h4><ul><li>这里我们使用交叉熵来作为损失函数比较好，因为这是一个分类问题，具体原因需要机器学习基础，可能看过，暂时忘了= =！</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#因为我们是按照批量进行训练的，之前设置的batch_size=100,总共有60000张，那么就应该需要600个批次</span></span><br><span class="line">total_step=len(train_loader)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        <span class="comment">#将图片重新设定形状大小，（batch_size,input_size）,多了一维是批量数大小</span></span><br><span class="line">        <span class="comment">#当前的images的大小是28*28*batch_size的，所以再将它们重新变一下形状即可</span></span><br><span class="line">        images=images.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        outputs=model(images)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度置0+反向传播+更新参数</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;'</span>.format(epoch+<span class="number">1</span>, num_epochs, i+<span class="number">1</span>, total_step, loss.item()))</span><br></pre></td></tr></table></figure><pre><code>Epoch [1/5], Step [100/600], Loss: 2.2148Epoch [1/5], Step [200/600], Loss: 2.1090Epoch [1/5], Step [300/600], Loss: 2.0445Epoch [1/5], Step [400/600], Loss: 1.9044Epoch [1/5], Step [500/600], Loss: 1.8223Epoch [1/5], Step [600/600], Loss: 1.7955Epoch [2/5], Step [100/600], Loss: 1.7728Epoch [2/5], Step [200/600], Loss: 1.7020Epoch [2/5], Step [300/600], Loss: 1.6512Epoch [2/5], Step [400/600], Loss: 1.4894Epoch [2/5], Step [500/600], Loss: 1.5539Epoch [2/5], Step [600/600], Loss: 1.4890Epoch [3/5], Step [100/600], Loss: 1.4254Epoch [3/5], Step [200/600], Loss: 1.4015Epoch [3/5], Step [300/600], Loss: 1.4230Epoch [3/5], Step [400/600], Loss: 1.3121Epoch [3/5], Step [500/600], Loss: 1.3245Epoch [3/5], Step [600/600], Loss: 1.3191Epoch [4/5], Step [100/600], Loss: 1.2653Epoch [4/5], Step [200/600], Loss: 1.1637Epoch [4/5], Step [300/600], Loss: 1.2509Epoch [4/5], Step [400/600], Loss: 1.1195Epoch [4/5], Step [500/600], Loss: 1.1106Epoch [4/5], Step [600/600], Loss: 1.1059Epoch [5/5], Step [100/600], Loss: 1.1150Epoch [5/5], Step [200/600], Loss: 1.0129Epoch [5/5], Step [300/600], Loss: 1.0519Epoch [5/5], Step [400/600], Loss: 1.0661Epoch [5/5], Step [500/600], Loss: 0.9755Epoch [5/5], Step [600/600], Loss: 1.0962</code></pre><h4 id="测试模型并保存模型"><a href="#测试模型并保存模型" class="headerlink" title="测试模型并保存模型"></a>测试模型并保存模型</h4><ul><li>这里需要注意的是，在测试阶段，我们不需要再次计算梯度了（为了提高内存的效率= =！）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试模型</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    correct=<span class="number">0</span></span><br><span class="line">    total=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        <span class="comment">#print(labels.size(0)),其值就是100，也就是我们设置的批量大小</span></span><br><span class="line">        images=images.reshape(<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        outputs=model(images)</span><br><span class="line">        _,predicted=torch.max(outputs.data,<span class="number">1</span>)</span><br><span class="line">        total+=labels.size(<span class="number">0</span>)</span><br><span class="line">        correct+=(predicted==labels).sum()</span><br><span class="line">        </span><br><span class="line">    print(<span class="string">'Accuracy of the model on the 10000 test images: &#123;&#125; %'</span>.format(<span class="number">100</span> * correct / total))</span><br><span class="line">    </span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">'logistic.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the model on the 10000 test images: 82 %</code></pre><ul><li>没有用CNN，得到的这个效果其实还可以</li></ul><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>PyTorch使用的流程：</p><ul><li>第一步：通常是设置一些超参数（例如输入大小、如果是分类问题：可能有类别数目、训练轮次，批量大小，学习率）</li><li>第二步：加载数据集（有的是PyTorch中封装好的，也有是自定义的，具体问题具体分析）<ul><li>训练数据集</li><li>测试训练集</li></ul></li><li>第三步：定义数据加载器（设计数据输入流水线）</li><li>第四步：建立模型，复杂一点的就是创建自定义网络模型</li><li>第五步：定义损失函数和优化器<ul><li>回归一般用MSE（均方误差）</li><li>分类问题一般用CrossEntropyLoss（交叉熵）</li></ul></li><li>第六步：训练模型<ul><li>外部循环是训练轮次</li><li>内部循环如果有，一般是数据集很大，我们分成了很多批次，每次按照批次大小训练</li><li>训练的步骤一般是：如果是批量输入，考虑是否要给数据改变形状-&gt;前向传播-&gt;计算损失-&gt;优化器梯度置0-&gt;反向传播-&gt;更新所有参数</li></ul></li><li>第七步：测试模型（在测试阶段不需要计算梯度，使用<code>with torch.no_grad()</code>）</li><li>第八步：保存模型，推荐只保存模型的权重</li></ul><h3 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h3><p>在这个教程里,我们将学习如何使用数据并行(DataParallel)来使用多GPU。</p><p>PyTorch非常容易的就可以使用GPU,你可以用如下方式把一个模型放到GPU上:</p><p><code>device = torch.device(&quot;cuda:0&quot;)</code></p><p><code>model.to(device)</code></p><p>然后你可以复制所有的张量到GPU上:</p><p><code>mytensor = my_tensor.to(device)</code></p><p>请注意,只调用<code>mytensor.gpu()</code>并没有复制张量到GPU上。你需要把它赋值给一个新的张量并在GPU上使用这个张量。</p><p>在多GPU上执行前向和反向传播是自然而然的事。然而，<strong>PyTorch默认将只是用一个GPU</strong>。你可以使用DataParallel让模型并行运行来轻易的让你的操作在多个GPU上运行。</p><p><code>model = nn.DataParallel(model)</code></p><p>这是这篇教程背后的核心，我们接下来将更详细的介绍它</p><h4 id="导入PyTorch模块和定义参数"><a href="#导入PyTorch模块和定义参数" class="headerlink" title="导入PyTorch模块和定义参数"></a>导入PyTorch模块和定义参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义参数</span></span><br><span class="line">input_size=<span class="number">5</span></span><br><span class="line">output_size=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">30</span></span><br><span class="line">data_size=<span class="number">100</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设备</span></span><br><span class="line">device=torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">print(device)</span><br><span class="line">print(torch.cuda.device_count())</span><br><span class="line">print(torch.cuda.current_device())</span><br><span class="line">print(torch.cuda.get_device_name(<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>cuda:010GeForce GTX 950M</code></pre><h4 id="虚拟数据集"><a href="#虚拟数据集" class="headerlink" title="虚拟数据集"></a>虚拟数据集</h4><p>制作一个虚拟（随机）数据集，你只需实现<strong>getitem</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,size,length)</span>:</span></span><br><span class="line">        self.len=length</span><br><span class="line">        <span class="comment">#randn返回一个张量，从标准正态分布（均值为0，方差为1）中抽取的一组随机数。</span></span><br><span class="line">        <span class="comment">#length--整数序列，定义了输出张量的形状</span></span><br><span class="line">        <span class="comment">#size--输出张量的形状</span></span><br><span class="line">        self.data=torch.randn(length,size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,index)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data[index]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.len</span><br><span class="line">    </span><br><span class="line">rand_loader=DataLoader(dataset=RandomDataset(input_size,data_size),batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="简单的模型"><a href="#简单的模型" class="headerlink" title="简单的模型"></a>简单的模型</h4><p>作为演示，我们的模型只接受一个输入，执行一个线性操作，然后得到结果。然而，你能在任何模型（CNN，RNN，Capsule Net等）上使用DataParallel。</p><p>我们在模型内部放置了一条打印语句来检测输入和输出向量的大小。请注意批等级为0时打印的内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_size,output_size)</span>:</span></span><br><span class="line">        <span class="comment">#这句话官方就是这么写，规定好了,继承Module的初始化函数</span></span><br><span class="line">        super(Model,self).__init__()</span><br><span class="line">        self.fc=nn.Linear(input_size,output_size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=self.fc(input)</span><br><span class="line">        print(<span class="string">"\tIn Model: input size"</span>, input.size(),<span class="string">"output size"</span>, output.size())</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><h4 id="创建一个模型和数据并行"><a href="#创建一个模型和数据并行" class="headerlink" title="创建一个模型和数据并行"></a>创建一个模型和数据并行</h4><p>这是本教程的核心部分。首先，我们需要创建一个模型实例和检测我们是否有多个GPU。如果我们有多个GPU，我们使用nn.DataParallel来包装我们的模型。然后通过model.to(device)把模型放到GPU上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model=Model(input_size,output_size)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count()&gt;<span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"let's use"</span>,torch.cuda.device_count(),<span class="string">"GPUs!"</span>)</span><br><span class="line">    </span><br><span class="line">    model=nn.DataParallel(model)</span><br><span class="line">    </span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><pre><code>Model(  (fc): Linear(in_features=5, out_features=2, bias=True))</code></pre><h4 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h4><p>现在我们可以看看输入和输出张量的大小</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input=data.to(device)</span><br><span class="line">    output=model(input)</span><br><span class="line">    print(<span class="string">"outside: input size"</span>,input_size,<span class="string">"output size"</span>,output_size)</span><br></pre></td></tr></table></figure><pre><code>    In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])outside: input size 5 output size 2    In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])outside: input size 5 output size 2    In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])outside: input size 5 output size 2    In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])outside: input size 5 output size 2</code></pre><h4 id="但是，我只有一个GPU-！"><a href="#但是，我只有一个GPU-！" class="headerlink" title="但是，我只有一个GPU = =！"></a>但是，我只有一个GPU = =！</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看完官方的入门文档之后，又在github上找了一个教程，这是一个韩国人写的教程，感觉还不错。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这个资源为深度学习研究人员提供了学习PyTorch的教程&lt;/li&gt;
&lt;li&gt;代码大多数模型都使用少于30行代码实现&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Python之进程和线程_2</title>
    <link href="https://cblog.club/ck3ecxtql003av0g4dp1h8pct.html"/>
    <id>https://cblog.club/ck3ecxtql003av0g4dp1h8pct.html</id>
    <published>2019-11-22T06:31:14.000Z</published>
    <updated>2019-11-22T06:49:52.342Z</updated>
    
    <content type="html"><![CDATA[<h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><p>多任务可以由多进程完成，也可以由一个进程内的多线程完成。</p><p>我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。</p><p>由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。</p><a id="more"></a><p>Python的标准库提供了两个模块：<code>_thread</code>和<code>threading</code>，<code>_thread</code>是低级模块，<code>threading</code>是高级模块，对<code>_thread</code>进行了封装。绝大多数情况下，我们只需要使用<code>threading</code>这个高级模块。</p><p>启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#新线程的执行代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">'thread %s is running ...'</span>%threading.current_thread().name)</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="number">5</span> :</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">        print(<span class="string">'thread %s &gt;&gt;&gt; %s'</span>%(threading.current_thread().name,n))</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">'thread %s is ended.'</span>%threading.current_thread().name)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'thread %s is running ...'</span>%threading.current_thread().name)</span><br><span class="line">t=threading.Thread(target=loop,name=<span class="string">'LoopThread'</span>)</span><br><span class="line">t.start()</span><br><span class="line">t.join()</span><br><span class="line">print(<span class="string">'thread %s ended.'</span>%threading.current_thread().name)</span><br><span class="line">thread MainThread <span class="keyword">is</span> running ...</span><br><span class="line">thread LoopThread <span class="keyword">is</span> running ...</span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">1</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">2</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">3</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">4</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">5</span></span><br><span class="line">thread LoopThread <span class="keyword">is</span> ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure><p>由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个<code>current_thread()</code>函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2……</p><h4 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h4><p>多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，<strong>所有变量都由所有线程共享</strong> ，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。</p><p>来看看多个线程同时操作一个变量怎么把内容给改乱了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#假定这是你的银行存款,balance有结余的意思（get了）</span></span><br><span class="line">balance=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_balance</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="comment">#先存款，后取款，结果应为0，在这里的global关键字，定义的一个全局变量，对应于函数外的balance</span></span><br><span class="line">    <span class="keyword">global</span> balance</span><br><span class="line">    balance = balance + n</span><br><span class="line">    balance = balance - n</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_thread</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000000</span>):</span><br><span class="line">        change_balance(n)</span><br><span class="line"></span><br><span class="line">t1=threading.Thread(target=run_thread,name=<span class="string">'t1'</span>,args=(<span class="number">5</span>,))</span><br><span class="line">t2=threading.Thread(target=run_thread,name=<span class="string">'t2'</span>,args=(<span class="number">8</span>,))</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br><span class="line">print(balance)</span><br><span class="line"><span class="number">90</span></span><br></pre></td></tr></table></figure><p>我们定义了一个共享变量balance，初始值为0，并且启动两个线程，先存后取，理论上结果应该为0，但是，由于<strong>线程的调度是由操作系统决定的</strong>，当t1、t2交替执行时，只要<strong>循环次数足够多</strong> ，balance的结果就不一定是0了。</p><p>原因是因为高级语言的一条语句在CPU执行时是若干条语句，即使一个简单的计算： <code>balance = balance + n</code> 也分为两步：</p><ul><li>计算balance + n，存入临时变量中</li><li>将临时变量的值赋给balance 也就是可以看成：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = balance + n</span><br><span class="line">balance = x</span><br></pre></td></tr></table></figure><p>由于x是局部变量，两个线程各自都有自己的x，当代码正常执行时：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">初始值 balance = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">t1: x1 = balance + <span class="number">5</span> <span class="comment"># x1 = 0 + 5 = 5</span></span><br><span class="line">t1: balance = x1     <span class="comment"># balance = 5</span></span><br><span class="line">t1: x1 = balance - <span class="number">5</span> <span class="comment"># x1 = 5 - 5 = 0</span></span><br><span class="line">t1: balance = x1     <span class="comment"># balance = 0</span></span><br><span class="line"></span><br><span class="line">t2: x2 = balance + <span class="number">8</span> <span class="comment"># x2 = 0 + 8 = 8</span></span><br><span class="line">t2: balance = x2     <span class="comment"># balance = 8</span></span><br><span class="line">t2: x2 = balance - <span class="number">8</span> <span class="comment"># x2 = 8 - 8 = 0</span></span><br><span class="line">t2: balance = x2     <span class="comment"># balance = 0</span></span><br><span class="line">    </span><br><span class="line">结果 balance = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>但是t1和t2是交替运行的，如果操作系统是以下面的顺序执行的话：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">初始值 balance = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">t1: x1 = balance + <span class="number">5</span>  <span class="comment"># x1 = 0 + 5 = 5</span></span><br><span class="line"></span><br><span class="line">t2: x2 = balance + <span class="number">8</span>  <span class="comment"># x2 = 0 + 8 = 8</span></span><br><span class="line">t2: balance = x2      <span class="comment"># balance = 8</span></span><br><span class="line"></span><br><span class="line">t1: balance = x1      <span class="comment"># balance = 5</span></span><br><span class="line">t1: x1 = balance - <span class="number">5</span>  <span class="comment"># x1 = 5 - 5 = 0</span></span><br><span class="line">t1: balance = x1      <span class="comment"># balance = 0</span></span><br><span class="line"></span><br><span class="line">t2: x2 = balance - <span class="number">8</span>  <span class="comment"># x2 = 0 - 8 = -8</span></span><br><span class="line">t2: balance = x2   <span class="comment"># balance = -8</span></span><br><span class="line"></span><br><span class="line">结果 balance = <span class="number">-8</span></span><br></pre></td></tr></table></figure><p>究其原因，是因为修改balance需要多条语句，而<strong>执行这几条语句时，线程可能中断</strong>，从而导致多个线程把同一个对象的内容改乱了。</p><p>两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以，我们必须确保一个线程在修改balance的时候，别的线程一定不能改。</p><p>如果我们要确保balance计算正确，就要给<code>change_balance()</code>上一把锁，当某个线程开始执行<code>change_balance()</code>时，我们说，该线程因为获得了锁，因此其他线程不能同时执行<code>change_balance()</code>，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁(就是OS相关的互斥)，所以，不会造成修改的冲突。创建一个锁就是通过<code>threading.Lock()</code>来实现：</p><h5 id="增加锁后的代码，运行时间稍微有一点点"><a href="#增加锁后的代码，运行时间稍微有一点点" class="headerlink" title="增加锁后的代码，运行时间稍微有一点点"></a>增加锁后的代码，运行时间稍微有一点点</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#假定这是你的银行存款,balance有结余的意思（get了）</span></span><br><span class="line">balance=<span class="number">0</span></span><br><span class="line"><span class="comment">#创建一个锁</span></span><br><span class="line">lock=threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_balance</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="comment">#先存款，后取款，结果应为0，在这里的global关键字，定义的一个全局变量，对应于函数外的balance</span></span><br><span class="line">    <span class="keyword">global</span> balance</span><br><span class="line">    balance = balance + n</span><br><span class="line">    balance = balance - n</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_thread</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000000</span>):</span><br><span class="line">        <span class="comment">#先要获取锁</span></span><br><span class="line">        lock.acquire()</span><br><span class="line">        <span class="comment">#try/finally语句不管有没有异常，都会执行finally语句</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment">#放心的修改</span></span><br><span class="line">            change_balance(n)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="comment">#改完了一次就释放锁</span></span><br><span class="line">            lock.release()</span><br><span class="line"></span><br><span class="line">t1=threading.Thread(target=run_thread,name=<span class="string">'t1'</span>,args=(<span class="number">5</span>,))</span><br><span class="line">t2=threading.Thread(target=run_thread,name=<span class="string">'t2'</span>,args=(<span class="number">8</span>,))</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br><span class="line">print(balance)</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure><p>当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。</p><p>获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程（饿死）。所以我们用try…finally来确保锁一定会被释放。</p><p>锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，</p><ul><li>首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。</li><li>其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。</li></ul><h4 id="多核CPU"><a href="#多核CPU" class="headerlink" title="多核CPU"></a>多核CPU</h4><p>如果你不幸拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。</p><p>如果写一个死循环的话，会出现什么情况呢？</p><p>打开Mac OS X的Activity Monitor，或者Windows的Task Manager，都可以监控某个进程的CPU使用率。</p><p>我们可以监控到一个死循环线程会100%占用一个CPU。</p><p>如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。</p><p>要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。</p><p>试试用Python写个死循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading,multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">()</span>:</span></span><br><span class="line">    x=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        x=x^<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count()):</span><br><span class="line">    t=threading.Thread(target=loop)</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。</p><p>但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？</p><p>因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个<strong>GIL锁</strong>：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行<strong>100条字节码</strong>，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。</p><p>GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。</p><p>所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。</p><p>不过，也不用过于担心，Python虽然<strong>不能利用多线程实现多核任务，但可以通过多进程实现多核任务</strong>。多个Python进程有各自独立的GIL锁，互不影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">()</span>:</span></span><br><span class="line">    x=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        x=x^<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count()):</span><br><span class="line">    p=multiprocessing.Process(target=loop)</span><br><span class="line">    p.start()</span><br></pre></td></tr></table></figure><p>但是查看Task manager 并没有发现CPU利用率很高= =</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。</p><p>Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。</p><h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><p>在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。</p><p>但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_student</span><span class="params">(name)</span>:</span></span><br><span class="line">    std = Student(name)</span><br><span class="line">    <span class="comment"># std是局部变量，但是每个函数都要用它，因此必须传进去：</span></span><br><span class="line">    do_task_1(std)</span><br><span class="line">    do_task_2(std)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_1</span><span class="params">(std)</span>:</span></span><br><span class="line">    do_subtask_1(std)</span><br><span class="line">    do_subtask_2(std)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_2</span><span class="params">(std)</span>:</span></span><br><span class="line">    do_subtask_2(std)</span><br><span class="line">    do_subtask_2(std)</span><br></pre></td></tr></table></figure><p>每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的Student对象，不能共享。</p><p>如果用一个全局<code>dict</code>存放所有的Student对象，然后以<code>thread</code>自身作为<code>key</code>获得线程对应的Student对象如何？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">global_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">std_thread</span><span class="params">(name)</span>:</span></span><br><span class="line">    std = Student(name)</span><br><span class="line">    <span class="comment"># 把std放到全局变量global_dict中：</span></span><br><span class="line">    global_dict[threading.current_thread()] = std</span><br><span class="line">    do_task_1()</span><br><span class="line">    do_task_2()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 不传入std，而是根据当前线程查找：</span></span><br><span class="line">    std = global_dict[threading.current_thread()]</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_task_2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 任何函数都可以查找出当前线程的std变量：</span></span><br><span class="line">    std = global_dict[threading.current_thread()]</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>这种方式理论上是可行的，它最大的优点是消除了std对象在每层函数中的传递问题，但是，每个函数获取std的代码有点丑。</p><p>有没有更简单的方式？</p><p>ThreadLocal应运而生，不用查找dict，ThreadLocal帮你自动做这件事：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建全局ThreadLocal对象</span></span><br><span class="line">local_school=threading.local()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_thread</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="comment">#绑定ThreadLocal的student</span></span><br><span class="line">    local_school.student=name</span><br><span class="line">    process_student()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_student</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#获取当前线程关联的student</span></span><br><span class="line">    std=local_school.student</span><br><span class="line">    print(<span class="string">'Hello , %s (in %s)\n'</span>%(std,threading.current_thread().name))</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target=process_thread,args=(<span class="string">'lemon'</span>,),name=<span class="string">'thread-lemon'</span>)</span><br><span class="line">t2 = threading.Thread(target=process_thread,args=(<span class="string">'leocode'</span>,),name=<span class="string">'thread-leocode'</span>)</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br><span class="line">print(<span class="string">'end!'</span>)</span><br><span class="line">Hello , lemon (<span class="keyword">in</span> thread-lemon)</span><br><span class="line"></span><br><span class="line">Hello , leocode (<span class="keyword">in</span> thread-leocode)</span><br><span class="line"></span><br><span class="line">end!</span><br></pre></td></tr></table></figure><p>全局变量<code>local_school</code>就是一个<code>ThreadLocal</code>对象，每个Thread对它都可以读写student属性，但互不影响。你可以把<code>local_school</code>看成全局变量，但每个属性如<code>local_school.student</code>都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。</p><p>可以理解为全局变量<code>local_school</code>是一个dict，不但可以用<code>local_school.student</code>，还可以绑定其他变量，如<code>local_school.teacher</code>等等。</p><p>ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。</p><h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p>一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。</p><h3 id="进程VS线程"><a href="#进程VS线程" class="headerlink" title="进程VS线程"></a>进程VS线程</h3><p>我们介绍了多进程和多线程，这是实现多任务最常用的两种方式。现在，我们来讨论一下这两种方式的优缺点。</p><p>首先，要实现多任务，通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责执行任务，因此，多任务环境下，通常是一个Master，多个Worker。</p><h4 id="简单介绍一下Master-Worker模式："><a href="#简单介绍一下Master-Worker模式：" class="headerlink" title="简单介绍一下Master-Worker模式："></a>简单介绍一下Master-Worker模式：</h4><ul><li>Master-Worker模式是常用的并行设计模式。它的核心思想是，系统有两个进程协议工作：Master进程和Worker进程。Master进程负责接收和分配任务，Worker进程负责处理子任务。当各个Worker进程将子任务处理完后，将结果返回给Master进程，由Master进行归纳和汇总，从而得到系统结果。</li><li><img src="/ck3ecxtql003av0g4dp1h8pct/1.jpg" class=""></li><li>Master-Worker模式的好处是，它能将大任务分解成若干个小任务，并发执行，从而提高系统性能。而对于系统请求者Client来说，任务一旦提交，Master进程就会立刻分配任务并立即返回，并不会等系统处理完全部任务再返回，其处理过程是异步的。</li></ul><h4 id="Master-Worker模式结构"><a href="#Master-Worker模式结构" class="headerlink" title="Master-Worker模式结构"></a>Master-Worker模式结构</h4><ul><li><img src="/ck3ecxtql003av0g4dp1h8pct/2.jpg" class=""></li><li>如上图所示，Master进程是主要进程，它维护着一个Worker进程队列、子任务队列和子结果集，Worker进程中的Worker进程不断的从任务队列中提取要处理的子任务，并将子任务的处理结果放入到子结果集中。</li><li>在上图中，Master：用于任务的分配和最终结果的合并；Worker：用于实际处理一个任务；客户端进程：用于启动系统，调度开启Master。</li></ul><p>如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。</p><p>如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。</p><p>多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。</p><p>多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。</p><p>多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。</p><p>在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式，真是把问题越搞越复杂(= =)。</p><h4 id="线程切换"><a href="#线程切换" class="headerlink" title="线程切换"></a>线程切换</h4><p>无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？</p><p>我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。</p><p>如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为单任务模型，或者批处理任务模型。</p><p>假设你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以幼儿园小朋友的眼光来看，你就正在同时写5科作业。</p><p>但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫<strong>保存现场</strong>），然后，打开数学课本、找出圆规直尺（这叫<strong>准备新环境</strong>），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于<strong>假死状态</strong>。</p><p>所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好。</p><h4 id="计算密集型-vs-IO密集型"><a href="#计算密集型-vs-IO密集型" class="headerlink" title="计算密集型 vs. IO密集型"></a>计算密集型 vs. IO密集型</h4><p>是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和IO密集型。</p><p>计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。</p><p>计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。<strong>对于计算密集型任务，最好用C语言编写</strong>。</p><p>第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。</p><p>IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。<strong>对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差</strong>。</p><h4 id="异步IO"><a href="#异步IO" class="headerlink" title="异步IO"></a>异步IO</h4><p>考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。</p><p>现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用<strong>异步IO编程模型来实现多任务是一个主要的趋势</strong>。</p><p>对应到Python语言，<strong>单线程的异步编程模型称为协程</strong>，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。我们会在后面讨论如何编写协程。</p><h4 id="分布式进程"><a href="#分布式进程" class="headerlink" title="分布式进程"></a>分布式进程</h4><p>在Thread和Process中，应当优选Process，因为Process更稳定，而且，<strong>Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上</strong>。</p><p>Python的<code>multiprocessing</code>模块不但支持多进程，其中<code>managers</code>子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于<code>managers</code>模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。</p><p>举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？</p><p>原有的Queue可以继续使用，但是，通过<code>managers</code>模块<strong>把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了</strong>。</p><p>我们先看服务进程，服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务：</p><ul><li>task_master.py，相当于分布式的主进程</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random,time,queue</span><br><span class="line"><span class="keyword">from</span> multiprocessing.managers <span class="keyword">import</span> BaseManager</span><br><span class="line"></span><br><span class="line"><span class="comment">#发送任务的队列：</span></span><br><span class="line">task_queue=queue.Queue()</span><br><span class="line"><span class="comment">#接收结果的队列</span></span><br><span class="line">result_queue=queue.Queue()</span><br><span class="line"></span><br><span class="line"><span class="comment">#从BaseManager继承的QueueManager</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueueManager</span><span class="params">(BaseManager)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#把两个Queue都注册到网络上，callale参数关联了Queue对象：</span></span><br><span class="line"><span class="comment">#lambda是匿名函数，可以理解为一次函数的执行过程</span></span><br><span class="line">QueueManager.register(<span class="string">'get_task_queue'</span>,callable=<span class="keyword">lambda</span> : task_queue)</span><br><span class="line">QueueManager.register(<span class="string">'get_result_queue'</span>,callable=<span class="keyword">lambda</span> : result_queue)</span><br><span class="line"><span class="comment">#绑定端口5000，设置验证码为'abc'</span></span><br><span class="line">manager=QueueManager(address=(<span class="string">''</span>,<span class="number">5000</span>),authkey=<span class="string">b'abc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动Queue</span></span><br><span class="line">manager.start()</span><br><span class="line"><span class="comment">#获得通过网络访问的Queue对象</span></span><br><span class="line">task=manager.get_task_queue()</span><br><span class="line">result=manager.get_result_queue()</span><br><span class="line"></span><br><span class="line"><span class="comment">#放几个任务进去</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    n=random.randint(<span class="number">0</span>,<span class="number">10000</span>)</span><br><span class="line">    print(<span class="string">'put task %s'</span>%n)</span><br><span class="line">    task.put(n)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从result队列读取结果</span></span><br><span class="line">print(<span class="string">'Try get results'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    r=result.get(timeout=<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">'result : %s'</span>%r)</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭</span></span><br><span class="line">manager.shutdown()</span><br><span class="line">print(<span class="string">'master.exit.'</span>)</span><br></pre></td></tr></table></figure><p>请注意，当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。</p><p>然后，在另一台机器上启动任务进程（本机上启动也可以）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time,sys,queue</span><br><span class="line"><span class="keyword">from</span> multiprocessing.managers <span class="keyword">import</span> BaseManager</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建类似的QueueManager</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueueManager</span><span class="params">(BaseManager)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#由于这个QueueManager只能从网络上获取Queue，所以注册时只提供名字</span></span><br><span class="line">QueueManager.register(<span class="string">'get_task_queue'</span>)</span><br><span class="line">QueueManager.register(<span class="string">'get_result_queue'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#连接到服务器，也就是运行task_master.py的机器</span></span><br><span class="line">server_addr=<span class="string">'127.0.0.1'</span></span><br><span class="line">print(<span class="string">'Connect to server %s...'</span>%server_addr)</span><br><span class="line"></span><br><span class="line"><span class="comment">#端口和验证码注意保持和task_master.py这只的完全一致</span></span><br><span class="line">m=QueueManager(address=(server_addr,<span class="number">5000</span>),authkey=<span class="string">b'abc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从网络连接</span></span><br><span class="line">m.connect()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取Queue的对象</span></span><br><span class="line">task=m.get_task_queue()</span><br><span class="line">result=m.get_result_queue()</span><br><span class="line"></span><br><span class="line"><span class="comment">#从task任务队列取任务，并把结果写入到result队列</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        n=task.get(timeout=<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'run task %d * %d...'</span>%(n,n))</span><br><span class="line">        r=<span class="string">'%d * %d = %d'</span>%(n,n,n*n)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        result.put(r)</span><br><span class="line">    <span class="keyword">except</span> Queue.Empty:</span><br><span class="line">        print(<span class="string">'task queue is empty.'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#处理结束</span></span><br><span class="line">print(<span class="string">'worker exit.'</span>)</span><br></pre></td></tr></table></figure><p>任务进程要通过网络连接到服务进程，所以要指定服务进程的IP。</p><p>现在，可以试试分布式进程的工作效果了。先启动<code>task_master.py</code>服务进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">liuchuang@ubuntu<span class="number">-4</span>:~/python$ python3 task_master.py</span><br><span class="line">put task <span class="number">4270</span></span><br><span class="line">put task <span class="number">7611</span></span><br><span class="line">put task <span class="number">6983</span></span><br><span class="line">put task <span class="number">2863</span></span><br><span class="line">put task <span class="number">9611</span></span><br><span class="line">put task <span class="number">2283</span></span><br><span class="line">put task <span class="number">3883</span></span><br><span class="line">put task <span class="number">9928</span></span><br><span class="line">put task <span class="number">5946</span></span><br><span class="line">put task <span class="number">7511</span></span><br><span class="line">Try get results</span><br></pre></td></tr></table></figure><p><code>task_master.py</code>进程发送完任务后，开始等待result队列的结果。现在启动<code>task_worker.py</code>进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">liuchuang@ubuntu<span class="number">-4</span>:~/python$ python3 task_worker.py</span><br><span class="line">Connect to server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>...</span><br><span class="line">run task <span class="number">4270</span> * <span class="number">4270.</span>..</span><br><span class="line">run task <span class="number">7611</span> * <span class="number">7611.</span>..</span><br><span class="line">run task <span class="number">6983</span> * <span class="number">6983.</span>..</span><br><span class="line">run task <span class="number">2863</span> * <span class="number">2863.</span>..</span><br><span class="line">run task <span class="number">9611</span> * <span class="number">9611.</span>..</span><br><span class="line">run task <span class="number">2283</span> * <span class="number">2283.</span>..</span><br><span class="line">run task <span class="number">3883</span> * <span class="number">3883.</span>..</span><br><span class="line">run task <span class="number">9928</span> * <span class="number">9928.</span>..</span><br><span class="line">run task <span class="number">5946</span> * <span class="number">5946.</span>..</span><br><span class="line">run task <span class="number">7511</span> * <span class="number">7511.</span>..</span><br><span class="line">worker exit.</span><br></pre></td></tr></table></figure><p><code>task_worker.py</code>进程结束，在<code>task_master.py</code>进程中会继续打印出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">liuchuang@ubuntu<span class="number">-4</span>:~/python$ python3 task_master.py</span><br><span class="line">put task <span class="number">4270</span></span><br><span class="line">put task <span class="number">7611</span></span><br><span class="line">put task <span class="number">6983</span></span><br><span class="line">put task <span class="number">2863</span></span><br><span class="line">put task <span class="number">9611</span></span><br><span class="line">put task <span class="number">2283</span></span><br><span class="line">put task <span class="number">3883</span></span><br><span class="line">put task <span class="number">9928</span></span><br><span class="line">put task <span class="number">5946</span></span><br><span class="line">put task <span class="number">7511</span></span><br><span class="line">Try get results</span><br><span class="line">result : <span class="number">4270</span> * <span class="number">4270</span> = <span class="number">18232900</span></span><br><span class="line">result : <span class="number">7611</span> * <span class="number">7611</span> = <span class="number">57927321</span></span><br><span class="line">result : <span class="number">6983</span> * <span class="number">6983</span> = <span class="number">48762289</span></span><br><span class="line">result : <span class="number">2863</span> * <span class="number">2863</span> = <span class="number">8196769</span></span><br><span class="line">result : <span class="number">9611</span> * <span class="number">9611</span> = <span class="number">92371321</span></span><br><span class="line">result : <span class="number">2283</span> * <span class="number">2283</span> = <span class="number">5212089</span></span><br><span class="line">result : <span class="number">3883</span> * <span class="number">3883</span> = <span class="number">15077689</span></span><br><span class="line">result : <span class="number">9928</span> * <span class="number">9928</span> = <span class="number">98565184</span></span><br><span class="line">result : <span class="number">5946</span> * <span class="number">5946</span> = <span class="number">35354916</span></span><br><span class="line">result : <span class="number">7511</span> * <span class="number">7511</span> = <span class="number">56415121</span></span><br><span class="line">master.exit.</span><br></pre></td></tr></table></figure><p>这个简单的Master/Worker模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个worker，就可以把任务分布到几台甚至几十台机器上，比如把计算<code>n*n</code>的代码换成发送邮件，就实现了邮件队列的异步发送。</p><p>Queue对象存储在哪？注意到task_worker.py中根本没有创建Queue的代码，所以，Queue对象存储在task_master.py进程中： <img src="/ck3ecxtql003av0g4dp1h8pct/3.jpg" class="">而Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，所以，要给每个Queue的网络调用接口起个名字，比如get_task_queue。</p><p>authkey有什么用？这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果task_worker.py的authkey和task_master.py的authkey不一致，肯定连接不上。</p><h4 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h4><p>Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。</p><p>注意Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;多线程&quot;&gt;&lt;a href=&quot;#多线程&quot; class=&quot;headerlink&quot; title=&quot;多线程&quot;&gt;&lt;/a&gt;多线程&lt;/h3&gt;&lt;p&gt;多任务可以由多进程完成，也可以由一个进程内的多线程完成。&lt;/p&gt;
&lt;p&gt;我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。&lt;/p&gt;
&lt;p&gt;由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://cblog.club/categories/Python/"/>
    
      <category term="OS" scheme="https://cblog.club/categories/Python/OS/"/>
    
    
      <category term="Python" scheme="https://cblog.club/tags/Python/"/>
    
      <category term="OS" scheme="https://cblog.club/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch_Day3</title>
    <link href="https://cblog.club/ck3ecxtqa002zv0g4032i4kj7.html"/>
    <id>https://cblog.club/ck3ecxtqa002zv0g4032i4kj7.html</id>
    <published>2019-11-21T14:24:18.000Z</published>
    <updated>2019-11-21T14:28:43.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="训练一个分类器"><a href="#训练一个分类器" class="headerlink" title="训练一个分类器"></a>训练一个分类器</h2><p>在了解了如何定义一个神经网络、计算损失值和更新网络的权重之后，那么数据从哪里来呢？</p><p>关于数据<br>通常，当你处理图像，文本，音频和视频数据时，你可以使用标准的Python包来加载数据到一个numpy数组中.然后把这个数组转换成torch.Tensor。</p><a id="more"></a><ul><li>对于图像,有诸如Pillow,OpenCV包等非常实用</li><li>对于音频,有诸如scipy和librosa包</li><li>对于文本,可以用原始Python和Cython来加载,或者使用NLTK和SpaCy </li><li>对于视觉,我们创建了一个torchvision包,包含常见数据集的数据加载,比如Imagenet,CIFAR10,MNIST等,和图像转换器,也就是torchvision.datasets和torch.utils.data.DataLoader。</li></ul><p>在之前，我用keras训练了Cifar10训练集，现在尝试使用PyTorch来训练一个分类器。</p><ul><li>cifar10：它有如下10个类别:’airplane’,’automobile’,’bird’,’cat’,’deer’,’dog’,’frog’,’horse’,’ship’,’truck’。这个数据集中的图像大小为32x32,即,3通道,32x32像素。</li></ul><h4 id="训练一个图像分类器"><a href="#训练一个图像分类器" class="headerlink" title="训练一个图像分类器"></a>训练一个图像分类器</h4><ul><li>使用totchvision加载和归一化Cifar10训练集和测试集</li><li>定义一个卷积神经网络</li><li>定义损失函数</li><li>在训练集上训练网络</li><li>在测试及上测试网络</li></ul><h4 id="加载和归一化cifar10"><a href="#加载和归一化cifar10" class="headerlink" title="加载和归一化cifar10"></a>加载和归一化cifar10</h4><p>使用torchvision加载cifar10是非常容易的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><h4 id="torchvision的输出是-0-1-的PILimage（python中的图像处理库PIL）图像，我们将其转换为-1-1-的张量"><a href="#torchvision的输出是-0-1-的PILimage（python中的图像处理库PIL）图像，我们将其转换为-1-1-的张量" class="headerlink" title="torchvision的输出是[0,1]的PILimage（python中的图像处理库PIL）图像，我们将其转换为[-1,1]的张量"></a>torchvision的输出是[0,1]的PILimage（python中的图像处理库PIL）图像，我们将其转换为[-1,1]的张量</h4><p>transforms.Compose</p><ul><li>将多个transform组合起来使用。</li><li>transforms： 由transform构成的列表</li><li>channel=（channel-mean）/std(因为transforms.ToTensor()已经把数据处理成[0,1],那么(x-0.5)/0.5就是[-1.0, 1.0])</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">transform=transforms.Compose(</span><br><span class="line">    <span class="comment">#前者是均值，后者是标准差</span></span><br><span class="line">    [transforms.ToTensor(),transforms.Normalize((<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>),(<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>))]</span><br><span class="line">)</span><br><span class="line">    </span><br><span class="line">trainset=torchvision.datasets.CIFAR10(root=<span class="string">'/data'</span>,train=<span class="literal">True</span>,download=<span class="literal">False</span>,transform=transform)</span><br><span class="line"><span class="comment">#shuffle 随机排序</span></span><br><span class="line">trainloader=torch.utils.data.DataLoader(trainset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset=torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>,train=<span class="literal">False</span>,download=<span class="literal">False</span>,transform=transform)</span><br><span class="line">testloader=torch.utils.data.DataLoader(testset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">False</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes=(<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>,<span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>)</span><br></pre></td></tr></table></figure><p>展示一些有趣的训练图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个显示图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(img)</span>:</span></span><br><span class="line">    img=img/<span class="number">2</span>+<span class="number">0.5</span></span><br><span class="line">    npimg=img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">    plt.show();</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取一些随机的训练图片</span></span><br><span class="line">dataiter=iter(trainloader)</span><br><span class="line">images,labels=dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出标签</span></span><br><span class="line">print(<span class="string">' '</span>.join(<span class="string">'%11s'</span>%classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><img src="/ck3ecxtqa002zv0g4032i4kj7/1.png" class=""><pre><code>plane       truck       plane         car</code></pre><h4 id="定义一个卷积神经网络"><a href="#定义一个卷积神经网络" class="headerlink" title="定义一个卷积神经网络"></a>定义一个卷积神经网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net,self).__init__()</span><br><span class="line">        <span class="comment">#输入是三通道的图，然后输出的是6通道的图，采用5x5的卷积框</span></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">6</span>,<span class="number">5</span>)</span><br><span class="line">        <span class="comment">#2x2的最大池化层</span></span><br><span class="line">        self.pool=nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#这里的输入时6通道，因为上边输出的6通道，我们用来接收，最后输出15通道的图，继续采用5x5的卷积框</span></span><br><span class="line">        self.conv2=nn.Conv2d(<span class="number">6</span>,<span class="number">16</span>,<span class="number">5</span>)</span><br><span class="line">        <span class="comment">#定义三个全连接层，对输入数据做线性变换，最后输出图像是120通道数</span></span><br><span class="line">        self.fc1=nn.Linear(<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>,<span class="number">120</span>)</span><br><span class="line">        self.fc2=nn.Linear(<span class="number">120</span>,<span class="number">84</span>)</span><br><span class="line">        self.fc3=nn.Linear(<span class="number">84</span>,<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#上边定义的并没有激活</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x=self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x=x.view(<span class="number">-1</span>,<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>)</span><br><span class="line">        x=F.relu(self.fc1(x))</span><br><span class="line">        x=F.relu(self.fc2(x))</span><br><span class="line">        x=self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">net=Net()</span><br></pre></td></tr></table></figure><h4 id="定义损失函数和优化器"><a href="#定义损失函数和优化器" class="headerlink" title="定义损失函数和优化器"></a>定义损失函数和优化器</h4><ul><li>使用交叉熵作为损失函数</li><li>使用带动量的随机梯度下降</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment">#损失函数标准为交叉熵</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#动量因子momentum</span></span><br><span class="line">optimizer=optim.SGD(net.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h4 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h4><ul><li>这时开始有趣的时刻，我们只需要在数据迭代器上循环，把数据输入给网络并优化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#epoch很熟悉了，这是数据集训练的轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    </span><br><span class="line">    running_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> enumerate(trainloader,<span class="number">0</span>):</span><br><span class="line">        <span class="comment">#获得输入</span></span><br><span class="line">        inputs,labels=data</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度置0</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#forward+backward+optimize</span></span><br><span class="line">        outputs=net(inputs)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#打印统计结果</span></span><br><span class="line">        running_loss+=loss.item()</span><br><span class="line">        <span class="comment">#每2000个为一个小批量，进行打印</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">2000</span>==<span class="number">1999</span>:</span><br><span class="line">            print(<span class="string">'[%d,%5d] loss:%.3f'</span>%(epoch+<span class="number">1</span>,i+<span class="number">1</span>,running_loss/<span class="number">2000</span>))</span><br><span class="line">            running_loss=<span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>[1, 2000] loss:2.112[1, 4000] loss:1.947[1, 6000] loss:1.926[1, 8000] loss:1.899[1,10000] loss:1.930[1,12000] loss:1.905[2, 2000] loss:1.936[2, 4000] loss:1.900[2, 6000] loss:1.932[2, 8000] loss:1.962[2,10000] loss:1.984[2,12000] loss:1.940Finished Training</code></pre><h4 id="在GPU上训练"><a href="#在GPU上训练" class="headerlink" title="在GPU上训练"></a>在GPU上训练</h4><p>你是如何把一个Tensor转换GPU上,你就如何把一个神经网络移动到GPU上训练。这个操作会递归遍历有所模块,并将其参数和缓冲区转换为CUDA张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">print(device)</span><br></pre></td></tr></table></figure><pre><code>cuda:0</code></pre><p>接下来假设我们有一台CUDA的机器，然后这些方法将递归遍历所有模块并将其参数和缓冲区转换为CUDA张量：</p><ul><li>注意优化器我们之前定义过（那是基于没有移动到GPU上的net，所以这里要再定义一次）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net.to(device)</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment">#损失函数标准为交叉熵</span></span><br><span class="line">criterion=nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#动量因子momentum</span></span><br><span class="line">optimizer=optim.SGD(net.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>请记住，你也必须在每一步中把你的输入和目标值转换到GPU上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#epoch很熟悉了，这是数据集训练的轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    </span><br><span class="line">    running_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> enumerate(trainloader,<span class="number">0</span>):</span><br><span class="line">        <span class="comment">#获得输入</span></span><br><span class="line">        inputs,labels=data</span><br><span class="line">        inputs=inputs.to(device)</span><br><span class="line">        labels=labels.to(device)</span><br><span class="line">            </span><br><span class="line">        <span class="comment">#梯度置0</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#forward+backward+optimize</span></span><br><span class="line">        outputs=net(inputs)</span><br><span class="line">        loss=criterion(outputs,labels)</span><br><span class="line">        loss=loss.to(device)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#打印统计结果</span></span><br><span class="line">        running_loss+=loss.item()</span><br><span class="line">        <span class="comment">#每2000个为一个小批量，进行打印</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">2000</span>==<span class="number">1999</span>:</span><br><span class="line">            print(<span class="string">'[%d,%5d] loss:%.3f'</span>%(epoch+<span class="number">1</span>,i+<span class="number">1</span>,running_loss/<span class="number">2000</span>))</span><br><span class="line">            running_loss=<span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>[1, 2000] loss:1.937[1, 4000] loss:1.940[1, 6000] loss:1.943[1, 8000] loss:1.987[1,10000] loss:2.013[1,12000] loss:1.979[2, 2000] loss:1.950[2, 4000] loss:2.005[2, 6000] loss:1.965[2, 8000] loss:1.974[2,10000] loss:1.970[2,12000] loss:1.962Finished Training</code></pre><h4 id="在测试集上测试网络"><a href="#在测试集上测试网络" class="headerlink" title="在测试集上测试网络"></a>在测试集上测试网络</h4><p>我们在整个训练集上训练了两次网络,但是我们还需要检查网络是否从数据集中学习到东西。</p><p>我们通过预测神经网络输出的类别标签并根据实际情况进行检测，如果预测正确,我们把该样本添加到正确预测列表。</p><p>第一步，显示测试集中的图片一遍熟悉图片内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataiter=iter(testloader)</span><br><span class="line">images,labels=dataiter.next()</span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line">print(<span class="string">'GroundTruth:'</span>,<span class="string">' '</span>.join(<span class="string">'%5s'</span>%classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><h4 id="注意：这里网络和数据都要加cuda-，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。"><a href="#注意：这里网络和数据都要加cuda-，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。" class="headerlink" title="注意：这里网络和数据都要加cuda()，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。"></a>注意：这里网络和数据都要加cuda()，因为网络是在GPU上训练的，数据也都是再GPU上跑的，这里不加会报错，教程里没加，是因为他没放到GPU上运行。</h4><p>现在我们来看看神经网络认为以上图片是什么?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net=net.cuda()</span><br><span class="line">images=images.cuda()</span><br><span class="line">outputs = net(images)</span><br></pre></td></tr></table></figure><p>输出是10个标签的概率。一个类别的概率越大,神经网络越认为他是这个类别。所以让我们得到最高概率的标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">_,predicted=torch.max(outputs.data,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Predicted: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[predicted[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><pre><code>Predicted:    cat   dog   dog horse</code></pre><p>接下来让我们看看网络在整个测试集上的结果如何。</p><ul><li>出现错误’weight’相关的，基本上都是没有将数据放在gpu上，在其后加一个.cuda()即可</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images,labels=data</span><br><span class="line">        net=net.cuda()</span><br><span class="line">        labels=labels.cuda()</span><br><span class="line">        images=images.cuda()</span><br><span class="line">        outputs=net(images)</span><br><span class="line">        _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).sum().item()        </span><br><span class="line">print(<span class="string">'Accuracy of the network on the 10000 test images: %d %%'</span> % (<span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the network on the 10000 test images: 26 %</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class_correct = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line">class_total = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        net=net.cuda()</span><br><span class="line">        labels=labels.cuda()</span><br><span class="line">        images=images.cuda()</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">        c = (predicted == labels).squeeze()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            class_correct[label] += c[i].item()</span><br><span class="line">            class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'Accuracy of %5s : %2d %%'</span> % (</span><br><span class="line">        classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;训练一个分类器&quot;&gt;&lt;a href=&quot;#训练一个分类器&quot; class=&quot;headerlink&quot; title=&quot;训练一个分类器&quot;&gt;&lt;/a&gt;训练一个分类器&lt;/h2&gt;&lt;p&gt;在了解了如何定义一个神经网络、计算损失值和更新网络的权重之后，那么数据从哪里来呢？&lt;/p&gt;
&lt;p&gt;关于数据&lt;br&gt;通常，当你处理图像，文本，音频和视频数据时，你可以使用标准的Python包来加载数据到一个numpy数组中.然后把这个数组转换成torch.Tensor。&lt;/p&gt;
    
    </summary>
    
    
      <category term="PyTorch" scheme="https://cblog.club/categories/PyTorch/"/>
    
    
      <category term="PyTorch" scheme="https://cblog.club/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Python之进程和线程</title>
    <link href="https://cblog.club/ck3ecxtqo003fv0g42qsf8h13.html"/>
    <id>https://cblog.club/ck3ecxtqo003fv0g42qsf8h13.html</id>
    <published>2019-11-21T13:24:49.000Z</published>
    <updated>2019-11-21T13:34:41.991Z</updated>
    
    <content type="html"><![CDATA[<p>刚开始学习Python的时候，只是简单的学习了基础的语法和面向对象相关的资料，但是对于进程和线程并没有花时间来看，并且到这一章，和底层实现就密切相关了，和OS更是密不可分，面试非常喜欢问这类的问题，所以还是花点时间来看看，不妨多看看，多找找相关资料，很有帮助，本人是看的廖雪峰的教程，感觉还可以，就是这一章，最好还是在ubuntu环境下跑，因为linux和windows在进程和线程实现细节上有些不同！</p><a id="more"></a><p>很多同学都听说过，现代操作系统比如Mac OS X，UNIX，Linux，Windows等，都是支持“多任务”的操作系统。</p><p>什么叫“多任务”呢？简单地说，就是操作系统可以同时运行多个任务。打个比方，你一边在用浏览器上网，一边在听MP3，一边在用Word赶作业，这就是多任务，至少同时有3个任务正在运行。还有很多任务悄悄地在后台同时运行着，只是桌面上没有显示而已。</p><p>现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是顺序执行的，那么，单核CPU是怎么执行多任务的呢？</p><p>答案就是<strong>操作系统轮流让各个任务交替执行</strong>，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。</p><p>真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。</p><p>对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。</p><p>有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。</p><p>由于每个进程至少要干一件事，所以，一个进程至少有一个线程。当然，像Word这种复杂的进程可以有多个线程，多个线程可以同时执行，多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样。当然，真正地同时执行多线程需要多核CPU才可能实现。</p><p>我们前面编写的所有的Python程序，都是执行单任务的进程，也就是只有一个线程。如果我们要同时执行多个任务怎么办？</p><p>有两种解决方案：</p><ul><li><p>一种是启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。</p></li><li><p>还有一种方法是启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。</p></li><li><p>当然还有第三种方法，就是启动多个进程，每个进程再启动多个线程，这样同时执行的任务就更多了，当然这种模型更复杂，实际很少采用。</p></li></ul><p>总结一下就是，多任务的实现有3种方式：</p><ul><li>多进程模式；</li><li>多线程模式；</li><li>多进程+多线程模式</li></ul><p>同时执行多个任务通常各个任务之间并不是没有关联的，而是需要相互通信和协调，有时，任务1必须暂停等待任务2完成后才能继续执行，有时，任务3和任务4又不能同时执行，所以，多进程和多线程的程序的复杂度要远远高于我们前面写的单进程单线程的程序。</p><p>因为复杂度高，调试困难，所以，不是迫不得已，我们也不想编写多任务。但是，有很多时候，没有多任务还真不行。想想在电脑上看电影，就必须由一个线程播放视频，另一个线程播放音频，否则，单线程实现的话就只能先把视频播放完再播放音频，或者先把音频播放完再播放视频，这显然是不行的。</p><p>Python既支持多进程，又支持多线程，我们会讨论如何编写这两种多任务程序。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>线程是最小的执行单元，而进程由至少一个线程组成。如何调度进程和线程，完全由操作系统决定，程序自己不能决定什么时候执行，执行多长时间。</p><p>多进程和多线程的程序涉及到同步、数据共享的问题，编写起来更复杂。</p><h4 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h4><p>要让Python程序实现多进程（multiprocessing），我们先了解操作系统的相关知识。</p><p>Unix/Linux操作系统提供了一个<code>fork()</code> 系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，<strong>返回两次</strong> ，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。</p><p>子进程永远返回<code>0</code>，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用<code>getppid()</code>就可以拿到父进程的ID。</p><p>Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Process (%s) start...'</span>%os.getpid())</span><br><span class="line">pid=os.fork()</span><br><span class="line"><span class="keyword">if</span> pid == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">'I am child process (%s) and my parent is %s'</span>%(os.getpid(),os.getppid()))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'I (%s) just created a child process (%s)'</span>%(os.getpid(),pid))</span><br></pre></td></tr></table></figure><p>由于Windows没有fork调用，上面的代码在Windows上无法运行。<br>这是我在ubuntu下运行的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Process (96787) start...</span><br><span class="line">I (96787) just created a child process (96788)</span><br><span class="line">I am child process (96788) and my parent is 96787</span><br></pre></td></tr></table></figure><p>有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。</p><h4 id="multiprocessing"><a href="#multiprocessing" class="headerlink" title="multiprocessing"></a>multiprocessing</h4><p>如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？</p><p>由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。</p><p>multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#子进程要做的事情</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_proc</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'Run child process %s (%s)...'</span>%(name,os.getpid()))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'Parent process %s.'</span>%os.getpid())</span><br><span class="line">    p = Process(target=run_proc,args=(<span class="string">'test'</span>,))</span><br><span class="line">    print(<span class="string">'Child process will start.'</span>)</span><br><span class="line">    p.start()</span><br><span class="line">    p.join()</span><br><span class="line">    print(<span class="string">'Child process end.'</span>)</span><br></pre></td></tr></table></figure><pre><code>Parent process 2816.Child process will start.Child process end.</code></pre><p>这是我在ubuntu下运行的结果，不知道windows为什么有问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Parent process 98189.</span><br><span class="line">Child process will start.</span><br><span class="line">Run child process test (98190)...</span><br><span class="line">Child process end.</span><br></pre></td></tr></table></figure><p>创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。</p><p>join()方法可以<strong>等待子进程结束后再继续往下运行</strong> ，通常用于进程间的同步。<br>下面是将<code>p.join()</code>注释掉的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Parent process 98628.</span><br><span class="line">Child process will start.</span><br><span class="line">Child process end.</span><br><span class="line">Run child process test (98629)...</span><br></pre></td></tr></table></figure><h4 id="Pool进程池"><a href="#Pool进程池" class="headerlink" title="Pool进程池"></a>Pool进程池</h4><p>如果要启动大量的子进程，可以用进程池的方式批量创建子进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> os,time,random</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">long_time_rask</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'Run task %s (%s)...'</span> % (name, os.getpid()))</span><br><span class="line">    start=time.time()</span><br><span class="line">    time.sleep(random.random()*<span class="number">3</span>)</span><br><span class="line">    end=time.time()</span><br><span class="line">    print(<span class="string">'Task %s runs %0.2f seconds.'</span> % (name, (end - start)))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'Parent process %s.'</span> % os.getpid())</span><br><span class="line">    p=Pool(<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        p.apply_async(long_time_rask,args=(i,))</span><br><span class="line">    print(<span class="string">'Waiting for all subprocesses done...'</span>)</span><br><span class="line">    p.close()</span><br><span class="line">    p.join()</span><br><span class="line">    print(<span class="string">'All subprocesses done.'</span>)</span><br></pre></td></tr></table></figure><pre><code>Parent process 2816.Waiting for all subprocesses done...</code></pre><p>哎，这一章节真的不能在windows下运行，如上，在windows运行，会卡住，下面是我在ubuntu下运行的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Parent process 99268.</span><br><span class="line">Waiting for all subprocesses done...</span><br><span class="line">Run task 0 (99270)...</span><br><span class="line">Run task 1 (99271)...</span><br><span class="line">Run task 2 (99272)...</span><br><span class="line">Run task 3 (99273)...</span><br><span class="line">Task 0 runs 0.30 seconds.</span><br><span class="line">Run task 4 (99270)...</span><br><span class="line">Task 1 runs 0.37 seconds.</span><br><span class="line">Task 4 runs 0.74 seconds.</span><br><span class="line">Task 2 runs 1.85 seconds.</span><br><span class="line">Task 3 runs 2.58 seconds.</span><br><span class="line">All subprocesses done.</span><br></pre></td></tr></table></figure><p>对Pool对象调用join()方法会等待所有子进程执行完毕，<strong>调用join()之前必须先调用close()</strong> ，调用close()之后就不能继续添加新的Process了。</p><p>请注意输出的结果，task 0，1，2，3是立刻执行的（也就是说同一时刻，这四个进程是同时进行的），而task 4要等待前面某个task完成后才执行（因为前边有四个进程在执行，而我们设定的同时能运行的进程数4，所以只能等待），这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成：<br><code>p = Pool(5)</code>，就可以同时跑5个进程。<br>由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。</p><h4 id="子进程"><a href="#子进程" class="headerlink" title="子进程"></a>子进程</h4><p>很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。</p><p>subprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。</p><p>下面的例子演示了如何在Python代码中运行命令 <code>nslookup www.python.org</code>，这和命令行直接运行的效果是一样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="comment">#nslookup命令用于查询DNS的记录，查看域名解析是否正常，在网络故障的时候用来诊断网络问题</span></span><br><span class="line">print(<span class="string">'$ nslookup www.python.org'</span>)</span><br><span class="line">r=subprocess.call([<span class="string">'nslookup'</span>,<span class="string">'www.python.org'</span>])</span><br><span class="line">print(<span class="string">'exit code:'</span>,r)</span><br></pre></td></tr></table></figure><pre><code>$ nslookup www.python.orgexit code: 0</code></pre><p>这是我在Ubuntu下运行的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup www.python.org</span><br><span class="line">Server:         202.204.48.8</span><br><span class="line">Address:        202.204.48.8#53</span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">www.python.org  canonical name = dualstack.python.map.fastly.net.</span><br><span class="line">Name:   dualstack.python.map.fastly.net</span><br><span class="line">Address: 151.101.24.223</span><br><span class="line"></span><br><span class="line">exit code:</span><br></pre></td></tr></table></figure><p>如果子进程还需要输入，则可以通过communicate()方法输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'$ nslookup'</span>)</span><br><span class="line">p = subprocess.Popen([<span class="string">'nslookup'</span>], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class="line">output,err=p.communicate(<span class="string">b'set q=mx\npython.org\nexit\n'</span>)</span><br><span class="line">print(output.decode(<span class="string">'utf-8'</span>))</span><br><span class="line">print(<span class="string">'exit code:'</span>,p.returncode)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup</span><br><span class="line">Server:         202.204.48.8</span><br><span class="line">Address:        202.204.48.8#53</span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">python.org      mail exchanger = 50 mail.python.org.</span><br><span class="line"></span><br><span class="line">Authoritative answers can be found from:</span><br><span class="line">mail.python.org internet address = 188.166.95.178</span><br><span class="line">mail.python.org has AAAA address 2a03:b0c0:2:d0::71:1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">exit code: 0</span><br></pre></td></tr></table></figure><h3 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h3><p>Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的<code>multiprocessing</code>模块包装了底层的机制，提供了<code>Queue</code>、<code>Pipes</code>等多种方式来交换数据。</p><p>我们以<code>Queue</code>为例，在父进程中创建两个子进程，一个往<code>Queue</code>里写数据，一个从<code>Queue</code>里读数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#写数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(q)</span>:</span></span><br><span class="line">    print(<span class="string">'Process to write: %s'</span> % os.getpid())</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> [<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'D'</span>]:</span><br><span class="line">        print(<span class="string">'Put %s to queue...'</span> % value)</span><br><span class="line">        q.put(value)</span><br><span class="line">        <span class="comment">#有了这一步，有了一定的时间间隔，那么在这个过程中，也是可以读的，如果注释掉，那么ABCD一股脑全部写入</span></span><br><span class="line">        time.sleep(random.random())</span><br><span class="line"></span><br><span class="line"><span class="comment">#读数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(q)</span>:</span></span><br><span class="line">    print(<span class="string">'Process to read: %s '</span> % os.getpid())</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        value=q.get(<span class="literal">True</span>)</span><br><span class="line">        print(<span class="string">'Get %s from queue.'</span> % value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#父进程创建Queue，并传给各个子进程</span></span><br><span class="line">    q=Queue()</span><br><span class="line">    pw=Process(target=write,args=(q,))</span><br><span class="line">    pr=Process(target=read,args=(q,))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#启动子进程pw，写入数据：</span></span><br><span class="line">    pw.start()</span><br><span class="line">    <span class="comment">#启动子进程pr，读出数据：</span></span><br><span class="line">    pr.start()</span><br><span class="line">    <span class="comment">#等待pw结束</span></span><br><span class="line">    pw.join()</span><br><span class="line">    <span class="comment">#pr进程里是死循环，无法等待其结束，只能强行终止：</span></span><br><span class="line">    pr.terminate()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Process to write: 99800</span><br><span class="line">Put A to queue...</span><br><span class="line">Process to read: 99801 </span><br><span class="line">Get A from queue.</span><br><span class="line">Put B to queue...</span><br><span class="line">Get B from queue.</span><br><span class="line">Put C to queue...</span><br><span class="line">Get C from queue.</span><br><span class="line">Put D to queue...</span><br><span class="line">Get D from queue.</span><br></pre></td></tr></table></figure><p>在Unix/Linux下，<code>multiprocessing</code>模块封装了<code>fork()</code>调用，使我们不需要关注<code>fork()</code>的细节。由于Windows没有<code>fork</code>调用，因此，<code>multiprocessing</code>需要“模拟”出fork的效果，父进程所有Python对象都必须通过<code>pickle</code>序列化再传到子进程去，所以，如果<code>multiprocessing</code>在Windows下调用失败了，要先考虑是不是pickle失败了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;刚开始学习Python的时候，只是简单的学习了基础的语法和面向对象相关的资料，但是对于进程和线程并没有花时间来看，并且到这一章，和底层实现就密切相关了，和OS更是密不可分，面试非常喜欢问这类的问题，所以还是花点时间来看看，不妨多看看，多找找相关资料，很有帮助，本人是看的廖雪峰的教程，感觉还可以，就是这一章，最好还是在ubuntu环境下跑，因为linux和windows在进程和线程实现细节上有些不同！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://cblog.club/categories/Python/"/>
    
      <category term="OS" scheme="https://cblog.club/categories/Python/OS/"/>
    
    
      <category term="OS" scheme="https://cblog.club/tags/OS/"/>
    
      <category term="python" scheme="https://cblog.club/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Django项目的自动化测试</title>
    <link href="https://cblog.club/ck3ecxtq2002jv0g47xz85x9e.html"/>
    <id>https://cblog.club/ck3ecxtq2002jv0g47xz85x9e.html</id>
    <published>2019-11-21T06:13:00.000Z</published>
    <updated>2019-11-25T01:45:31.218Z</updated>
    
    <content type="html"><![CDATA[<p>最近，实验室有个小项目，关于企业上云，然后我们这边要做一个Django的web(已经做了很多功能，需要添加和修改一些功能)，所以要给项目添加一些测试，以备后期更改，自动化测试看的是Django 的官方文档。网址是： <a href="https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/" target="_blank" rel="noopener">https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/</a> 。</p><a id="more"></a><h3 id="自动化测试简介"><a href="#自动化测试简介" class="headerlink" title="自动化测试简介"></a>自动化测试简介</h3><h4 id="自动化测试是什么"><a href="#自动化测试是什么" class="headerlink" title="自动化测试是什么"></a>自动化测试是什么</h4><p>测试，是用来检查代码正确性的一些简单的程序。</p><p>测试在不同的层次中都存在。有些测试只关注某个很小的细节（某个模型的某个方法的返回值是否满足预期？），而另一些测试可能检查对某个软件的一系列操作（<em>某一用户输入序列是否造成了预期的结果？</em>）。其实这和我们在 <a href="https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial02/" target="_blank" rel="noopener">教程第 2 部分</a>，里做的并没有什么不同，我们使用 <a href="https://docs.djangoproject.com/zh-hans/2.2/ref/django-admin/#django-admin-shell" target="_blank" rel="noopener"><code>shell</code></a> 来测试某一方法的功能，或者运行某个应用并输入数据来检查它的行为。</p><p>真正不同的地方在于，<em>自动化</em> 测试是由某个系统帮你自动完成的。当你创建好了一系列测试，每次修改应用代码后，就可以自动检查出修改后的代码是否还像你曾经预期的那样正常工作。你不需要花费大量时间来进行手动测试。</p><h4 id="为什么你需要写测试？"><a href="#为什么你需要写测试？" class="headerlink" title="为什么你需要写测试？"></a>为什么你需要写测试？</h4><p>但是，为什么需要测试呢？又为什么是现在呢？</p><p>你可能觉得学 Python/Django 对你来说已经很满足了，再学一些新东西的话看起来有点负担过重并且没什么必要。毕竟，我们的投票应用（官方文档的一个项目举例）看起来已经完美工作了。写一些自动测试并不能让它工作的更好。如果写一个投票应用是你想用 Django 完成的唯一工作，那你确实没必要学写测试。<strong>但是如果你还想写更复杂的项目，现在就是学习测试写法的最好时机了。</strong></p><ul><li><p>测试将节约你的时间</p><p>在某种程度上，能够「判断出代码是否正常工作」的测试，就称得上是个令人满意的了。在更复杂的应用程序中，组件之间可能会有数十个复杂的交互。</p><p>在更加复杂的应用中，各种组件之间的交互可能会及其的复杂。改变其中某一组件的行为，也有可能会造成意想不到的结果。判断「代码是否正常工作」意味着你需要用大量的数据来完整的测试全部代码的功能，以确保你的小修改没有对应用整体造成破坏——这太费时间了。</p><p>尤其是当你发现自动化测试能在几秒钟之内帮你完成这件事时，就更会觉得手动测试实在是太浪费时间了。当某人写出错误的代码时，自动化测试还能帮助你定位错误代码的位置。</p><p>有时候你会觉得，和富有创造性和生产力的业务代码比起来，编写枯燥的测试代码实在是太无聊了，特别是当你知道你的代码完全没有问题的时候。</p><p><strong>然而，编写测试还是要比花费几个小时手动测试你的应用，或者为了找到某个小错误而胡乱翻看代码要有意义的多。</strong></p></li><li><p>测试不仅能发现错误，还能预防错误</p><p>「测试是开发的对立面」，这种思想是不对的。</p><p>如果没有测试，整个应用的行为意图会变得更加的不清晰。甚至当你在看自己写的代码时也是这样，有时候你需要仔细研读一段代码才能搞清楚它有什么用。</p><p>而测试的出现改变了这种情况。测试就好像是从内部仔细检查你的代码，当有些地方出错时，这些地方将会变得很显眼——<em>就算你自己没有意识到那里写错了</em>。</p></li><li><p>测试使你的代码更有吸引力</p><p>你也许遇到过这种情况：你编写了一个绝赞的软件，但是其他开发者看都不看它一眼，因为它缺少测试。<strong>没有测试的代码不值得信任。</strong> Django 最初开发者之一的 Jacob Kaplan-Moss 说过：“项目规划时没有包含测试是不科学的。”</p><p>其他的开发者希望在正式使用你的代码前看到它通过了测试，这是你需要写测试的另一个重要原因。</p></li><li><p>测试有助于团队协作</p><p>前面的几点都是从单人开发的角度来说的。复杂的应用可能由团队维护。测试的存在保证了协作者不会不小心破坏了了你的代码（也保证你不会不小心弄坏他们的）。如果你想作为一个 Django 程序员谋生的话，你必须擅长编写测试！ </p></li></ul><h4 id="基础测试策略"><a href="#基础测试策略" class="headerlink" title="基础测试策略"></a>基础测试策略</h4><p>有好几种不同的方法可以写测试。</p><p>一些开发者遵循 “<a href="https://en.wikipedia.org/wiki/Test-driven_development" target="_blank" rel="noopener">测试驱动</a>“ 的开发原则，他们在写代码之前先写测试。这种方法看起来有点反直觉，但事实上，这和大多数人日常的做法是相吻合的。我们会先描述一个问题，然后写代码来解决它。「测试驱动」的开发方法只是将问题的描述抽象为了 Python 的测试样例。</p><p>更普遍的情况是，一个刚接触自动化测试的新手更倾向于先写代码，然后再写测试。虽然提前写测试可能更好，但是晚点写起码也比没有强。</p><p>有时候很难决定从哪里开始下手写测试。如果你才写了几千行 Python 代码，选择从哪里开始写测试确实不怎么简单。如果是这种情况，那么在你下次修改代码（比如加新功能，或者修复 Bug）之前写个测试是比较合理且有效的。</p><h4 id="Django中的测试"><a href="#Django中的测试" class="headerlink" title="Django中的测试"></a>Django中的测试</h4><p>随着网站的增长，他们越来越难以手动测试。不仅要进行更多的测试，而且随着组件之间的交互变得越来越复杂，一个区域的小改变可能会影响到其他区域，所以需要做更多的改变来确保一切正常运行，并且在进行更多更改时不会引入错误。减轻这些问题的一种方法是编写自动化测试，每当您进行更改时，都可以轻松可靠地运行测试。</p><p>测试一个 Web 应用是一项复杂的工作，因为 Web 应用包含了多层业务逻辑——从 HTTP 层响应请求，到表单有效性检测和处理，再到模板渲染。利用 Django 的测试执行框架和配套的工具，你可以模拟其你去，插入测试数据，检查应用的输出，以此检验你的代码是否按照期望运行。</p><p>最大的优点是，它非常简单。</p><p>此外，自动化测试可以充当代码的第一个真实“用户”，迫使您严格定义和记录网站的行为方式。它们通常是您的代码示例，和文档的基础。由于这些原因，一些软件开发过程，从测试定义和实现开始，之后编写代码以匹配所需的行为（例如，测试驱动<a href="https://en.wikipedia.org/wiki/Test-driven_development" target="_blank" rel="noopener">test-driven</a> 和行为驱动 <a href="https://en.wikipedia.org/wiki/Behavior-driven_development" target="_blank" rel="noopener">behaviour-driven</a>的开发）。 </p><h4 id="测试的类型"><a href="#测试的类型" class="headerlink" title="测试的类型"></a>测试的类型</h4><ul><li>单元测试<ul><li>验证各个组件的功能行为，通常是类别和功能级别 </li></ul></li><li>回归测试<ul><li>测试重现历史错误。最初运行每个测试，以验证错误是否已修复，然后重新运行，以确保在以后更改代码之后，未重新引入该错误。 （有点像测试后发现错误，然后修改错误，再进行测试的意思）</li></ul></li><li>集成测试<ul><li>验证组件分组在一起使用时的工作方式。集成测试了解组件之间所需的交互，但不一定了解每个组件的内部操作。它们可能涵盖整个网站的简单组件分组。 （这就有点像全部来一次测试，验证各个组件之间是否能够正常运行）</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，实验室有个小项目，关于企业上云，然后我们这边要做一个Django的web(已经做了很多功能，需要添加和修改一些功能)，所以要给项目添加一些测试，以备后期更改，自动化测试看的是Django 的官方文档。网址是： &lt;a href=&quot;https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.djangoproject.com/zh-hans/2.2/intro/tutorial05/&lt;/a&gt; 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Django" scheme="https://cblog.club/categories/Django/"/>
    
      <category term="自动化测试" scheme="https://cblog.club/categories/Django/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="Django" scheme="https://cblog.club/tags/Django/"/>
    
      <category term="自动化测试" scheme="https://cblog.club/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>279完全平方数</title>
    <link href="https://cblog.club/ck3ecxtnm000av0g4ho5v24t1.html"/>
    <id>https://cblog.club/ck3ecxtnm000av0g4ho5v24t1.html</id>
    <published>2019-11-21T03:36:38.000Z</published>
    <updated>2019-11-21T05:48:41.449Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定正整数 <em>n</em>，找到若干个完全平方数（比如 <code>1, 4, 9, 16, ...</code>）使得它们的和等于 <em>n</em>。你需要让组成和的完全平方数的个数最少。 </p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: n = <span class="number">12</span></span><br><span class="line">输出: <span class="number">3</span> </span><br><span class="line">解释: <span class="number">12</span> = <span class="number">4</span> + <span class="number">4</span> + <span class="number">4.</span></span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: n = <span class="number">13</span></span><br><span class="line">输出: <span class="number">2</span></span><br><span class="line">解释: <span class="number">13</span> = <span class="number">4</span> + <span class="number">9.</span></span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。"><a href="#解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。" class="headerlink" title="解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。"></a>解题思路：本题思考了一会，在想怎么使用DP呢？然后灵光一现，这不就是兑换零钱的变种吗，只不过零钱的面额在这一题中，不再是固定的了，比如12，那么对应的“面额”就应该是1，4，9，这些完全平方数，以此类推，第一次的代码，我是将这些“面额”循环插入到一个数组中了（其实没必要，可以合并，进行代码优化），其他的思想和兑换零钱一样。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numSquares</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(n+<span class="number">1</span>,n);</span><br><span class="line">        dp[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;=n;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j*j&lt;=n;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> cur=j*j;</span><br><span class="line">                <span class="keyword">if</span>(i&lt;cur)<span class="keyword">break</span>;</span><br><span class="line">                dp[i]=min(<span class="number">1</span>+dp[i-cur],dp[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定正整数 &lt;em&gt;n&lt;/em&gt;，找到若干个完全平方数（比如 &lt;code&gt;1, 4, 9, 16, ...&lt;/code&gt;）使得它们的和等于 &lt;em&gt;n&lt;/em&gt;。你需要让组成和的完全平方数的个数最少。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>152乘积最大子序列</title>
    <link href="https://cblog.club/ck3ecxtn40005v0g4d7tnae0l.html"/>
    <id>https://cblog.club/ck3ecxtn40005v0g4d7tnae0l.html</id>
    <published>2019-11-21T03:30:32.000Z</published>
    <updated>2019-11-21T03:35:40.032Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个整数数组 <code>nums</code> ，找出一个序列中乘积最大的连续子序列（该序列至少包含一个数）。 </p><a id="more"></a><blockquote><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">2</span>,<span class="number">3</span>,<span class="number">-2</span>,<span class="number">4</span>]</span><br><span class="line">输出: <span class="number">6</span></span><br><span class="line">解释: 子数组 [<span class="number">2</span>,<span class="number">3</span>] 有最大乘积 <span class="number">6</span>。</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">-2</span>,<span class="number">0</span>,<span class="number">-1</span>]</span><br><span class="line">输出: <span class="number">0</span></span><br><span class="line">解释: 结果不能为 <span class="number">2</span>, 因为 [<span class="number">-2</span>,<span class="number">-1</span>] 不是子数组。</span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp-i-代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。"><a href="#解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp-i-代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。" class="headerlink" title="解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp[i]代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。"></a>解题思路：刚开始，我觉得非常简单，是一道特别基础的DP题目，但是后来提交的时候才发现，欠考虑了，dp[i]代表以当前节点为终止结点的最大连乘值，但是这一题特别就特别在他有负的值，所以我们不能只保存最大的连乘值，我们还要保存最小的连乘值，然后取前一个最大连乘值的时候就要注意，如果当前节点是负数，那我就要去最小的连乘值了，所以采用两个dp，一个存最大，一个存最小，（最大的来源要有最小这个因素）最后去取最大即可。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxProduct</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">int</span> mul_pre,mul_pre2,res,max_temp,min_temp;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp2(size);</span><br><span class="line">        dp[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        dp2[<span class="number">0</span>]=nums[<span class="number">0</span>];</span><br><span class="line">        res=dp[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;size;i++)&#123;</span><br><span class="line">            mul_pre=nums[i]*dp[i<span class="number">-1</span>];</span><br><span class="line">            mul_pre2=nums[i]*dp2[i<span class="number">-1</span>];</span><br><span class="line">            max_temp=max(mul_pre,mul_pre2);</span><br><span class="line">            dp[i]=max(max_temp,nums[i]);</span><br><span class="line">            min_temp=min(mul_pre,mul_pre2);</span><br><span class="line">            dp2[i]=min(min_temp,nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(res&lt;dp[i])res=dp[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个整数数组 &lt;code&gt;nums&lt;/code&gt; ，找出一个序列中乘积最大的连续子序列（该序列至少包含一个数）。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>Python回顾之OOP</title>
    <link href="https://cblog.club/ck3ecxtqq003iv0g490aab9xv.html"/>
    <id>https://cblog.club/ck3ecxtqq003iv0g490aab9xv.html</id>
    <published>2019-11-20T14:27:36.000Z</published>
    <updated>2019-11-20T14:28:47.456Z</updated>
    
    <content type="html"><![CDATA[<h3 id="面向对象的两个基本概念"><a href="#面向对象的两个基本概念" class="headerlink" title="面向对象的两个基本概念"></a>面向对象的两个基本概念</h3><p>编程语言中，一般有两种编程思维，面向过程和面向对象。</p><p>面向过程，看重的是解决问题的过程。</p><p>这好比我们解决日常生活问题差不多，分析解决问题的步骤，然后一步一步的解决。</p><p>而面向对象是一种抽象，抽象是指用分类的眼光去看世界的一种方法。</p><a id="more"></a><p>Python 就是一门面向对象的语言,</p><p>如果你学过 Java ，就知道 Java 的编程思想就是：万事万物皆对象。Python 也不例外，在解决实际问题的过程中，可以把构成问题事务分解成各个对象。</p><p>面向对象都有两个基本的概率，分别是类和对象。</p><ul><li><p>类<br>用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。</p></li><li><p>对象<br>通过类定义的数据结构实例</p></li></ul><h3 id="面向对象的三大特性"><a href="#面向对象的三大特性" class="headerlink" title="面向对象的三大特性"></a>面向对象的三大特性</h3><p>面向对象的编程语言，也有三大特性，继承，多态和封装性。</p><ul><li><p>继承<br>即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如：一个 Dog 类型的对象派生自 Animal 类，这是模拟”是一个（is-a）”关系（例图，Dog 是一个 Animal ）。</p></li><li><p>多态<br>它是指对不同类型的变量进行相同的操作，它会根据对象（或类）类型的不同而表现出不同的行为。</p></li><li><p>封装性<br>“封装”就是将抽象得到的数据和行为（或功能）相结合，形成一个有机的整体（即类）；封装的目的是增强安全性和简化编程，使用者不必了解具体的实现细节，而只是要通过外部接口，一特定的访问权限来使用类的成员。</p></li></ul><h4 id="类方法如何调用类属性"><a href="#类方法如何调用类属性" class="headerlink" title="类方法如何调用类属性"></a>类方法如何调用类属性</h4><p>如果没有声明是类方法，方法参数中就没有 cls , 就没法通过 cls 获取到类属性。</p><p>因此类方法，想要调用类属性，需要以下步骤：</p><ul><li>在方法上面，用 @classmethon 声明该方法是类方法。只有声明了是类方法，才能使用类属性</li><li>类方法想要使用类属性，在第一个参数中，需要写上 cls , cls 是 class 的缩写，其实意思就是把这个类作为参数，传给自己，这样就可以使用类属性了。</li><li>类属性的使用方式就是 cls.变量名</li></ul><p>记住，无论是 @classmethon 还是 cls ,都是不能省去的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"name is "</span>+cls.name)</span><br><span class="line"></span><br><span class="line">Person.get_name()</span><br></pre></td></tr></table></figure><pre><code>name is lc</code></pre><h4 id="类方法传参"><a href="#类方法传参" class="headerlink" title="类方法传参"></a>类方法传参</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"name is "</span>+cls.name+str)</span><br><span class="line"></span><br><span class="line">Person.get_name(<span class="string">"1998"</span>)</span><br></pre></td></tr></table></figure><pre><code>name is lc1998</code></pre><h4 id="修改和增加类属性"><a href="#修改和增加类属性" class="headerlink" title="修改和增加类属性"></a>修改和增加类属性</h4><ul><li>从内部增加和修改类属性</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">Person.rename_customize(<span class="string">"lemon"</span>)</span><br></pre></td></tr></table></figure><pre><code>original name is lccurrent name is lemon</code></pre><ul><li>从外部增加和修改类属性</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lc=Person()</span><br><span class="line">print(lc.name)</span><br><span class="line">lc.name=<span class="string">"lc"</span></span><br><span class="line">print(lc.name)</span><br></pre></td></tr></table></figure><pre><code>12lc</code></pre><h3 id="对象的实例化"><a href="#对象的实例化" class="headerlink" title="对象的实例化"></a>对象的实例化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#属性</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"age is "</span>+str(self.age))</span><br><span class="line"></span><br><span class="line">lc=Person()</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 18</code></pre><p>只不过使用 cls 和 self 是我们的编程习惯，这也是我们的编程规范。</p><p>因为 cls 是 class 的缩写，代表这类 ， 而 self 代表这对象的意思。</p><p>所以啊，这里我们实例化对象的时候，就使用 self 。</p><p>而且 self 是所有类方法位于首位、默认的特殊参数。</p><p>除此之外，在这里，还要强调一个概念，当你把类实例化之后，里面的属性和方法，就不叫类属性和类方法了，改为叫实例</p><p>属性和实例方法，也可以叫对象属性和对象方法。</p><h4 id="实例属性和类属性"><a href="#实例属性和类属性" class="headerlink" title="实例属性和类属性"></a>实例属性和类属性</h4><ul><li>发现类属性改变了，实例属性也会改变，因为我们的实例对象就是根据类来复制出来的，类属性改变了，实例对象的属性也会跟着改变。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lemon=Person()</span><br><span class="line">Person.age=<span class="number">19</span></span><br><span class="line">lemon.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 19</code></pre><ul><li>当我们修改实例对象的属性是，类属性是不会改变的,因为每个实例都是单独的个体，不能影响到类的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lemon=Person()</span><br><span class="line">print(Person.age)</span><br><span class="line">lemon.age=<span class="number">19</span></span><br><span class="line">print(Person.age)</span><br></pre></td></tr></table></figure><pre><code>1818</code></pre><h4 id="实例方法和类方法"><a href="#实例方法和类方法" class="headerlink" title="实例方法和类方法"></a>实例方法和类方法</h4><ul><li>如果类方法改变了，实例方法会不会跟着改变呢？答案是肯定</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#属性</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"age is "</span>+str(self.age))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lc=Person()</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 18</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">    print(<span class="string">"age + 1 is "</span>+str(self.age+<span class="number">1</span>))</span><br><span class="line">Person.get_age=new_get_age</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age + 1 is 19</code></pre><p>在这个例子中，我们需要改变类方法，就用到了<strong>类的重写</strong>。</p><p>我们使用了 类.原始函数 = 新函数 就完成类的重写。</p><h4 id="要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是-类-原始函数-新函数-这个写法是不对的。"><a href="#要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是-类-原始函数-新函数-这个写法是不对的。" class="headerlink" title="要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是 类.原始函数() = 新函数() 这个写法是不对的。"></a>要注意的是，这里的赋值是在替换方法，并不是调用函数。所以是不能加上括号的，也就是 类.原始函数() = 新函数() 这个写法是不对的。</h4><ul><li>那么如果实例方法改变了，类方法会改变吗？答案是肯定不会的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#属性</span></span><br><span class="line">    name=<span class="string">"lc"</span></span><br><span class="line">    age=<span class="number">18</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=input(<span class="string">'please input your name:'</span>)</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rename_customize</span><span class="params">(cls,str)</span>:</span></span><br><span class="line">        print(<span class="string">"original name is "</span>+cls.name)</span><br><span class="line">        cls.name=str</span><br><span class="line">        print(<span class="string">"current name is "</span>+cls.name)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_age</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"age is "</span>+str(self.age))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(self,str)</span>:</span></span><br><span class="line">        print(<span class="string">"name is "</span>+str)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lc=Person()</span><br><span class="line">lc.get_age()</span><br></pre></td></tr></table></figure><pre><code>age is 18</code></pre><h4 id="我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）"><a href="#我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）" class="headerlink" title="我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）"></a>我们发现也能改写（但是教程上说不可以，它出错的原因是缺少参数self）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_get_name</span><span class="params">(str)</span>:</span></span><br><span class="line">        print(<span class="string">"your name is "</span>+str)</span><br><span class="line">lc.get_name=new_get_name</span><br><span class="line">lc.get_name(<span class="string">"leocode"</span>)</span><br></pre></td></tr></table></figure><pre><code>your name is leocode</code></pre><h4 id="修改实例方法，只对于这一个实例起作用"><a href="#修改实例方法，只对于这一个实例起作用" class="headerlink" title="修改实例方法，只对于这一个实例起作用"></a>修改实例方法，只对于这一个实例起作用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leo=Person()</span><br><span class="line">leo.get_name(<span class="string">"lc"</span>)</span><br></pre></td></tr></table></figure><pre><code>name is lc</code></pre><h3 id="初始化函数（也就是构造函数）"><a href="#初始化函数（也就是构造函数）" class="headerlink" title="初始化函数（也就是构造函数）"></a>初始化函数（也就是构造函数）</h3><ul><li>初始化函数的意思是，当你创建一个实例的时候，这个函数就会被调用。</li><li>当代码在执行 dog=Animals() 的语句时，就自动调用了 _<em>init_</em>(self) 函数。</li><li>而这个 _<em>init_</em>(self) 函数就是初始化函数，也叫构造函数</li><li>构造函数格式：<code>def __init__(self,[参数1，参数2...]):</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"初始化成功！"</span>)</span><br><span class="line">        </span><br><span class="line">dog=Animals()</span><br></pre></td></tr></table></figure><pre><code>初始化成功！</code></pre><h4 id="构造函数也可以传递参数"><a href="#构造函数也可以传递参数" class="headerlink" title="构造函数也可以传递参数"></a>构造函数也可以传递参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,str)</span>:</span></span><br><span class="line">        print(<span class="string">"初始化成功！"</span>+str)</span><br><span class="line">        </span><br><span class="line">dog=Animals(<span class="string">"leocode"</span>)</span><br></pre></td></tr></table></figure><pre><code>初始化成功！leocode</code></pre><h3 id="析构函数（用于销毁实例）"><a href="#析构函数（用于销毁实例）" class="headerlink" title="析构函数（用于销毁实例）"></a>析构函数（用于销毁实例）</h3><ul><li>一个在创建的时候，会调用构造函数，那么理所当然，这个当一个类销毁的时候，就会调用析构函数</li><li>格式：<code>def __del__(self,[参数1，参数2...]):</code></li><li>使用del调用析构函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#初始化函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,str)</span>:</span></span><br><span class="line">        print(<span class="string">"初始化成功！"</span>+str)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__del__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"实例已销毁"</span>)</span><br><span class="line">        </span><br><span class="line">dog=Animals(<span class="string">"leocode"</span>)</span><br><span class="line"><span class="keyword">del</span> dog</span><br></pre></td></tr></table></figure><pre><code>初始化成功！leocode实例已销毁</code></pre><h3 id="类的继承"><a href="#类的继承" class="headerlink" title="类的继承"></a>类的继承</h3><ul><li>定义类的继承</li></ul><p>说到继承，你一定会联想到继承你老爸的家产之类的。</p><p>类的继承也是一样。</p><p>比如有一个旧类，是可以算平均数的。然后这时候有一个新类，也要用到算平均数，那么这时候我们就可以使用继承的方式。新类继承旧类，这样子新类也就有这个功能了。</p><p>通常情况下，我们叫旧类为父类，新类为子类。</p><p>在定义类的时候，可以在括号里写继承的类，如果不用继承类的时候，也要写继承 object 类（也可以不写），因为在 Python 中 object 类是一切类的父类。</p><p>当然上面的是单继承，Python 也是支持多继承的，具体的语法如下：</p><p>多继承有一点需要注意的：若是父类中有相同的方法名，而在子类使用时未指定，python 在圆括号中父类的顺序，从左至右搜索 ， 即方法在子类中未找到时，从左到右查找父类中是否包含方法。</p><p>那么继承的子类可以干什么呢？</p><p>继承的子类的好处：</p><ul><li>会继承父类的属性和方法</li><li>可以自己定义，覆盖父类的属性和方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animals</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,kind,name)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self.kind=kind</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"its name is "</span>+self.name)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eat</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.kind+<span class="string">"在吃东西"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(Animals)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,kind,name,age)</span>:</span></span><br><span class="line">        super(Dog,self).__init__(kind,name)</span><br><span class="line">        self.age=age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eat</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.kind+<span class="string">"在吃东西,并且它"</span>+str(self.age)+<span class="string">"岁了"</span>)</span><br><span class="line">dog_a=Dog(<span class="string">"dog"</span>,<span class="string">"dz"</span>,<span class="number">2</span>)</span><br><span class="line">dog_a.get_name()</span><br><span class="line">dog_a.eat()</span><br></pre></td></tr></table></figure><pre><code>its name is dzdog在吃东西,并且它2岁了</code></pre><h4 id="子类的类型判断"><a href="#子类的类型判断" class="headerlink" title="子类的类型判断"></a>子类的类型判断</h4><p>对于 class 的继承关系来说，有些时候我们需要判断 class 的类型，该怎么办呢？</p><p>可以使用 isinstance() 函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span><span class="params">(User1)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User3</span><span class="params">(User2)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">user1=User1()</span><br><span class="line">user2=User2()</span><br><span class="line">user3=User3()</span><br><span class="line"></span><br><span class="line">print(isinstance(user1,User1))</span><br><span class="line">print(isinstance(user2,User1))</span><br><span class="line">print(isinstance(user3,User2))</span><br><span class="line">print(isinstance(<span class="number">1321</span>,str))</span><br><span class="line">print(isinstance(<span class="number">1321</span>,int))</span><br><span class="line">print(type(user1))</span><br></pre></td></tr></table></figure><pre><code>TrueTrueTrueFalseTrue&lt;class &apos;__main__.User1&apos;&gt;</code></pre><ul><li>可以看到 isinstance() 不仅可以告诉我们，一个对象是否是某种类型，也可以用于基本类型的判断</li></ul><h3 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h3><p>多态的概念其实不难理解，它是指对不同类型的变量进行相同的操作，它会根据对象（或类）类型的不同而表现出不同的行为。</p><p>事实上，我们经常用到多态的性质，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;1 + 2</span><br><span class="line">3</span><br><span class="line">&gt;&gt;&gt;&apos;a&apos; + &apos;b&apos;</span><br><span class="line">&apos;ab&apos;</span><br></pre></td></tr></table></figure><p>可以看到，我们对两个整数进行 + 操作，会返回它们的和，对两个字符进行相同的 + 操作，会返回拼接后的字符串。</p><p>也就是说，不同类型的对象对同一消息会作出不同的响应。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,age)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self.age=age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.name+<span class="string">"在工作！他现在"</span>+str(self.age)+<span class="string">"岁！"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,age)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self.age=age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">work</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"他现在"</span>+str(self.age)+<span class="string">"岁！"</span>+self.name+<span class="string">"在工作！"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inter_work</span><span class="params">(user)</span>:</span></span><br><span class="line">    user.work()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lc=User1(<span class="string">"lc"</span>,<span class="number">22</span>)</span><br><span class="line">lemon=User2(<span class="string">"lemon"</span>,<span class="number">21</span>)</span><br><span class="line">inter_work(lc)</span><br><span class="line">inter_work(lemon)</span><br></pre></td></tr></table></figure><pre><code>lc在工作！他现在22岁！他现在21岁！lemon在工作！</code></pre><p>可以看到，lc 和 lemon 是两个不同的对象，对它们调用 inter_work 方法，它们会自动调用实际类型的 work 方法，作出不同的响应。这就是多态的魅力。</p><p>要注意喔，有了继承，才有了多态，也会有不同类的对象对同一消息会作出不同的相应。</p><h3 id="类的访问控制"><a href="#类的访问控制" class="headerlink" title="类的访问控制"></a>类的访问控制</h3><ul><li>类属性的访问控制<br>在 Java 中，有 public （公共）属性 和 private （私有）属性，这可以对属性进行访问控制。</li></ul><p>那么在 Python 中有没有属性的访问控制呢？</p><p>一般情况下，我们会使用 __private_attrs 两个下划线开头，声明该属性为私有，不能在类地外部被使用或直接访问。在类内部的方法中使用时 self.__private_attrs。</p><p>为什么只能说一般情况下呢？</p><p>因为实际上， Python 中是没有提供私有属性等功能的。</p><p>但是 Python 对属性的访问控制是靠程序员自觉的。为什么这么说呢？</p><p>看看下面的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserInfo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,age,account)</span>:</span></span><br><span class="line">        self.name=name</span><br><span class="line">        self._age=age</span><br><span class="line">        self.__account=account</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_account</span><span class="params">(self)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> self.__account</span><br><span class="line">        </span><br><span class="line">userInfo=UserInfo(<span class="string">"leocode"</span>,<span class="number">21</span>,<span class="number">199831</span>)</span><br><span class="line"><span class="comment">#输出所有属性</span></span><br><span class="line">print(dir(userInfo))</span><br><span class="line"><span class="comment">#输出构造函数中的属性</span></span><br><span class="line">print(userInfo.__dict__)</span><br><span class="line"><span class="comment">#用于验证双下划线是否是真正的私有属性</span></span><br><span class="line">print(userInfo._UserInfo__account)</span><br><span class="line">print(userInfo._age)</span><br></pre></td></tr></table></figure><pre><code>[&apos;_UserInfo__account&apos;, &apos;__class__&apos;, &apos;__delattr__&apos;, &apos;__dict__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__getattribute__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__le__&apos;, &apos;__lt__&apos;, &apos;__module__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;, &apos;__weakref__&apos;, &apos;_age&apos;, &apos;name&apos;]{&apos;name&apos;: &apos;leocode&apos;, &apos;_age&apos;: 21, &apos;_UserInfo__account&apos;: 199831}19983121</code></pre><h3 id="类专有的方法"><a href="#类专有的方法" class="headerlink" title="类专有的方法"></a>类专有的方法</h3><ul><li>一个类创建的时候，就会包含一些方法</li></ul><h3 id="方法的访问控制"><a href="#方法的访问控制" class="headerlink" title="方法的访问控制"></a>方法的访问控制</h3><ul><li>方法也可以看成类的属性（只是看成），用法是一样的</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;面向对象的两个基本概念&quot;&gt;&lt;a href=&quot;#面向对象的两个基本概念&quot; class=&quot;headerlink&quot; title=&quot;面向对象的两个基本概念&quot;&gt;&lt;/a&gt;面向对象的两个基本概念&lt;/h3&gt;&lt;p&gt;编程语言中，一般有两种编程思维，面向过程和面向对象。&lt;/p&gt;
&lt;p&gt;面向过程，看重的是解决问题的过程。&lt;/p&gt;
&lt;p&gt;这好比我们解决日常生活问题差不多，分析解决问题的步骤，然后一步一步的解决。&lt;/p&gt;
&lt;p&gt;而面向对象是一种抽象，抽象是指用分类的眼光去看世界的一种方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://cblog.club/categories/Python/"/>
    
    
      <category term="Python" scheme="https://cblog.club/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>300最长上升子序列</title>
    <link href="https://cblog.club/ck3ecxtnr000dv0g447859ue3.html"/>
    <id>https://cblog.club/ck3ecxtnr000dv0g447859ue3.html</id>
    <published>2019-11-20T14:13:00.000Z</published>
    <updated>2019-11-21T06:02:54.860Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p> 给定一个无序的整数数组，找到其中最长上升子序列的长度。 </p><a id="more"></a><blockquote><p><strong>示例:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入: [<span class="number">10</span>,<span class="number">9</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">101</span>,<span class="number">18</span>]</span><br><span class="line">输出: <span class="number">4</span> </span><br><span class="line">解释: 最长的上升子序列是 [<span class="number">2</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">101</span>]，它的长度是 <span class="number">4</span>。</span><br></pre></td></tr></table></figure><p><strong>说明:</strong></p><ul><li>可能会有多种最长上升子序列的组合，你只需要输出对应的长度即可。</li><li>你算法的时间复杂度应该为 O(<em>n2</em>) 。</li></ul><p><strong>进阶:</strong> 你能将算法的时间复杂度降低到 O(<em>n</em> log <em>n</em>) 吗?</p></blockquote><h6 id="解题思路：本题思路不是很难，但是时间复杂度在O-n-2-，想要让时间复杂度降低到-O-n-log-n-，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。"><a href="#解题思路：本题思路不是很难，但是时间复杂度在O-n-2-，想要让时间复杂度降低到-O-n-log-n-，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。" class="headerlink" title="解题思路：本题思路不是很难，但是时间复杂度在O(n^2)，想要让时间复杂度降低到 O(n log n)，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。"></a>解题思路：本题思路不是很难，但是时间复杂度在O(n^2)，想要让时间复杂度降低到 O(<em>n</em> log <em>n</em>)，暂时还没有想到，而且使用的已经是动态规划了（记录以当前结点为终止结点的子序列的最长长度），但是我发现其实还是多级算了一些结点，其实并不一定要一个一个遍历，我们只需要找到在当前结点之前最大的（但又是必须要小于他）的结点即可，所以暂时停留在这一步，明天重构一下，用我现在的思路。</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> max_val=<span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size,<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;size;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i<span class="number">-1</span>;j&gt;=<span class="number">0</span>;j--)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[j]&lt;nums[i])dp[i]=max(dp[i],dp[j]+<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(max_val&lt;dp[i])max_val=dp[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max_val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h6 id="法二：其实题目规定将算法时间复杂度降到O-nlogn-这就是在提示我们使用二分法，但是这个二分真的很难想，dp-i-代表的是i-1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）"><a href="#法二：其实题目规定将算法时间复杂度降到O-nlogn-这就是在提示我们使用二分法，但是这个二分真的很难想，dp-i-代表的是i-1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）" class="headerlink" title="法二：其实题目规定将算法时间复杂度降到O(nlogn)这就是在提示我们使用二分法，但是这个二分真的很难想，dp[i]代表的是i+1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）"></a>法二：其实题目规定将算法时间复杂度降到O(nlogn)这就是在提示我们使用二分法，但是这个二分真的很难想，dp[i]代表的是i+1长度的序列的尾元素的最小值（因为采取最小值，这样后边来一个值，更容易造成上升这个趋势），并且dp数组满足一定是一个递增的数组的条件（这一方法需要再思考）</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size=nums.size();</span><br><span class="line">        <span class="keyword">if</span>(size==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> max_val,cur_max,res;</span><br><span class="line">        max_val=<span class="number">1</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;dp(size);</span><br><span class="line">        res=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num:nums)&#123;</span><br><span class="line">            <span class="keyword">int</span> l,r,m;</span><br><span class="line">            l=<span class="number">0</span>;r=res;</span><br><span class="line">            <span class="keyword">while</span>(l&lt;r)&#123;</span><br><span class="line">                m=(r+l)/<span class="number">2</span>;</span><br><span class="line">                <span class="keyword">if</span>(dp[m]&gt;=num)r=m;</span><br><span class="line">                <span class="keyword">else</span> l=m+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            dp[l]=num;</span><br><span class="line">            <span class="keyword">if</span>(res==r)res++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt; 给定一个无序的整数数组，找到其中最长上升子序列的长度。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>62不同路径</title>
    <link href="https://cblog.club/ck3ecxtpb001sv0g44en6gy0p.html"/>
    <id>https://cblog.club/ck3ecxtpb001sv0g44en6gy0p.html</id>
    <published>2019-11-20T14:08:46.000Z</published>
    <updated>2019-11-20T14:12:20.800Z</updated>
    
    <content type="html"><![CDATA[<h6 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h6><p>一个机器人位于一个 <em>m x n</em> 网格的左上角 （起始点在下图中标记为“Start” ）。</p><p>机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。</p><p>问总共有多少条不同的路径？</p><a id="more"></a><blockquote><p><strong>说明：</strong>m 和 <em>n</em> 的值均不超过 100。</p><p><strong>示例 1:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入: m = <span class="number">3</span>, n = <span class="number">2</span></span><br><span class="line">输出: <span class="number">3</span></span><br><span class="line">解释:</span><br><span class="line">从左上角开始，总共有 <span class="number">3</span> 条路径可以到达右下角。</span><br><span class="line"><span class="number">1.</span> 向右 -&gt; 向右 -&gt; 向下</span><br><span class="line"><span class="number">2.</span> 向右 -&gt; 向下 -&gt; 向右</span><br><span class="line"><span class="number">3.</span> 向下 -&gt; 向右 -&gt; 向右</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: m = <span class="number">7</span>, n = <span class="number">3</span></span><br><span class="line">输出: <span class="number">28</span></span><br></pre></td></tr></table></figure></blockquote><h6 id="解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）"><a href="#解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）" class="headerlink" title="解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）"></a>解题思路：本题其实还是蛮简单的，就是模拟一下走的路径，只能向下走和向右走，用一个二维数组模拟即可，注意的是第一行和第一列都是1，代表当前走到这里可能的路径数目（如果只有起点，算一个路径）</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">uniquePaths</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> dp[m][n];</span><br><span class="line">        <span class="keyword">int</span> i,j;</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>][i]=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(j=<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">                dp[i][j]=dp[i<span class="number">-1</span>][j]+dp[i][j<span class="number">-1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m<span class="number">-1</span>][n<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h6 id=&quot;题目描述：&quot;&gt;&lt;a href=&quot;#题目描述：&quot; class=&quot;headerlink&quot; title=&quot;题目描述：&quot;&gt;&lt;/a&gt;题目描述：&lt;/h6&gt;&lt;p&gt;一个机器人位于一个 &lt;em&gt;m x n&lt;/em&gt; 网格的左上角 （起始点在下图中标记为“Start” ）。&lt;/p&gt;
&lt;p&gt;机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。&lt;/p&gt;
&lt;p&gt;问总共有多少条不同的路径？&lt;/p&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://cblog.club/categories/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/categories/leetcode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
      <category term="leetcode" scheme="https://cblog.club/tags/leetcode/"/>
    
      <category term="动态规划" scheme="https://cblog.club/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
</feed>
